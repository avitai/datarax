{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Complete Pipeline Tutorial\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Beginner to Intermediate |\n",
    "| **Runtime** | ~30 min |\n",
    "| **Prerequisites** | [Simple Pipeline Quick Reference](01_simple_pipeline.py) |\n",
    "| **Format** | Python + Jupyter |\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial provides a thorough introduction to building data pipelines\n",
    "with Datarax. You'll learn to create data sources, compose multiple operators,\n",
    "handle different data modalities, and build production-ready pipelines.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. Understand the DAG-based pipeline architecture\n",
    "2. Create and configure different data sources\n",
    "3. Build custom transformation operators\n",
    "4. Compose operators using CompositeOperator\n",
    "5. Apply probabilistic augmentations\n",
    "6. Handle multi-field data (images + labels)\n",
    "7. Build reproducible pipelines with proper RNG management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "# Install datarax with all dependencies\n",
    "uv pip install \"datarax[data]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "\n",
    "from datarax import from_source\n",
    "from datarax.dag.nodes import OperatorNode\n",
    "from datarax.operators import (\n",
    "    ElementOperator,\n",
    "    ElementOperatorConfig,\n",
    ")\n",
    "from datarax.operators.composite_operator import (\n",
    "    CompositeOperatorConfig,\n",
    "    CompositeOperatorModule,\n",
    "    CompositionStrategy,\n",
    ")\n",
    "\n",
    "# Note: ProbabilisticOperator available for conditional augmentation\n",
    "# See advanced examples for probabilistic operator usage\n",
    "from datarax.sources import MemorySource, MemorySourceConfig\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX backend: {jax.default_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 1: Understanding the Pipeline Architecture\n",
    "\n",
    "Datarax pipelines follow a **Directed Acyclic Graph (DAG)** pattern:\n",
    "\n",
    "```\n",
    "DataSource → OperatorNode → OperatorNode → ... → Output\n",
    "     ↑            ↑              ↑\n",
    "   Config      Operator       Operator\n",
    "```\n",
    "\n",
    "Key concepts:\n",
    "\n",
    "- **Source**: Produces raw data elements\n",
    "- **OperatorNode**: Wraps an operator for the pipeline DAG\n",
    "- **Operator**: Transforms data elements\n",
    "- **Pipeline**: Connects source and operators, handles batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 2: Creating a Data Source\n",
    "\n",
    "`MemorySource` wraps in-memory data. Data must be dictionary-based\n",
    "with arrays sharing the same first dimension (sample dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic training data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "num_samples = 500\n",
    "image_height, image_width, channels = 32, 32, 3\n",
    "\n",
    "# Simulate RGB images and one-hot encoded labels\n",
    "data = {\n",
    "    \"image\": np.random.randint(0, 256, (num_samples, image_height, image_width, channels)).astype(\n",
    "        np.float32\n",
    "    ),\n",
    "    \"label\": np.eye(10)[np.random.randint(0, 10, num_samples)].astype(np.float32),\n",
    "    \"metadata\": np.random.rand(num_samples, 4).astype(np.float32),  # Extra features\n",
    "}\n",
    "\n",
    "print(\"Dataset structure:\")\n",
    "for key, value in data.items():\n",
    "    print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MemorySource with configuration\n",
    "source_config = MemorySourceConfig()\n",
    "source = MemorySource(source_config, data=data, rngs=nnx.Rngs(0))\n",
    "\n",
    "print(f\"\\nSource created: {len(source)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 3: Building Custom Operators\n",
    "\n",
    "Operators transform data elements. Each operator receives:\n",
    "\n",
    "- `element`: A data element with `.data` dict\n",
    "- `key`: JAX random key (for stochastic operators)\n",
    "\n",
    "The operator returns a new element via `element.update_data(new_data)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operator 1: Normalize images to [0, 1]\n",
    "def normalize_image(element, key=None):\n",
    "    \"\"\"Normalize image pixel values to [0, 1] range.\"\"\"\n",
    "    image = element.data[\"image\"]\n",
    "    normalized = image / 255.0\n",
    "    return element.update_data({\"image\": normalized})\n",
    "\n",
    "\n",
    "normalizer = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=False),  # Deterministic\n",
    "    fn=normalize_image,\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "print(\"Created: normalizer (deterministic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operator 2: Random horizontal flip (stochastic)\n",
    "def random_flip(element, key):\n",
    "    \"\"\"Randomly flip image horizontally with 50% probability.\"\"\"\n",
    "    flip_key, _ = jax.random.split(key)\n",
    "    should_flip = jax.random.bernoulli(flip_key, 0.5)\n",
    "\n",
    "    image = element.data[\"image\"]\n",
    "    flipped = jax.lax.cond(\n",
    "        should_flip,\n",
    "        lambda x: jnp.flip(x, axis=1),  # Flip along width axis\n",
    "        lambda x: x,\n",
    "        image,\n",
    "    )\n",
    "    return element.update_data({\"image\": flipped})\n",
    "\n",
    "\n",
    "flipper = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=True, stream_name=\"flip\"),\n",
    "    fn=random_flip,\n",
    "    rngs=nnx.Rngs(flip=42),\n",
    ")\n",
    "print(\"Created: flipper (stochastic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operator 3: Add Gaussian noise (stochastic)\n",
    "def add_noise(element, key):\n",
    "    \"\"\"Add random Gaussian noise to image.\"\"\"\n",
    "    noise_key, _ = jax.random.split(key)\n",
    "    image = element.data[\"image\"]\n",
    "\n",
    "    # Add small noise (std=0.1)\n",
    "    noise = jax.random.normal(noise_key, image.shape) * 0.1\n",
    "    noisy = jnp.clip(image + noise, 0.0, 1.0)  # Keep in valid range\n",
    "\n",
    "    return element.update_data({\"image\": noisy})\n",
    "\n",
    "\n",
    "noise_adder = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=True, stream_name=\"noise\"),\n",
    "    fn=add_noise,\n",
    "    rngs=nnx.Rngs(noise=123),\n",
    ")\n",
    "print(\"Created: noise_adder (stochastic)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 4: Composing Operators\n",
    "\n",
    "`CompositeOperatorModule` chains multiple operators together,\n",
    "applying them sequentially to each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create composite augmentation pipeline\n",
    "# CompositeOperatorConfig requires strategy and operators in the config\n",
    "augmentation_config = CompositeOperatorConfig(\n",
    "    strategy=CompositionStrategy.SEQUENTIAL,  # Apply operators in sequence\n",
    "    operators=[flipper, noise_adder],  # List of operators to chain\n",
    "    stochastic=True,\n",
    "    stream_name=\"augment\",\n",
    ")\n",
    "\n",
    "# Build composite operator from config\n",
    "augmentation_pipeline = CompositeOperatorModule(\n",
    "    augmentation_config,\n",
    "    rngs=nnx.Rngs(augment=999),\n",
    ")\n",
    "\n",
    "print(\"Created composite operator with SEQUENTIAL strategy (2 operators)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 5: Additional Transformations\n",
    "\n",
    "Add more operators to the pipeline for extensive augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a brightness adjustment operator\n",
    "def adjust_brightness(element, key):\n",
    "    \"\"\"Adjust image brightness by a random factor.\"\"\"\n",
    "    brightness_key, _ = jax.random.split(key)\n",
    "    factor = jax.random.uniform(brightness_key, minval=0.8, maxval=1.2)\n",
    "\n",
    "    image = element.data[\"image\"]\n",
    "    adjusted = jnp.clip(image * factor, 0.0, 1.0)\n",
    "    return element.update_data({\"image\": adjusted})\n",
    "\n",
    "\n",
    "brightness_op = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=True, stream_name=\"brightness\"),\n",
    "    fn=adjust_brightness,\n",
    "    rngs=nnx.Rngs(brightness=456),\n",
    ")\n",
    "\n",
    "print(\"Created brightness adjustment operator (stochastic)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 6: Building the Complete Pipeline\n",
    "\n",
    "Chain everything together using the DAG API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the full pipeline\n",
    "pipeline = (\n",
    "    from_source(source, batch_size=32)\n",
    "    .add(OperatorNode(normalizer))  # Step 1: Normalize\n",
    "    .add(OperatorNode(augmentation_pipeline))  # Step 2: Flip + Noise\n",
    "    .add(OperatorNode(brightness_op))  # Step 3: Brightness adjustment\n",
    ")\n",
    "\n",
    "print(\"Pipeline structure:\")\n",
    "print(\"  Source → Normalize → [Flip + Noise] → Brightness → Output\")\n",
    "print(\"  Batch size: 32\")\n",
    "print(f\"  Total samples: {len(source)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 7: Running the Pipeline\n",
    "\n",
    "Iterate through the pipeline to process data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process batches\n",
    "print(\"\\nProcessing batches:\")\n",
    "stats = {\"min\": [], \"max\": [], \"mean\": []}\n",
    "\n",
    "for i, batch in enumerate(pipeline):\n",
    "    if i >= 5:  # Process 5 batches for demo\n",
    "        break\n",
    "\n",
    "    image_batch = batch[\"image\"]\n",
    "    label_batch = batch[\"label\"]\n",
    "\n",
    "    # Collect statistics\n",
    "    stats[\"min\"].append(float(image_batch.min()))\n",
    "    stats[\"max\"].append(float(image_batch.max()))\n",
    "    stats[\"mean\"].append(float(image_batch.mean()))\n",
    "\n",
    "    print(f\"Batch {i}:\")\n",
    "    img_min, img_max = image_batch.min(), image_batch.max()\n",
    "    print(f\"  Image: shape={image_batch.shape}, range=[{img_min:.3f}, {img_max:.3f}]\")\n",
    "    print(f\"  Label: shape={label_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nPipeline Statistics (5 batches):\")\n",
    "print(f\"  Min pixel: {min(stats['min']):.4f}\")\n",
    "print(f\"  Max pixel: {max(stats['max']):.4f}\")\n",
    "print(f\"  Mean pixel: {sum(stats['mean']) / len(stats['mean']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 8: Reproducibility\n",
    "\n",
    "Datarax ensures reproducible pipelines through explicit RNG management.\n",
    "Same seeds produce identical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate reproducibility\n",
    "def create_pipeline_with_seed(seed: int):\n",
    "    \"\"\"Create a fresh pipeline with specific seed.\"\"\"\n",
    "    src = MemorySource(MemorySourceConfig(), data=data, rngs=nnx.Rngs(seed))\n",
    "\n",
    "    norm = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False), fn=normalize_image, rngs=nnx.Rngs(0)\n",
    "    )\n",
    "\n",
    "    flip = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=True, stream_name=\"flip\"),\n",
    "        fn=random_flip,\n",
    "        rngs=nnx.Rngs(flip=seed),\n",
    "    )\n",
    "\n",
    "    return from_source(src, batch_size=8).add(OperatorNode(norm)).add(OperatorNode(flip))\n",
    "\n",
    "\n",
    "# Create two pipelines with same seed\n",
    "p1 = create_pipeline_with_seed(42)\n",
    "p2 = create_pipeline_with_seed(42)\n",
    "\n",
    "# Get first batch from each\n",
    "batch1 = next(iter(p1))\n",
    "batch2 = next(iter(p2))\n",
    "\n",
    "# Check if identical\n",
    "images_match = jnp.allclose(batch1[\"image\"], batch2[\"image\"])\n",
    "print(f\"Same seed produces identical results: {images_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "| Component | Type | Purpose |\n",
    "|-----------|------|---------|\n",
    "| MemorySource | Source | In-memory data storage |\n",
    "| ElementOperator | Operator | Element-wise transforms |\n",
    "| CompositeOperator | Operator | Chain multiple operators |\n",
    "| OperatorNode | DAG Node | Wrap operators for pipeline |\n",
    "\n",
    "Pipeline features:\n",
    "\n",
    "- **Lazy evaluation**: Data processed only when iterated\n",
    "- **Reproducibility**: Deterministic with same seeds\n",
    "- **Composability**: Operators can be nested and chained\n",
    "- **Type safety**: Strong typing throughout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Image operators**: See `datarax.operators.modality.image` for augmentations\n",
    "- **External data**: [HuggingFace](../integration/huggingface/01_hf_quickref.ipynb)\n",
    "- **Distributed**: [Sharding](../advanced/distributed/01_sharding_quickref.ipynb)\n",
    "- **Checkpointing**: [Checkpoint](../advanced/checkpointing/01_checkpoint_quickref.ipynb)\n",
    "- **API Reference**: [Operators API](https://datarax.readthedocs.io/operators/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the complete pipeline tutorial.\"\"\"\n",
    "    print(\"Complete Pipeline Tutorial\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Create data\n",
    "    np.random.seed(42)\n",
    "    num_samples = 200\n",
    "    data = {\n",
    "        \"image\": np.random.randint(0, 256, (num_samples, 32, 32, 3)).astype(np.float32),\n",
    "        \"label\": np.eye(10)[np.random.randint(0, 10, num_samples)].astype(np.float32),\n",
    "    }\n",
    "\n",
    "    # Create source and operators\n",
    "    source = MemorySource(MemorySourceConfig(), data=data, rngs=nnx.Rngs(0))\n",
    "\n",
    "    normalizer = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False), fn=normalize_image, rngs=nnx.Rngs(0)\n",
    "    )\n",
    "    flipper = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=True, stream_name=\"flip\"),\n",
    "        fn=random_flip,\n",
    "        rngs=nnx.Rngs(flip=42),\n",
    "    )\n",
    "\n",
    "    # Build pipeline\n",
    "    pipeline = (\n",
    "        from_source(source, batch_size=32).add(OperatorNode(normalizer)).add(OperatorNode(flipper))\n",
    "    )\n",
    "\n",
    "    # Process all data\n",
    "    total_samples = 0\n",
    "    for batch in pipeline:\n",
    "        total_samples += batch[\"image\"].shape[0]\n",
    "\n",
    "    print(f\"Processed {total_samples} samples through the pipeline\")\n",
    "    print(\"Tutorial completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
