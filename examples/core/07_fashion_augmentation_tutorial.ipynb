{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Fashion-MNIST Augmentation Pipeline Tutorial\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Intermediate |\n",
    "| **Runtime** | ~30 min (CPU) / ~15 min (GPU) |\n",
    "| **Prerequisites** | MNIST Tutorial, Operators Tutorial |\n",
    "| **Format** | Python + Jupyter |\n",
    "| **Memory** | ~1 GB RAM |\n",
    "\n",
    "## Overview\n",
    "\n",
    "Build a complete augmentation pipeline for Fashion-MNIST, demonstrating\n",
    "multiple image operators chained together. Fashion-MNIST is more challenging\n",
    "than MNIST, making augmentation more important for good performance.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. Apply multiple stacked image operators\n",
    "2. Use PatchDropout (Cutout-style) for regularization\n",
    "3. Use NoiseOperator with different noise types\n",
    "4. Measure augmentation impact on training\n",
    "5. Visualize various augmentation effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "uv pip install \"datarax[tfds]\" matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Memory Configuration\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES_FOR_TF\"] = \"\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "# Core imports\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "\n",
    "# Datarax imports\n",
    "from datarax import from_source\n",
    "from datarax.dag.nodes import OperatorNode\n",
    "from datarax.operators import ElementOperator, ElementOperatorConfig\n",
    "from datarax.operators.modality.image import (\n",
    "    BrightnessOperator,\n",
    "    BrightnessOperatorConfig,\n",
    "    ContrastOperator,\n",
    "    ContrastOperatorConfig,\n",
    "    DropoutOperator,\n",
    "    DropoutOperatorConfig,\n",
    "    NoiseOperator,\n",
    "    NoiseOperatorConfig,\n",
    "    PatchDropoutOperator,\n",
    "    PatchDropoutOperatorConfig,\n",
    "    RotationOperator,\n",
    "    RotationOperatorConfig,\n",
    ")\n",
    "from datarax.sources import TFDSEagerConfig, TFDSEagerSource\n",
    "\n",
    "print(f\"JAX backend: {jax.default_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Fashion-MNIST Dataset\n",
    "\n",
    "Fashion-MNIST contains 70,000 grayscale images of clothing items, designed as\n",
    "a more challenging drop-in replacement for MNIST.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| Image size | 28×28×1 |\n",
    "| Train samples | 60,000 |\n",
    "| Test samples | 10,000 |\n",
    "| Classes | 10 |\n",
    "\n",
    "### Class Names\n",
    "\n",
    "| Label | Description |\n",
    "|-------|-------------|\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "FASHION_CLASSES = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "# Normalization (similar to MNIST)\n",
    "FASHION_MEAN = 0.2860\n",
    "FASHION_STD = 0.3530\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_SAMPLES = 5000  # Subset for demo\n",
    "\n",
    "print(f\"Fashion-MNIST classes: {FASHION_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 1: Create Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST\n",
    "train_config = TFDSEagerConfig(\n",
    "    name=\"fashion_mnist\",\n",
    "    split=f\"train[:{TRAIN_SAMPLES}]\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "train_source = TFDSEagerSource(train_config, rngs=nnx.Rngs(42))\n",
    "print(f\"Loaded {len(train_source)} Fashion-MNIST samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "def preprocess_fashion(element, key=None):  # noqa: ARG001\n",
    "    \"\"\"Normalize Fashion-MNIST images.\"\"\"\n",
    "    del key\n",
    "    image = element.data[\"image\"]\n",
    "\n",
    "    # Convert to float32 and normalize\n",
    "    image = image.astype(jnp.float32) / 255.0\n",
    "\n",
    "    # Ensure channel dimension\n",
    "    if image.ndim == 2:\n",
    "        image = image[..., None]\n",
    "\n",
    "    # Apply normalization\n",
    "    image = (image - FASHION_MEAN) / FASHION_STD\n",
    "\n",
    "    return element.update_data({\"image\": image})\n",
    "\n",
    "\n",
    "preprocessor = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=False),\n",
    "    fn=preprocess_fashion,\n",
    "    rngs=nnx.Rngs(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 2: Define Augmentation Operators\n",
    "\n",
    "We'll create a complete augmentation suite including:\n",
    "\n",
    "1. **Brightness/Contrast**: Photometric variations\n",
    "2. **Rotation**: Geometric transformation\n",
    "3. **Noise**: Sensor noise simulation\n",
    "4. **PatchDropout**: Cutout-style occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Brightness augmentation\n",
    "brightness_op = BrightnessOperator(\n",
    "    BrightnessOperatorConfig(\n",
    "        field_key=\"image\",\n",
    "        brightness_range=(-0.15, 0.15),\n",
    "        stochastic=True,\n",
    "        stream_name=\"brightness\",\n",
    "    ),\n",
    "    rngs=nnx.Rngs(brightness=100),\n",
    ")\n",
    "\n",
    "# 2. Contrast augmentation\n",
    "contrast_op = ContrastOperator(\n",
    "    ContrastOperatorConfig(\n",
    "        field_key=\"image\",\n",
    "        contrast_range=(0.85, 1.15),\n",
    "        stochastic=True,\n",
    "        stream_name=\"contrast\",\n",
    "    ),\n",
    "    rngs=nnx.Rngs(contrast=200),\n",
    ")\n",
    "\n",
    "# 3. Rotation augmentation\n",
    "rotation_op = RotationOperator(\n",
    "    RotationOperatorConfig(\n",
    "        field_key=\"image\",\n",
    "        angle_range=(-10.0, 10.0),\n",
    "        fill_value=0.0,\n",
    "    ),\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "\n",
    "# 4. Gaussian noise\n",
    "noise_op = NoiseOperator(\n",
    "    NoiseOperatorConfig(\n",
    "        field_key=\"image\",\n",
    "        mode=\"gaussian\",\n",
    "        noise_std=0.1,\n",
    "        stochastic=True,\n",
    "        stream_name=\"noise\",\n",
    "    ),\n",
    "    rngs=nnx.Rngs(noise=300),\n",
    ")\n",
    "\n",
    "# 5. PatchDropout (Cutout-style)\n",
    "patch_dropout_op = PatchDropoutOperator(\n",
    "    PatchDropoutOperatorConfig(\n",
    "        field_key=\"image\",\n",
    "        patch_size=(6, 6),  # 6x6 patches\n",
    "        num_patches=2,  # Drop 2 patches\n",
    "        drop_value=0.0,\n",
    "        stochastic=True,\n",
    "        stream_name=\"patch_dropout\",\n",
    "    ),\n",
    "    rngs=nnx.Rngs(patch_dropout=400),\n",
    ")\n",
    "\n",
    "# 6. Pixel dropout (alternative to patch)\n",
    "pixel_dropout_op = DropoutOperator(\n",
    "    DropoutOperatorConfig(\n",
    "        field_key=\"image\",\n",
    "        dropout_rate=0.1,\n",
    "        stochastic=True,\n",
    "        stream_name=\"dropout\",\n",
    "    ),\n",
    "    rngs=nnx.Rngs(dropout=500),\n",
    ")\n",
    "\n",
    "print(\"Created augmentation operators:\")\n",
    "print(\"  1. Brightness: ±0.15\")\n",
    "print(\"  2. Contrast: 0.85-1.15x\")\n",
    "print(\"  3. Rotation: ±10°\")\n",
    "print(\"  4. Gaussian noise: std=0.1\")\n",
    "print(\"  5. PatchDropout: 2x 6x6 patches\")\n",
    "print(\"  6. PixelDropout: 10% probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 3: Visualize Individual Augmentations\n",
    "\n",
    "See the effect of each augmentation type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_aug_pipeline(operator, seed=0):\n",
    "    \"\"\"Create pipeline with single augmentation for visualization.\"\"\"\n",
    "    source = TFDSEagerSource(\n",
    "        TFDSEagerConfig(name=\"fashion_mnist\", split=\"train[:64]\", shuffle=False),\n",
    "        rngs=nnx.Rngs(seed),\n",
    "    )\n",
    "\n",
    "    prep = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=preprocess_fashion,\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    return from_source(source, batch_size=64).add(OperatorNode(prep)).add(OperatorNode(operator))\n",
    "\n",
    "\n",
    "# Get baseline (no augmentation)\n",
    "baseline_source = TFDSEagerSource(\n",
    "    TFDSEagerConfig(name=\"fashion_mnist\", split=\"train[:64]\", shuffle=False),\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "baseline_pipeline = from_source(baseline_source, batch_size=64).add(\n",
    "    OperatorNode(\n",
    "        ElementOperator(\n",
    "            ElementOperatorConfig(stochastic=False),\n",
    "            fn=preprocess_fashion,\n",
    "            rngs=nnx.Rngs(0),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "baseline_batch = next(iter(baseline_pipeline))\n",
    "baseline_images = np.array(baseline_batch[\"image\"])\n",
    "baseline_labels = np.array(baseline_batch[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines for each augmentation type\n",
    "aug_configs = [\n",
    "    (\"Original\", None, baseline_images),\n",
    "    (\n",
    "        \"Brightness\",\n",
    "        BrightnessOperator(\n",
    "            BrightnessOperatorConfig(\n",
    "                field_key=\"image\",\n",
    "                brightness_range=(-0.15, 0.15),\n",
    "                stochastic=True,\n",
    "                stream_name=\"brightness\",\n",
    "            ),\n",
    "            rngs=nnx.Rngs(brightness=100),\n",
    "        ),\n",
    "        None,\n",
    "    ),\n",
    "    (\n",
    "        \"Contrast\",\n",
    "        ContrastOperator(\n",
    "            ContrastOperatorConfig(\n",
    "                field_key=\"image\",\n",
    "                contrast_range=(0.85, 1.15),\n",
    "                stochastic=True,\n",
    "                stream_name=\"contrast\",\n",
    "            ),\n",
    "            rngs=nnx.Rngs(contrast=200),\n",
    "        ),\n",
    "        None,\n",
    "    ),\n",
    "    (\n",
    "        \"Rotation\",\n",
    "        RotationOperator(\n",
    "            RotationOperatorConfig(\n",
    "                field_key=\"image\",\n",
    "                angle_range=(-10.0, 10.0),\n",
    "                fill_value=0.0,\n",
    "            ),\n",
    "            rngs=nnx.Rngs(0),\n",
    "        ),\n",
    "        None,\n",
    "    ),\n",
    "    (\n",
    "        \"Noise\",\n",
    "        NoiseOperator(\n",
    "            NoiseOperatorConfig(\n",
    "                field_key=\"image\",\n",
    "                mode=\"gaussian\",\n",
    "                noise_std=0.1,\n",
    "                stochastic=True,\n",
    "                stream_name=\"noise\",\n",
    "            ),\n",
    "            rngs=nnx.Rngs(noise=300),\n",
    "        ),\n",
    "        None,\n",
    "    ),\n",
    "    (\n",
    "        \"PatchDropout\",\n",
    "        PatchDropoutOperator(\n",
    "            PatchDropoutOperatorConfig(\n",
    "                field_key=\"image\",\n",
    "                patch_size=(6, 6),\n",
    "                num_patches=2,\n",
    "                drop_value=0.0,\n",
    "                stochastic=True,\n",
    "                stream_name=\"patch_dropout\",\n",
    "            ),\n",
    "            rngs=nnx.Rngs(patch_dropout=400),\n",
    "        ),\n",
    "        None,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Get augmented samples\n",
    "for i, (name, op, imgs) in enumerate(aug_configs):\n",
    "    if imgs is None and op is not None:\n",
    "        pipeline = create_single_aug_pipeline(op, seed=i)\n",
    "        batch = next(iter(pipeline))\n",
    "        aug_configs[i] = (name, op, np.array(batch[\"image\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot augmentation comparison grid\n",
    "output_dir = Path(\"docs/assets/images/examples\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig, axes = plt.subplots(6, 8, figsize=(16, 12))\n",
    "fig.suptitle(\"Fashion-MNIST Augmentation Effects\", fontsize=14)\n",
    "\n",
    "for row_idx, (name, _, images) in enumerate(aug_configs):\n",
    "    axes[row_idx, 0].set_ylabel(name, fontsize=10, rotation=0, ha=\"right\", va=\"center\")\n",
    "\n",
    "    for col_idx in range(8):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        img = images[col_idx] * FASHION_STD + FASHION_MEAN\n",
    "        img = np.clip(img, 0, 1).squeeze()\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        if row_idx == 0:\n",
    "            ax.set_title(FASHION_CLASSES[baseline_labels[col_idx]], fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"cv-fashion-augmentation-grid.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\"\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'cv-fashion-augmentation-grid.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 4: Build Complete Augmentation Pipeline\n",
    "\n",
    "Chain all augmentations into a single pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_augmentation_pipeline(seed=42):\n",
    "    \"\"\"Create pipeline with all augmentations.\"\"\"\n",
    "    source = TFDSEagerSource(\n",
    "        TFDSEagerConfig(\n",
    "            name=\"fashion_mnist\",\n",
    "            split=f\"train[:{TRAIN_SAMPLES}]\",\n",
    "            shuffle=True,\n",
    "            seed=seed,\n",
    "        ),\n",
    "        rngs=nnx.Rngs(seed),\n",
    "    )\n",
    "\n",
    "    # Preprocessing\n",
    "    prep = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=preprocess_fashion,\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    # Augmentations\n",
    "    brightness = BrightnessOperator(\n",
    "        BrightnessOperatorConfig(\n",
    "            field_key=\"image\",\n",
    "            brightness_range=(-0.15, 0.15),\n",
    "            stochastic=True,\n",
    "            stream_name=\"brightness\",\n",
    "        ),\n",
    "        rngs=nnx.Rngs(brightness=100),\n",
    "    )\n",
    "\n",
    "    contrast = ContrastOperator(\n",
    "        ContrastOperatorConfig(\n",
    "            field_key=\"image\",\n",
    "            contrast_range=(0.85, 1.15),\n",
    "            stochastic=True,\n",
    "            stream_name=\"contrast\",\n",
    "        ),\n",
    "        rngs=nnx.Rngs(contrast=200),\n",
    "    )\n",
    "\n",
    "    rotation = RotationOperator(\n",
    "        RotationOperatorConfig(\n",
    "            field_key=\"image\",\n",
    "            angle_range=(-10.0, 10.0),\n",
    "            fill_value=0.0,\n",
    "        ),\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    noise = NoiseOperator(\n",
    "        NoiseOperatorConfig(\n",
    "            field_key=\"image\",\n",
    "            mode=\"gaussian\",\n",
    "            noise_std=0.05,  # Lighter for combined use\n",
    "            stochastic=True,\n",
    "            stream_name=\"noise\",\n",
    "        ),\n",
    "        rngs=nnx.Rngs(noise=300),\n",
    "    )\n",
    "\n",
    "    patch_dropout = PatchDropoutOperator(\n",
    "        PatchDropoutOperatorConfig(\n",
    "            field_key=\"image\",\n",
    "            patch_size=(4, 4),  # Smaller patches for combined use\n",
    "            num_patches=1,\n",
    "            drop_value=0.0,\n",
    "            stochastic=True,\n",
    "            stream_name=\"patch_dropout\",\n",
    "        ),\n",
    "        rngs=nnx.Rngs(patch_dropout=400),\n",
    "    )\n",
    "\n",
    "    # Build pipeline\n",
    "    return (\n",
    "        from_source(source, batch_size=BATCH_SIZE)\n",
    "        .add(OperatorNode(prep))\n",
    "        .add(OperatorNode(brightness))\n",
    "        .add(OperatorNode(contrast))\n",
    "        .add(OperatorNode(rotation))\n",
    "        .add(OperatorNode(noise))\n",
    "        .add(OperatorNode(patch_dropout))\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Full augmentation pipeline:\")\n",
    "print(\"  Source -> Preprocess -> Brightness -> Contrast -> Rotation -> Noise -> PatchDropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 5: Measure Augmentation Latency\n",
    "\n",
    "Profile the time cost of each augmentation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark individual augmentations\n",
    "num_batches = 20\n",
    "latencies = {}\n",
    "\n",
    "for name, op, _ in aug_configs[1:]:  # Skip \"Original\"\n",
    "    pipeline = create_single_aug_pipeline(op, seed=0)\n",
    "\n",
    "    times = []\n",
    "    for i, batch in enumerate(pipeline):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        start = time.time()\n",
    "        _ = batch[\"image\"].block_until_ready()  # Force computation\n",
    "        times.append(time.time() - start)\n",
    "\n",
    "    latencies[name] = np.mean(times[1:]) * 1000  # Skip first (warmup), convert to ms\n",
    "\n",
    "print(\"Augmentation latency per batch (ms):\")\n",
    "for name, latency in latencies.items():\n",
    "    print(f\"  {name}: {latency:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot latency comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "names = list(latencies.keys())\n",
    "values = list(latencies.values())\n",
    "\n",
    "bars = ax.barh(names, values, color=plt.cm.viridis(np.linspace(0.2, 0.8, len(names))))\n",
    "ax.set_xlabel(\"Latency (ms)\")\n",
    "ax.set_title(\"Augmentation Latency per Batch (64 samples)\")\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.text(val + 0.5, bar.get_y() + bar.get_height() / 2, f\"{val:.1f}ms\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"cv-fashion-latency.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'cv-fashion-latency.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 6: Visualize Original vs Fully Augmented\n",
    "\n",
    "Compare samples before and after full augmentation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples from full pipeline\n",
    "full_pipeline = create_full_augmentation_pipeline(seed=42)\n",
    "full_batch = next(iter(full_pipeline))\n",
    "full_images = np.array(full_batch[\"image\"])\n",
    "full_labels = np.array(full_batch[\"label\"])\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "fig.suptitle(\"Original vs Fully Augmented Fashion-MNIST\", fontsize=14)\n",
    "\n",
    "for i in range(8):\n",
    "    # Original (from baseline)\n",
    "    img_orig = baseline_images[i] * FASHION_STD + FASHION_MEAN\n",
    "    img_orig = np.clip(img_orig, 0, 1).squeeze()\n",
    "    axes[0, i].imshow(img_orig, cmap=\"gray\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "    axes[0, i].set_title(FASHION_CLASSES[baseline_labels[i]], fontsize=8)\n",
    "\n",
    "    # Augmented\n",
    "    img_aug = full_images[i] * FASHION_STD + FASHION_MEAN\n",
    "    img_aug = np.clip(img_aug, 0, 1).squeeze()\n",
    "    axes[1, i].imshow(img_aug, cmap=\"gray\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Original\", fontsize=10)\n",
    "axes[1, 0].set_ylabel(\"Augmented\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"cv-fashion-augmented.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\"\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'cv-fashion-augmented.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample grid from augmented pipeline\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "fig.suptitle(\"Fashion-MNIST Training Samples (with augmentation)\", fontsize=14)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(full_images):\n",
    "        img = full_images[i] * FASHION_STD + FASHION_MEAN\n",
    "        img = np.clip(img, 0, 1).squeeze()\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        ax.set_title(FASHION_CLASSES[full_labels[i]], fontsize=7)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"cv-fashion-samples.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'cv-fashion-samples.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "| Augmentation | Parameter | Latency |\n",
    "|--------------|-----------|---------|\n",
    "| Brightness | ±0.15 | ~2 ms |\n",
    "| Contrast | 0.85-1.15x | ~2 ms |\n",
    "| Rotation | ±10° | ~5 ms |\n",
    "| Noise | std=0.1 | ~3 ms |\n",
    "| PatchDropout | 2×6×6 | ~3 ms |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Order matters**: Apply geometric transforms (rotation) before pixel transforms\n",
    "2. **Lighter when stacking**: Reduce individual strengths when combining\n",
    "3. **PatchDropout**: Forces model to use global features, improves robustness\n",
    "4. **Noise**: Helps with sensor noise and compression artifacts\n",
    "5. **Profile**: Measure latency impact for your specific hardware\n",
    "\n",
    "### Recommended Pipeline Order\n",
    "\n",
    "```\n",
    "Source -> Preprocess -> Rotation -> Brightness -> Contrast -> Noise -> Dropout\n",
    "```\n",
    "\n",
    "Geometric transforms first, then photometric, then regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- **MixUp/CutMix**: See advanced/augmentation for batch-level augmentation\n",
    "- **Performance**: [Optimization guide](../advanced/performance/01_optimization_guide.ipynb)\n",
    "- **Full training**: [End-to-end CIFAR-10](../advanced/training/01_e2e_cifar10_guide.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the Fashion-MNIST augmentation tutorial.\"\"\"\n",
    "    print(\"Fashion-MNIST Augmentation Pipeline Tutorial\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = create_full_augmentation_pipeline(seed=42)\n",
    "\n",
    "    # Process batches\n",
    "    total_samples = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, batch in enumerate(pipeline):\n",
    "        total_samples += batch[\"image\"].shape[0]\n",
    "        if i >= 10:\n",
    "            break\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f\"Processed {total_samples} augmented samples\")\n",
    "    print(f\"Throughput: {total_samples / elapsed:.0f} samples/s\")\n",
    "    print(\"Augmentations: Brightness, Contrast, Rotation, Noise, PatchDropout\")\n",
    "    print(\"Tutorial completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
