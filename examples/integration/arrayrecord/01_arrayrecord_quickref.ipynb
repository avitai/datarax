{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# ArrayRecord Source Quick Reference\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Intermediate |\n",
    "| **Runtime** | ~15 min |\n",
    "| **Prerequisites** | Simple Pipeline |\n",
    "| **Format** | Python + Jupyter |\n",
    "\n",
    "## Overview\n",
    "\n",
    "Learn to use `ArrayRecordSourceModule` for loading data from Google's\n",
    "ArrayRecord format. ArrayRecord is a high-performance file format used\n",
    "by Google for ML datasets, similar to TFRecord but with better random access.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this quick reference, you will be able to:\n",
    "\n",
    "1. Configure `ArrayRecordSourceConfig` for ArrayRecord files\n",
    "2. Create an `ArrayRecordSourceModule` from file paths\n",
    "3. Integrate ArrayRecord sources into Datarax pipelines\n",
    "4. Understand checkpointing and state management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Coming from Google Grain?\n",
    "\n",
    "| Grain | Datarax |\n",
    "|-------|---------|\n",
    "| `grain.ArrayRecordDataSource(paths)` | `ArrayRecordSourceModule(config, paths)` |\n",
    "| `grain.DataLoader(source)` | `from_source(source)` |\n",
    "| Manual iteration | Automatic stateful iteration |\n",
    "| Manual checkpointing | Built-in `get_state()` / `set_state()` |\n",
    "\n",
    "## Key Differences\n",
    "\n",
    "1. **Stateful Iteration**: Datarax tracks position automatically via NNX Variables\n",
    "2. **Checkpointing**: Built-in state serialization for resume\n",
    "3. **Pipeline Integration**: Direct integration with DAG-based pipelines\n",
    "4. **Shuffling**: Internal shuffle handling per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup\n",
    "\n",
    "ArrayRecord requires the `array_record` package (Google's format):\n",
    "\n",
    "```bash\n",
    "uv pip install \"datarax[data]\" array-record\n",
    "```\n",
    "\n",
    "Note: ArrayRecord is primarily available on Linux. Check compatibility for your platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Note: These imports would be used with actual ArrayRecord files:\n",
    "# import numpy as np\n",
    "# from flax import nnx\n",
    "# from datarax import from_source\n",
    "# from datarax.sources import ArrayRecordSourceModule, ArrayRecordSourceConfig\n",
    "\n",
    "print(\"ArrayRecord Source Quick Reference\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 1: ArrayRecordSourceConfig\n",
    "\n",
    "Configuration for ArrayRecord data sources.\n",
    "\n",
    "### Configuration Options\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `seed` | int | 42 | Random seed for shuffling |\n",
    "| `num_epochs` | int | -1 | Number of epochs (-1 for infinite) |\n",
    "| `shuffle_files` | bool | False | Whether to shuffle file order |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration example (conceptual - actual usage requires ArrayRecord files)\n",
    "print(\"ArrayRecordSourceConfig Parameters:\")\n",
    "print()\n",
    "print(\"  seed: int = 42\")\n",
    "print(\"    - Random seed for epoch-based shuffling\")\n",
    "print()\n",
    "print(\"  num_epochs: int = -1\")\n",
    "print(\"    - Number of epochs to iterate\")\n",
    "print(\"    - -1 means infinite iteration\")\n",
    "print()\n",
    "print(\"  shuffle_files: bool = False\")\n",
    "print(\"    - Whether to shuffle record order within epoch\")\n",
    "print(\"    - Re-shuffles at each epoch boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 2: Creating an ArrayRecord Source\n",
    "\n",
    "### Basic Usage Pattern\n",
    "\n",
    "```python\n",
    "from datarax.sources import ArrayRecordSourceModule, ArrayRecordSourceConfig\n",
    "\n",
    "# Single file\n",
    "source = ArrayRecordSourceModule(\n",
    "    ArrayRecordSourceConfig(seed=42),\n",
    "    paths=\"/path/to/data.riegeli\",\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "\n",
    "# Multiple files with glob pattern\n",
    "source = ArrayRecordSourceModule(\n",
    "    ArrayRecordSourceConfig(seed=42, shuffle_files=True),\n",
    "    paths=\"/path/to/data-*.riegeli\",\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "\n",
    "# List of specific files\n",
    "source = ArrayRecordSourceModule(\n",
    "    ArrayRecordSourceConfig(num_epochs=10),\n",
    "    paths=[\n",
    "        \"/path/to/train-00000.riegeli\",\n",
    "        \"/path/to/train-00001.riegeli\",\n",
    "    ],\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Creating ArrayRecordSourceModule:\")\n",
    "print()\n",
    "print(\"  # Path options:\")\n",
    "print('  paths = \"/path/to/data.riegeli\"          # Single file')\n",
    "print('  paths = \"/path/to/data-*.riegeli\"        # Glob pattern')\n",
    "print('  paths = [\"file1.riegeli\", \"file2.riegeli\"]  # List')\n",
    "print()\n",
    "print(\"  # Initialization:\")\n",
    "print(\"  source = ArrayRecordSourceModule(\")\n",
    "print(\"      ArrayRecordSourceConfig(seed=42),\")\n",
    "print(\"      paths=paths,\")\n",
    "print(\"      rngs=nnx.Rngs(0),\")\n",
    "print(\"  )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 3: Pipeline Integration\n",
    "\n",
    "### Using with Datarax Pipelines\n",
    "\n",
    "```python\n",
    "from datarax import from_source\n",
    "from datarax.dag.nodes import OperatorNode\n",
    "\n",
    "# Create pipeline from ArrayRecord source\n",
    "pipeline = from_source(source, batch_size=32)\n",
    "\n",
    "# Add transformations\n",
    "pipeline = pipeline.add(OperatorNode(normalize_op))\n",
    "\n",
    "# Iterate\n",
    "for batch in pipeline:\n",
    "    # Process batch\n",
    "    print(f\"Batch shape: {batch['data'].shape}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Pipeline Integration Pattern:\")\n",
    "print()\n",
    "print(\"  # Create pipeline\")\n",
    "print(\"  pipeline = from_source(source, batch_size=32)\")\n",
    "print()\n",
    "print(\"  # Add operators\")\n",
    "print(\"  pipeline = pipeline.add(OperatorNode(my_operator))\")\n",
    "print()\n",
    "print(\"  # Iterate\")\n",
    "print(\"  for batch in pipeline:\")\n",
    "print(\"      train_step(batch)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 4: Checkpointing and State Management\n",
    "\n",
    "ArrayRecordSourceModule supports full state serialization for training resume.\n",
    "\n",
    "### State Contents\n",
    "\n",
    "| State Key | Description |\n",
    "|-----------|-------------|\n",
    "| `current_index` | Current position in dataset |\n",
    "| `current_epoch` | Current epoch number |\n",
    "| `shuffled_indices` | Shuffle order (if enabled) |\n",
    "| `prefetch_cache` | Prefetched records cache |\n",
    "\n",
    "### Checkpointing Pattern\n",
    "\n",
    "```python\n",
    "# Save checkpoint\n",
    "state = source.get_state()\n",
    "# state = {\"current_index\": 1234, \"current_epoch\": 5, ...}\n",
    "\n",
    "# Later: restore from checkpoint\n",
    "source.set_state(state)\n",
    "# Resumes from exact position\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Checkpointing API:\")\n",
    "print()\n",
    "print(\"  # Save state\")\n",
    "print(\"  checkpoint = {\")\n",
    "print('      \"source_state\": source.get_state(),')\n",
    "print('      \"model_params\": model.params,')\n",
    "print(\"  }\")\n",
    "print()\n",
    "print(\"  # Restore state\")\n",
    "print('  source.set_state(checkpoint[\"source_state\"])')\n",
    "print(\"  # Iteration resumes from saved position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 5: Epoch Control\n",
    "\n",
    "### Finite Epochs\n",
    "\n",
    "```python\n",
    "# Run for exactly 10 epochs\n",
    "config = ArrayRecordSourceConfig(num_epochs=10)\n",
    "source = ArrayRecordSourceModule(config, paths=paths, rngs=nnx.Rngs(0))\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch in from_source(source, batch_size=32):\n",
    "        train_step(batch)\n",
    "# Automatically stops after 10 epochs\n",
    "```\n",
    "\n",
    "### Infinite Iteration\n",
    "\n",
    "```python\n",
    "# Run indefinitely (for step-based training)\n",
    "config = ArrayRecordSourceConfig(num_epochs=-1)\n",
    "source = ArrayRecordSourceModule(config, paths=paths, rngs=nnx.Rngs(0))\n",
    "\n",
    "step = 0\n",
    "for batch in from_source(source, batch_size=32):\n",
    "    train_step(batch)\n",
    "    step += 1\n",
    "    if step >= max_steps:\n",
    "        break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Epoch Control:\")\n",
    "print()\n",
    "print(\"  # Finite epochs\")\n",
    "print(\"  config = ArrayRecordSourceConfig(num_epochs=10)\")\n",
    "print(\"  # Stops automatically after 10 epochs\")\n",
    "print()\n",
    "print(\"  # Infinite iteration (step-based)\")\n",
    "print(\"  config = ArrayRecordSourceConfig(num_epochs=-1)\")\n",
    "print(\"  # Use break/max_steps for control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 6: Shuffling Behavior\n",
    "\n",
    "### Per-Epoch Reshuffling\n",
    "\n",
    "When `shuffle_files=True`:\n",
    "\n",
    "1. At initialization, indices are shuffled using `seed`\n",
    "2. At each epoch boundary, indices are reshuffled using `seed + epoch`\n",
    "3. This ensures reproducible but varied order across epochs\n",
    "\n",
    "```python\n",
    "# Enable shuffling with reproducible seed\n",
    "config = ArrayRecordSourceConfig(\n",
    "    seed=42,\n",
    "    shuffle_files=True,\n",
    ")\n",
    "# Epoch 0: shuffled with seed=42\n",
    "# Epoch 1: reshuffled with seed=43\n",
    "# Epoch 2: reshuffled with seed=44\n",
    "# ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Shuffling Behavior:\")\n",
    "print()\n",
    "print(\"  shuffle_files=True:\")\n",
    "print(\"    - Initial shuffle: seed=42\")\n",
    "print(\"    - Epoch 1 reshuffle: seed=43\")\n",
    "print(\"    - Epoch 2 reshuffle: seed=44\")\n",
    "print(\"    - Ensures varied but reproducible order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "### ArrayRecordSourceModule Features\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Stateful** | Tracks position via NNX Variables |\n",
    "| **Checkpointing** | Full `get_state()` / `set_state()` |\n",
    "| **Shuffling** | Per-epoch reshuffling with seed control |\n",
    "| **Epoch Control** | Finite or infinite iteration |\n",
    "| **Grain Compatible** | Wraps Grain's ArrayRecordDataSource |\n",
    "\n",
    "### When to Use ArrayRecord\n",
    "\n",
    "- Large datasets (>10GB)\n",
    "- Need random access to records\n",
    "- Working with Google's ML infrastructure\n",
    "- Migrating from TFRecord to a modern format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- [HuggingFace Tutorial](../huggingface/hf-tutorial.ipynb) - Alternative data source\n",
    "- [TFDS Quick Reference](../tfds/tfds-quickref.ipynb) - TensorFlow Datasets\n",
    "- [Checkpointing Guide](../../advanced/checkpointing/checkpoint-quickref.ipynb) - Full checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the ArrayRecord quick reference.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ArrayRecord Source Quick Reference\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print()\n",
    "    print(\"This quick reference demonstrates the ArrayRecordSourceModule API.\")\n",
    "    print(\"Actual usage requires ArrayRecord files (*.riegeli format).\")\n",
    "\n",
    "    print()\n",
    "    print(\"Key API Summary:\")\n",
    "    print()\n",
    "    print(\"  1. Configuration:\")\n",
    "    print(\"     config = ArrayRecordSourceConfig(\")\n",
    "    print(\"         seed=42,\")\n",
    "    print(\"         num_epochs=-1,\")\n",
    "    print(\"         shuffle_files=True,\")\n",
    "    print(\"     )\")\n",
    "    print()\n",
    "    print(\"  2. Source Creation:\")\n",
    "    print(\"     source = ArrayRecordSourceModule(\")\n",
    "    print(\"         config,\")\n",
    "    print('         paths=\"/path/to/*.riegeli\",')\n",
    "    print(\"         rngs=nnx.Rngs(0),\")\n",
    "    print(\"     )\")\n",
    "    print()\n",
    "    print(\"  3. Pipeline Integration:\")\n",
    "    print(\"     pipeline = from_source(source, batch_size=32)\")\n",
    "    print()\n",
    "    print(\"  4. Checkpointing:\")\n",
    "    print(\"     state = source.get_state()\")\n",
    "    print(\"     source.set_state(state)\")\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Quick reference completed!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
