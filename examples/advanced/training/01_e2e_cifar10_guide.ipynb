{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# End-to-End CIFAR-10 Training Guide\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Advanced |\n",
    "| **Runtime** | ~60 min (CPU) / ~15 min (GPU) |\n",
    "| **Prerequisites** | MNIST Tutorial, Augmentation tutorials |\n",
    "| **Format** | Python + Jupyter |\n",
    "| **Memory** | ~2 GB RAM |\n",
    "\n",
    "## Overview\n",
    "\n",
    "Build a complete, production-ready training pipeline for CIFAR-10 image\n",
    "classification. This guide integrates all Datarax features: data loading,\n",
    "augmentation, batch mixing, and metrics collection with a Flax NNX model.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this guide, you will be able to:\n",
    "\n",
    "1. Design complete training and validation pipelines\n",
    "2. Implement a CNN with Flax NNX from scratch\n",
    "3. Use MixUp augmentation for improved generalization\n",
    "4. Track training metrics and generate visualizations\n",
    "5. Evaluate model performance with confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "uv pip install \"datarax[tfds]\" flax optax matplotlib seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Memory Configuration\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES_FOR_TF\"] = \"\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "# Core imports\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "# Datarax imports\n",
    "from datarax import from_source\n",
    "from datarax.core.config import BatchMixOperatorConfig\n",
    "from datarax.dag.nodes import OperatorNode\n",
    "from datarax.operators import ElementOperator, ElementOperatorConfig\n",
    "from datarax.operators.batch_mix_operator import BatchMixOperator\n",
    "from datarax.operators.modality.image import (\n",
    "    BrightnessOperator,\n",
    "    BrightnessOperatorConfig,\n",
    "    ContrastOperator,\n",
    "    ContrastOperatorConfig,\n",
    "    NoiseOperator,\n",
    "    NoiseOperatorConfig,\n",
    ")\n",
    "from datarax.sources import TFDSEagerConfig, TFDSEagerSource\n",
    "\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Configuration\n",
    "\n",
    "All hyperparameters in one place for easy tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "CIFAR10_CLASSES = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "NUM_CLASSES = 10\n",
    "IMAGE_SHAPE = (32, 32, 3)\n",
    "\n",
    "# Normalization\n",
    "CIFAR10_MEAN = jnp.array([0.4914, 0.4822, 0.4465])\n",
    "CIFAR10_STD = jnp.array([0.2470, 0.2435, 0.2616])\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_EPOCHS = 5  # Reduced for demo\n",
    "TRAIN_SAMPLES = 5000  # Subset for faster demo\n",
    "TEST_SAMPLES = 1000\n",
    "\n",
    "# Augmentation\n",
    "USE_MIXUP = True\n",
    "MIXUP_ALPHA = 0.2\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Weight decay: {WEIGHT_DECAY}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  MixUp: {USE_MIXUP} (alpha={MIXUP_ALPHA})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 1: Data Pipeline\n",
    "\n",
    "### Training Pipeline (with augmentation)\n",
    "- Standard CIFAR-10 normalization\n",
    "- Random brightness/contrast\n",
    "- Light Gaussian noise\n",
    "- MixUp for regularization\n",
    "\n",
    "### Validation Pipeline (no augmentation)\n",
    "- Normalization only\n",
    "- Hard labels for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train(element, key=None):  # noqa: ARG001\n",
    "    \"\"\"Preprocess for training with one-hot labels for MixUp.\"\"\"\n",
    "    del key\n",
    "    image = element.data[\"image\"]\n",
    "\n",
    "    # Normalize\n",
    "    image = image.astype(jnp.float32) / 255.0\n",
    "    image = (image - CIFAR10_MEAN) / CIFAR10_STD\n",
    "\n",
    "    # One-hot labels for MixUp\n",
    "    label = element.data[\"label\"]\n",
    "    label_onehot = jnp.eye(NUM_CLASSES, dtype=jnp.float32)[label]\n",
    "\n",
    "    return element.update_data(\n",
    "        {\n",
    "            \"image\": image,\n",
    "            \"label\": label_onehot,\n",
    "            \"label_idx\": label,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess_val(element, key=None):  # noqa: ARG001\n",
    "    \"\"\"Preprocess for validation with integer labels.\"\"\"\n",
    "    del key\n",
    "    image = element.data[\"image\"]\n",
    "\n",
    "    # Normalize\n",
    "    image = image.astype(jnp.float32) / 255.0\n",
    "    image = (image - CIFAR10_MEAN) / CIFAR10_STD\n",
    "\n",
    "    return element.update_data(\n",
    "        {\n",
    "            \"image\": image,\n",
    "            \"label\": element.data[\"label\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Preprocessing functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_pipeline(seed=42):\n",
    "    \"\"\"Create training pipeline with augmentation.\"\"\"\n",
    "    # Source\n",
    "    source = TFDSEagerSource(\n",
    "        TFDSEagerConfig(\n",
    "            name=\"cifar10\",\n",
    "            split=f\"train[:{TRAIN_SAMPLES}]\",\n",
    "            shuffle=True,\n",
    "            seed=seed,\n",
    "            exclude_keys={\"id\"},\n",
    "        ),\n",
    "        rngs=nnx.Rngs(seed),\n",
    "    )\n",
    "\n",
    "    # Preprocessor\n",
    "    prep = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=preprocess_train,\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    # Augmentation operators\n",
    "    brightness = BrightnessOperator(\n",
    "        BrightnessOperatorConfig(\n",
    "            field_key=\"image\",\n",
    "            brightness_range=(-0.1, 0.1),\n",
    "            stochastic=True,\n",
    "            stream_name=\"brightness\",\n",
    "        ),\n",
    "        rngs=nnx.Rngs(brightness=seed + 100),\n",
    "    )\n",
    "\n",
    "    contrast = ContrastOperator(\n",
    "        ContrastOperatorConfig(\n",
    "            field_key=\"image\",\n",
    "            contrast_range=(0.9, 1.1),\n",
    "            stochastic=True,\n",
    "            stream_name=\"contrast\",\n",
    "        ),\n",
    "        rngs=nnx.Rngs(contrast=seed + 200),\n",
    "    )\n",
    "\n",
    "    noise = NoiseOperator(\n",
    "        NoiseOperatorConfig(\n",
    "            field_key=\"image\",\n",
    "            mode=\"gaussian\",\n",
    "            noise_std=0.05,\n",
    "            stochastic=True,\n",
    "            stream_name=\"noise\",\n",
    "        ),\n",
    "        rngs=nnx.Rngs(noise=seed + 300),\n",
    "    )\n",
    "\n",
    "    # Build pipeline\n",
    "    pipeline = (\n",
    "        from_source(source, batch_size=BATCH_SIZE)\n",
    "        .add(OperatorNode(prep))\n",
    "        .add(OperatorNode(brightness))\n",
    "        .add(OperatorNode(contrast))\n",
    "        .add(OperatorNode(noise))\n",
    "    )\n",
    "\n",
    "    # Add MixUp if enabled\n",
    "    if USE_MIXUP:\n",
    "        mixup = BatchMixOperator(\n",
    "            BatchMixOperatorConfig(\n",
    "                mode=\"mixup\",\n",
    "                alpha=MIXUP_ALPHA,\n",
    "                data_field=\"image\",\n",
    "                label_field=\"label\",\n",
    "                stochastic=True,\n",
    "                stream_name=\"mixup\",\n",
    "            ),\n",
    "            rngs=nnx.Rngs(mixup=seed + 400),\n",
    "        )\n",
    "        pipeline = pipeline.add(OperatorNode(mixup))\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def create_val_pipeline():\n",
    "    \"\"\"Create validation pipeline (no augmentation).\"\"\"\n",
    "    source = TFDSEagerSource(\n",
    "        TFDSEagerConfig(\n",
    "            name=\"cifar10\",\n",
    "            split=f\"test[:{TEST_SAMPLES}]\",\n",
    "            shuffle=False,\n",
    "            exclude_keys={\"id\"},\n",
    "        ),\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    prep = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=preprocess_val,\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    return from_source(source, batch_size=BATCH_SIZE).add(OperatorNode(prep))\n",
    "\n",
    "\n",
    "print(\"Pipeline factories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 2: Model Architecture\n",
    "\n",
    "A ResNet-inspired CNN for CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nnx.Module):\n",
    "    \"\"\"Basic residual block with skip connection.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int, rngs: nnx.Rngs):\n",
    "        self.conv1 = nnx.Conv(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(stride, stride),\n",
    "            padding=\"SAME\",\n",
    "            rngs=rngs,\n",
    "        )\n",
    "        self.bn1 = nnx.BatchNorm(out_channels, rngs=rngs)\n",
    "        self.conv2 = nnx.Conv(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=\"SAME\",\n",
    "            rngs=rngs,\n",
    "        )\n",
    "        self.bn2 = nnx.BatchNorm(out_channels, rngs=rngs)\n",
    "\n",
    "        # Skip connection\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nnx.Conv(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(1, 1),\n",
    "                strides=(stride, stride),\n",
    "                padding=\"SAME\",\n",
    "                rngs=rngs,\n",
    "            )\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = nnx.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.skip is not None:\n",
    "            identity = self.skip(identity)\n",
    "\n",
    "        out = out + identity\n",
    "        out = nnx.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CIFAR10Net(nnx.Module):\n",
    "    \"\"\"ResNet-inspired network for CIFAR-10.\"\"\"\n",
    "\n",
    "    def __init__(self, rngs: nnx.Rngs):\n",
    "        # Initial convolution\n",
    "        self.conv1 = nnx.Conv(3, 32, kernel_size=(3, 3), padding=\"SAME\", rngs=rngs)\n",
    "        self.bn1 = nnx.BatchNorm(32, rngs=rngs)\n",
    "\n",
    "        # Residual blocks\n",
    "        self.block1 = ResidualBlock(32, 32, stride=1, rngs=rngs)\n",
    "        self.block2 = ResidualBlock(32, 64, stride=2, rngs=rngs)  # 16x16\n",
    "        self.block3 = ResidualBlock(64, 64, stride=1, rngs=rngs)\n",
    "        self.block4 = ResidualBlock(64, 128, stride=2, rngs=rngs)  # 8x8\n",
    "\n",
    "        # Classification head\n",
    "        self.fc = nnx.Linear(128, NUM_CLASSES, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Initial\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nnx.relu(x)\n",
    "\n",
    "        # Residual blocks\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "\n",
    "        # Global average pooling\n",
    "        x = jnp.mean(x, axis=(1, 2))\n",
    "\n",
    "        # Classification\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = CIFAR10Net(rngs=nnx.Rngs(0))\n",
    "\n",
    "# Test forward pass\n",
    "test_input = jnp.ones((2, 32, 32, 3))\n",
    "test_output = model(test_input)\n",
    "print(f\"Model output shape: {test_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 3: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer with weight decay\n",
    "# wrt=nnx.Param tells the optimizer to update all Param variables\n",
    "optimizer = nnx.Optimizer(\n",
    "    model,\n",
    "    optax.adamw(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY),\n",
    "    wrt=nnx.Param,\n",
    ")\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: CIFAR10Net, optimizer: nnx.Optimizer, images: jax.Array, labels: jax.Array):\n",
    "    \"\"\"Single training step with soft labels.\"\"\"\n",
    "\n",
    "    def loss_fn(model):\n",
    "        logits = model(images)\n",
    "        # Soft cross-entropy for MixUp\n",
    "        loss = -jnp.sum(labels * jax.nn.log_softmax(logits), axis=-1).mean()\n",
    "        return loss\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "    optimizer.update(model, grads)\n",
    "\n",
    "    # Compute accuracy (argmax of soft labels)\n",
    "    logits = model(images)\n",
    "    predictions = jnp.argmax(logits, axis=-1)\n",
    "    targets = jnp.argmax(labels, axis=-1)\n",
    "    accuracy = (predictions == targets).mean()\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model: CIFAR10Net, images: jax.Array, labels: jax.Array):\n",
    "    \"\"\"Single evaluation step with hard labels.\"\"\"\n",
    "    logits = model(images)\n",
    "    predictions = jnp.argmax(logits, axis=-1)\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, labels).mean()\n",
    "    return loss, accuracy, predictions\n",
    "\n",
    "\n",
    "print(\"Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics storage\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "epoch_times = []\n",
    "throughputs = []\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING CIFAR-10\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    # Training phase\n",
    "    train_pipeline = create_train_pipeline(seed=epoch)\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    samples_processed = 0\n",
    "\n",
    "    for batch in train_pipeline:\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        loss, acc = train_step(model, optimizer, images, labels)\n",
    "\n",
    "        epoch_losses.append(float(loss))\n",
    "        epoch_accs.append(float(acc))\n",
    "        samples_processed += images.shape[0]\n",
    "\n",
    "    train_loss = np.mean(epoch_losses)\n",
    "    train_acc = np.mean(epoch_accs)\n",
    "    train_losses.extend(epoch_losses)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # Validation phase\n",
    "    val_pipeline = create_val_pipeline()\n",
    "    val_losses_epoch = []\n",
    "    val_accs_epoch = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in val_pipeline:\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        loss, acc, preds = eval_step(model, images, labels)\n",
    "\n",
    "        val_losses_epoch.append(float(loss))\n",
    "        val_accs_epoch.append(float(acc))\n",
    "        all_predictions.extend(preds.tolist())\n",
    "        all_labels.extend(labels.tolist())\n",
    "\n",
    "    val_loss = np.mean(val_losses_epoch)\n",
    "    val_acc = np.mean(val_accs_epoch)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    # Timing\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_times.append(epoch_time)\n",
    "    throughput = samples_processed / epoch_time\n",
    "    throughputs.append(throughput)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2%}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2%}\")\n",
    "    print(f\"  Time: {epoch_time:.1f}s, Throughput: {throughput:.0f} samples/s\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 4: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"docs/assets/images/examples\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1. Training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0]\n",
    "ax1.plot(train_losses, alpha=0.3, color=\"blue\", label=\"_nolegend_\")\n",
    "# Smoothed\n",
    "window = max(5, len(train_losses) // 20)\n",
    "smoothed = np.convolve(train_losses, np.ones(window) / window, mode=\"valid\")\n",
    "ax1.plot(range(window - 1, len(train_losses)), smoothed, color=\"blue\", linewidth=2, label=\"Train\")\n",
    "# Validation (per epoch)\n",
    "epochs_x = [(i + 1) * (len(train_losses) // NUM_EPOCHS) for i in range(NUM_EPOCHS)]\n",
    "ax1.plot(epochs_x, val_losses, \"o-\", color=\"orange\", linewidth=2, markersize=8, label=\"Val\")\n",
    "ax1.set_xlabel(\"Batch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Training and Validation Loss\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2 = axes[1]\n",
    "epochs = list(range(1, NUM_EPOCHS + 1))\n",
    "ax2.plot(epochs, train_accs, \"o-\", color=\"blue\", linewidth=2, markersize=8, label=\"Train\")\n",
    "ax2.plot(epochs, val_accs, \"o-\", color=\"orange\", linewidth=2, markersize=8, label=\"Val\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.set_title(\"Training and Validation Accuracy\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"e2e-training-curves.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'e2e-training-curves.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Confusion matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion = np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=np.int32)\n",
    "for pred, true in zip(all_predictions, all_labels):\n",
    "    confusion[true, pred] += 1\n",
    "\n",
    "# Normalize by row (recall)\n",
    "confusion_norm = confusion.astype(np.float32) / confusion.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(confusion_norm, cmap=\"Blues\")\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(NUM_CLASSES):\n",
    "    for j in range(NUM_CLASSES):\n",
    "        val = confusion_norm[i, j]\n",
    "        color = \"white\" if val > 0.5 else \"black\"\n",
    "        ax.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\", color=color, fontsize=8)\n",
    "\n",
    "ax.set_xticks(range(NUM_CLASSES))\n",
    "ax.set_yticks(range(NUM_CLASSES))\n",
    "ax.set_xticklabels(CIFAR10_CLASSES, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(CIFAR10_CLASSES)\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "ax.set_title(\"Confusion Matrix (Normalized)\")\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"e2e-confusion-matrix.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\"\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'e2e-confusion-matrix.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Per-class accuracy\n",
    "per_class_acc = confusion.diagonal() / confusion.sum(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, NUM_CLASSES))\n",
    "bars = ax.bar(CIFAR10_CLASSES, per_class_acc, color=colors)\n",
    "ax.set_xlabel(\"Class\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Per-Class Accuracy\")\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, per_class_acc):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, val + 0.02, f\"{val:.2%}\", ha=\"center\", fontsize=9)\n",
    "\n",
    "ax.axhline(y=val_accs[-1], color=\"red\", linestyle=\"--\", label=f\"Mean: {val_accs[-1]:.2%}\")\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"e2e-per-class-accuracy.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\"\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'e2e-per-class-accuracy.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Throughput during training\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(range(1, NUM_EPOCHS + 1), throughputs, color=\"steelblue\")\n",
    "ax.axhline(\n",
    "    y=np.mean(throughputs),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {np.mean(throughputs):.0f} samples/s\",\n",
    ")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Throughput (samples/second)\")\n",
    "ax.set_title(\"Training Throughput per Epoch\")\n",
    "ax.legend()\n",
    "\n",
    "for i, tp in enumerate(throughputs):\n",
    "    ax.text(i + 1, tp + 50, f\"{tp:.0f}\", ha=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"e2e-throughput-during-training.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'e2e-throughput-during-training.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Final Train Accuracy | ~{train_accs[-1]:.1%} |\n",
    "| Final Val Accuracy | ~{val_accs[-1]:.1%} |\n",
    "| Mean Throughput | ~{np.mean(throughputs):.0f} samples/s |\n",
    "| Total Training Time | ~{sum(epoch_times):.0f}s |\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "```\n",
    "CIFAR10Net:\n",
    "├── Conv3x3(3→32) + BN + ReLU\n",
    "├── ResBlock(32→32)\n",
    "├── ResBlock(32→64, stride=2)  # 16x16\n",
    "├── ResBlock(64→64)\n",
    "├── ResBlock(64→128, stride=2)  # 8x8\n",
    "├── GlobalAvgPool\n",
    "└── FC(128→10)\n",
    "```\n",
    "\n",
    "### Pipeline Architecture\n",
    "\n",
    "```\n",
    "Training:\n",
    "TFDSEagerSource → Preprocess → Brightness → Contrast → Noise → MixUp → Model\n",
    "\n",
    "Validation:\n",
    "TFDSEagerSource → Preprocess → Model\n",
    "```\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Separate pipelines**: Train with augmentation, validate without\n",
    "2. **MixUp**: Creates soft labels, requires adapted loss function\n",
    "3. **BatchNorm**: Use in eval mode for validation\n",
    "4. **Fresh pipelines**: Create new pipeline each epoch for shuffling\n",
    "5. **Throughput tracking**: Monitor for optimization opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Improve accuracy**: Add more augmentations, train longer\n",
    "- **Distributed**: [Sharding guide](../distributed/02_sharding_guide.ipynb)\n",
    "- **Checkpointing**: [Resumable training](../checkpointing/02_resumable_training_guide.ipynb)\n",
    "- **Performance**: [Optimization guide](../performance/01_optimization_guide.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the end-to-end CIFAR-10 guide.\"\"\"\n",
    "    print(\"End-to-End CIFAR-10 Training Guide\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Quick training demo\n",
    "    model = CIFAR10Net(rngs=nnx.Rngs(0))\n",
    "    optimizer = nnx.Optimizer(model, optax.adam(1e-3), wrt=nnx.Param)\n",
    "\n",
    "    # Train one epoch\n",
    "    pipeline = create_train_pipeline(seed=0)\n",
    "    for i, batch in enumerate(pipeline):\n",
    "        if i >= 20:\n",
    "            break\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "        _, _ = train_step(model, optimizer, images, labels)\n",
    "\n",
    "    # Validate\n",
    "    val_pipeline = create_val_pipeline()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in val_pipeline:\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "        _, acc, _ = eval_step(model, images, labels)\n",
    "        correct += int(acc * len(labels))\n",
    "        total += len(labels)\n",
    "\n",
    "    print(f\"Validation accuracy after quick training: {correct / total:.2%}\")\n",
    "    print(\"Guide completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
