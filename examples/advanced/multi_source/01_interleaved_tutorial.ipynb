{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Multi-Source Data Loading Tutorial\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Intermediate |\n",
    "| **Runtime** | ~20 min |\n",
    "| **Prerequisites** | Pipeline Tutorial, TFDS Quick Reference |\n",
    "| **Format** | Python + Jupyter |\n",
    "| **Memory** | ~1.5 GB RAM |\n",
    "\n",
    "## Overview\n",
    "\n",
    "Learn to load and combine data from multiple sources in a single pipeline.\n",
    "This is essential for multi-task learning, domain adaptation, and creating\n",
    "diverse training sets from heterogeneous data.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. Create multiple TFDSEagerSource instances\n",
    "2. Interleave data from different datasets\n",
    "3. Apply source-specific preprocessing\n",
    "4. Handle different data formats in the same pipeline\n",
    "5. Visualize mixed dataset samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "uv pip install \"datarax[tfds]\" matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Memory Configuration\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES_FOR_TF\"] = \"\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "# Core imports\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "\n",
    "# Datarax imports\n",
    "from datarax import from_source\n",
    "from datarax.dag.nodes import OperatorNode\n",
    "from datarax.operators import ElementOperator, ElementOperatorConfig\n",
    "from datarax.sources import TFDSEagerConfig, TFDSEagerSource\n",
    "\n",
    "print(f\"JAX backend: {jax.default_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Use Case: Multi-Domain Digit Recognition\n",
    "\n",
    "We'll combine MNIST and Fashion-MNIST to create a unified digit/fashion\n",
    "classification dataset. This simulates scenarios like:\n",
    "\n",
    "- Domain adaptation (source → target domain)\n",
    "- Multi-task learning\n",
    "- Creating diverse training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 1: Create Individual Sources\n",
    "\n",
    "Each source has its own configuration, preprocessing, and sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Source - 10 digit classes (0-9)\n",
    "mnist_config = TFDSEagerConfig(\n",
    "    name=\"mnist\",\n",
    "    split=\"train[:2000]\",  # Subset for demo\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "mnist_source = TFDSEagerSource(mnist_config, rngs=nnx.Rngs(42))\n",
    "\n",
    "# Fashion-MNIST Source - 10 fashion classes\n",
    "fashion_config = TFDSEagerConfig(\n",
    "    name=\"fashion_mnist\",\n",
    "    split=\"train[:2000]\",\n",
    "    shuffle=True,\n",
    "    seed=43,\n",
    ")\n",
    "\n",
    "fashion_source = TFDSEagerSource(fashion_config, rngs=nnx.Rngs(43))\n",
    "\n",
    "print(f\"MNIST samples: {len(mnist_source)}\")\n",
    "print(f\"Fashion-MNIST samples: {len(fashion_source)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Dataset Properties\n",
    "\n",
    "| Dataset | Classes | Image Size | Task |\n",
    "|---------|---------|------------|------|\n",
    "| MNIST | 10 digits (0-9) | 28×28×1 | Digit recognition |\n",
    "| Fashion-MNIST | 10 items | 28×28×1 | Fashion classification |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels\n",
    "MNIST_CLASSES = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "FASHION_CLASSES = [\n",
    "    \"T-shirt\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Boot\",\n",
    "]\n",
    "\n",
    "# Normalization constants\n",
    "MNIST_MEAN, MNIST_STD = 0.1307, 0.3081\n",
    "FASHION_MEAN, FASHION_STD = 0.2860, 0.3530\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 2: Source-Specific Preprocessing\n",
    "\n",
    "Each source may need different preprocessing. We'll add a \"source\" tag\n",
    "to track where each sample came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist(element, key=None):  # noqa: ARG001\n",
    "    \"\"\"Preprocess MNIST with source tag.\"\"\"\n",
    "    del key\n",
    "    image = element.data[\"image\"]\n",
    "\n",
    "    # Normalize\n",
    "    image = image.astype(jnp.float32) / 255.0\n",
    "    if image.ndim == 2:\n",
    "        image = image[..., None]\n",
    "    image = (image - MNIST_MEAN) / MNIST_STD\n",
    "\n",
    "    # Add source indicator (0 = MNIST, 1 = Fashion)\n",
    "    return element.update_data(\n",
    "        {\n",
    "            \"image\": image,\n",
    "            \"label\": element.data[\"label\"],\n",
    "            \"source\": jnp.array(0, dtype=jnp.int32),  # 0 = MNIST\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess_fashion(element, key=None):  # noqa: ARG001\n",
    "    \"\"\"Preprocess Fashion-MNIST with source tag.\"\"\"\n",
    "    del key\n",
    "    image = element.data[\"image\"]\n",
    "\n",
    "    # Normalize\n",
    "    image = image.astype(jnp.float32) / 255.0\n",
    "    if image.ndim == 2:\n",
    "        image = image[..., None]\n",
    "    image = (image - FASHION_MEAN) / FASHION_STD\n",
    "\n",
    "    # Add source indicator (shift labels by 10 for unified label space)\n",
    "    return element.update_data(\n",
    "        {\n",
    "            \"image\": image,\n",
    "            \"label\": element.data[\"label\"] + 10,  # Offset for unified labels\n",
    "            \"original_label\": element.data[\"label\"],\n",
    "            \"source\": jnp.array(1, dtype=jnp.int32),  # 1 = Fashion\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "mnist_preprocessor = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=False),\n",
    "    fn=preprocess_mnist,\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "\n",
    "fashion_preprocessor = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=False),\n",
    "    fn=preprocess_fashion,\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "\n",
    "print(\"Created source-specific preprocessors:\")\n",
    "print(\"  MNIST: labels 0-9, source=0\")\n",
    "print(\"  Fashion: labels 10-19, source=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 3: Create Individual Pipelines\n",
    "\n",
    "First, let's verify each pipeline works independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST pipeline\n",
    "mnist_pipeline = from_source(mnist_source, batch_size=BATCH_SIZE).add(\n",
    "    OperatorNode(mnist_preprocessor)\n",
    ")\n",
    "\n",
    "# Fashion pipeline (need fresh source)\n",
    "fashion_source2 = TFDSEagerSource(fashion_config, rngs=nnx.Rngs(43))\n",
    "fashion_pipeline = from_source(fashion_source2, batch_size=BATCH_SIZE).add(\n",
    "    OperatorNode(fashion_preprocessor)\n",
    ")\n",
    "\n",
    "# Test individual pipelines\n",
    "mnist_batch = next(iter(mnist_pipeline))\n",
    "print(\"MNIST batch:\")\n",
    "print(f\"  Image shape: {mnist_batch['image'].shape}\")\n",
    "print(f\"  Labels: {mnist_batch['label'][:8]}\")\n",
    "print(f\"  Source: {mnist_batch['source'][:8]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 4: Interleaving Strategy\n",
    "\n",
    "We'll create a simple round-robin interleaving strategy that alternates\n",
    "between sources. More sophisticated strategies could use weighted sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterleavedIterator:\n",
    "    \"\"\"Round-robin iterator that alternates between multiple sources.\"\"\"\n",
    "\n",
    "    def __init__(self, pipelines: list, weights: list[float] | None = None):\n",
    "        \"\"\"Initialize with list of pipelines and optional weights.\n",
    "\n",
    "        Args:\n",
    "            pipelines: List of Datarax pipelines to interleave\n",
    "            weights: Optional sampling weights (default: equal)\n",
    "        \"\"\"\n",
    "        self.pipelines = pipelines\n",
    "        self.iterators = [iter(p) for p in pipelines]\n",
    "        self.weights = weights or [1.0 / len(pipelines)] * len(pipelines)\n",
    "        self.current_idx = 0\n",
    "        self.exhausted = [False] * len(pipelines)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"Get next batch, cycling through sources.\"\"\"\n",
    "        if all(self.exhausted):\n",
    "            raise StopIteration\n",
    "\n",
    "        # Find next non-exhausted source\n",
    "        attempts = 0\n",
    "        while self.exhausted[self.current_idx] and attempts < len(self.pipelines):\n",
    "            self.current_idx = (self.current_idx + 1) % len(self.pipelines)\n",
    "            attempts += 1\n",
    "\n",
    "        if attempts >= len(self.pipelines):\n",
    "            raise StopIteration\n",
    "\n",
    "        try:\n",
    "            batch = next(self.iterators[self.current_idx])\n",
    "            self.current_idx = (self.current_idx + 1) % len(self.pipelines)\n",
    "            return batch\n",
    "        except StopIteration:\n",
    "            self.exhausted[self.current_idx] = True\n",
    "            return self.__next__()\n",
    "\n",
    "\n",
    "print(\"Created InterleavedIterator for round-robin sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interleaved pipeline\n",
    "def create_interleaved_pipelines():\n",
    "    \"\"\"Create fresh pipelines for interleaving.\"\"\"\n",
    "    mnist_src = TFDSEagerSource(\n",
    "        TFDSEagerConfig(\n",
    "            name=\"mnist\",\n",
    "            split=\"train[:500]\",\n",
    "            shuffle=True,\n",
    "            seed=42,\n",
    "        ),\n",
    "        rngs=nnx.Rngs(42),\n",
    "    )\n",
    "\n",
    "    fashion_src = TFDSEagerSource(\n",
    "        TFDSEagerConfig(\n",
    "            name=\"fashion_mnist\",\n",
    "            split=\"train[:500]\",\n",
    "            shuffle=True,\n",
    "            seed=43,\n",
    "        ),\n",
    "        rngs=nnx.Rngs(43),\n",
    "    )\n",
    "\n",
    "    mnist_prep = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=preprocess_mnist,\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    fashion_prep = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=preprocess_fashion,\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    mnist_pipe = from_source(mnist_src, batch_size=BATCH_SIZE).add(OperatorNode(mnist_prep))\n",
    "    fashion_pipe = from_source(fashion_src, batch_size=BATCH_SIZE).add(OperatorNode(fashion_prep))\n",
    "\n",
    "    return [mnist_pipe, fashion_pipe]\n",
    "\n",
    "\n",
    "# Test interleaved iteration\n",
    "interleaved = InterleavedIterator(create_interleaved_pipelines())\n",
    "\n",
    "sources_seen = []\n",
    "for i, batch in enumerate(interleaved):\n",
    "    if i >= 10:  # Sample first 10 batches\n",
    "        break\n",
    "    sources_seen.append(int(batch[\"source\"][0]))\n",
    "\n",
    "print(f\"Sources in first 10 batches: {sources_seen}\")\n",
    "print(\"(0=MNIST, 1=Fashion)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 5: Visualize Mixed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"docs/assets/images/examples\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect samples from both sources\n",
    "interleaved = InterleavedIterator(create_interleaved_pipelines())\n",
    "all_images = []\n",
    "all_labels = []\n",
    "all_sources = []\n",
    "all_original_labels = []\n",
    "\n",
    "for batch in interleaved:\n",
    "    all_images.append(np.array(batch[\"image\"]))\n",
    "    all_labels.append(np.array(batch[\"label\"]))\n",
    "    all_sources.append(np.array(batch[\"source\"]))\n",
    "    # Use original_label if present, otherwise use label\n",
    "    if \"original_label\" in batch:\n",
    "        all_original_labels.append(np.array(batch[\"original_label\"]))\n",
    "    else:\n",
    "        all_original_labels.append(np.array(batch[\"label\"]))\n",
    "\n",
    "all_images = np.concatenate(all_images)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_sources = np.concatenate(all_sources)\n",
    "all_original_labels = np.concatenate(all_original_labels)\n",
    "\n",
    "print(f\"Total samples collected: {len(all_images)}\")\n",
    "print(f\"MNIST samples: {(all_sources == 0).sum()}\")\n",
    "print(f\"Fashion samples: {(all_sources == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mixed dataset samples\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "fig.suptitle(\"Multi-Source Dataset: MNIST + Fashion-MNIST\", fontsize=14)\n",
    "\n",
    "# Interleave MNIST and Fashion samples\n",
    "mnist_indices = np.where(all_sources == 0)[0][:16]\n",
    "fashion_indices = np.where(all_sources == 1)[0][:16]\n",
    "\n",
    "for i in range(8):\n",
    "    # MNIST row 1\n",
    "    idx = mnist_indices[i]\n",
    "    img = all_images[idx] * MNIST_STD + MNIST_MEAN\n",
    "    axes[0, i].imshow(img.squeeze(), cmap=\"gray\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "    axes[0, i].set_title(f\"MNIST: {MNIST_CLASSES[all_original_labels[idx] % 10]}\", fontsize=8)\n",
    "\n",
    "    # Fashion row 2\n",
    "    idx = fashion_indices[i]\n",
    "    img = all_images[idx] * FASHION_STD + FASHION_MEAN\n",
    "    axes[1, i].imshow(img.squeeze(), cmap=\"gray\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "    label_idx = all_original_labels[idx] % 10\n",
    "    axes[1, i].set_title(f\"Fashion: {FASHION_CLASSES[label_idx]}\", fontsize=8)\n",
    "\n",
    "    # MNIST row 3\n",
    "    if i + 8 < len(mnist_indices):\n",
    "        idx = mnist_indices[i + 8]\n",
    "        img = all_images[idx] * MNIST_STD + MNIST_MEAN\n",
    "        axes[2, i].imshow(img.squeeze(), cmap=\"gray\")\n",
    "        axes[2, i].axis(\"off\")\n",
    "        axes[2, i].set_title(f\"MNIST: {MNIST_CLASSES[all_original_labels[idx] % 10]}\", fontsize=8)\n",
    "    else:\n",
    "        axes[2, i].axis(\"off\")\n",
    "\n",
    "    # Fashion row 4\n",
    "    if i + 8 < len(fashion_indices):\n",
    "        idx = fashion_indices[i + 8]\n",
    "        img = all_images[idx] * FASHION_STD + FASHION_MEAN\n",
    "        axes[3, i].imshow(img.squeeze(), cmap=\"gray\")\n",
    "        axes[3, i].axis(\"off\")\n",
    "        label_idx = all_original_labels[idx] % 10\n",
    "        axes[3, i].set_title(f\"Fashion: {FASHION_CLASSES[label_idx]}\", fontsize=8)\n",
    "    else:\n",
    "        axes[3, i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"cv-multisource-samples.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\"\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'cv-multisource-samples.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 6: Source Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot source distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Source distribution\n",
    "source_counts = [np.sum(all_sources == 0), np.sum(all_sources == 1)]\n",
    "axes[0].bar([\"MNIST\", \"Fashion-MNIST\"], source_counts, color=[\"steelblue\", \"coral\"])\n",
    "axes[0].set_ylabel(\"Sample Count\")\n",
    "axes[0].set_title(\"Source Distribution\")\n",
    "for i, count in enumerate(source_counts):\n",
    "    axes[0].text(i, count + 10, str(count), ha=\"center\")\n",
    "\n",
    "# Label distribution (unified label space)\n",
    "label_counts = np.bincount(all_labels, minlength=20)\n",
    "x = np.arange(20)\n",
    "colors = [\"steelblue\"] * 10 + [\"coral\"] * 10\n",
    "axes[1].bar(x, label_counts, color=colors)\n",
    "axes[1].set_xlabel(\"Unified Label\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].set_title(\"Unified Label Distribution (0-9: MNIST, 10-19: Fashion)\")\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(x, fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"cv-multisource-distribution.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\"\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'cv-multisource-distribution.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 7: Throughput Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark single source\n",
    "mnist_src = TFDSEagerSource(\n",
    "    TFDSEagerConfig(name=\"mnist\", split=\"train[:1000]\", shuffle=False),\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "mnist_prep = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=False),\n",
    "    fn=preprocess_mnist,\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "single_pipeline = from_source(mnist_src, batch_size=64).add(OperatorNode(mnist_prep))\n",
    "\n",
    "start = time.time()\n",
    "single_count = 0\n",
    "for batch in single_pipeline:\n",
    "    _ = batch[\"image\"].block_until_ready()\n",
    "    single_count += batch[\"image\"].shape[0]\n",
    "single_time = time.time() - start\n",
    "single_throughput = single_count / single_time\n",
    "\n",
    "print(f\"Single source throughput: {single_throughput:.0f} samples/s\")\n",
    "\n",
    "# Benchmark interleaved\n",
    "interleaved = InterleavedIterator(create_interleaved_pipelines())\n",
    "\n",
    "start = time.time()\n",
    "multi_count = 0\n",
    "for batch in interleaved:\n",
    "    _ = batch[\"image\"].block_until_ready()\n",
    "    multi_count += batch[\"image\"].shape[0]\n",
    "multi_time = time.time() - start\n",
    "multi_throughput = multi_count / multi_time\n",
    "\n",
    "print(f\"Multi-source throughput: {multi_throughput:.0f} samples/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot throughput comparison\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "throughputs = [single_throughput, multi_throughput]\n",
    "labels = [\"Single Source\\n(MNIST)\", \"Interleaved\\n(MNIST + Fashion)\"]\n",
    "colors = [\"steelblue\", \"coral\"]\n",
    "\n",
    "bars = ax.bar(labels, throughputs, color=colors)\n",
    "ax.set_ylabel(\"Throughput (samples/second)\")\n",
    "ax.set_title(\"Data Loading Throughput Comparison\")\n",
    "\n",
    "for bar, val in zip(bars, throughputs):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, val + 50, f\"{val:.0f}\", ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"cv-multisource-throughput.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\"\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'cv-multisource-throughput.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "### Multi-Source Strategies\n",
    "\n",
    "| Strategy | Description | Use Case |\n",
    "|----------|-------------|----------|\n",
    "| Round-robin | Alternate sources equally | Balanced datasets |\n",
    "| Weighted | Sample by weights | Imbalanced sources |\n",
    "| Priority | Primary source + supplement | Domain adaptation |\n",
    "| Batch-level | Full batches from each | Multi-task learning |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Source tagging**: Add metadata to track data provenance\n",
    "2. **Label space**: Map to unified label space for multi-class\n",
    "3. **Fresh pipelines**: Create new pipeline instances for each epoch\n",
    "4. **Preprocessing**: Apply source-specific normalization\n",
    "5. **Throughput**: Multi-source adds minimal overhead\n",
    "\n",
    "### Unified Label Space\n",
    "\n",
    "```\n",
    "Labels 0-9:   MNIST digits\n",
    "Labels 10-19: Fashion-MNIST items\n",
    "\n",
    "Total classes: 20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Distributed**: [Sharding guide](../distributed/02_sharding_guide.ipynb)\n",
    "- **Checkpointing**: [Resumable training](../checkpointing/02_resumable_training_guide.ipynb)\n",
    "- **Full training**: [End-to-end CIFAR-10](../training/01_e2e_cifar10_guide.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the multi-source tutorial.\"\"\"\n",
    "    print(\"Multi-Source Data Loading Tutorial\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Create and iterate interleaved pipeline\n",
    "    interleaved = InterleavedIterator(create_interleaved_pipelines())\n",
    "\n",
    "    total_samples = 0\n",
    "    mnist_samples = 0\n",
    "    fashion_samples = 0\n",
    "\n",
    "    for batch in interleaved:\n",
    "        batch_size = batch[\"image\"].shape[0]\n",
    "        total_samples += batch_size\n",
    "        source = int(batch[\"source\"][0])\n",
    "        if source == 0:\n",
    "            mnist_samples += batch_size\n",
    "        else:\n",
    "            fashion_samples += batch_size\n",
    "\n",
    "    print(f\"Total samples processed: {total_samples}\")\n",
    "    print(f\"  MNIST: {mnist_samples}\")\n",
    "    print(f\"  Fashion: {fashion_samples}\")\n",
    "    print(\"Tutorial completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
