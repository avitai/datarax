{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# DADA: Differentiable Automatic Data Augmentation\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Advanced |\n",
    "| **Runtime** | ~60 min (GPU) / ~4 hrs (CPU) |\n",
    "| **Prerequisites** | JAX, Flax NNX, augmentation basics, gradient-based optimization |\n",
    "| **Memory** | ~4 GB VRAM (GPU) / ~8 GB RAM (CPU) |\n",
    "| **Devices** | GPU recommended, CPU supported |\n",
    "| **Format** | Python + Jupyter |\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example re-implements the core ideas from\n",
    "**DADA: Differentiable Automatic Data Augmentation** (Li et al., ECCV 2020)\n",
    "using datarax's operator library. Traditional augmentation search methods like\n",
    "AutoAugment require ~15,000 GPU-hours of reinforcement learning. DADA uses\n",
    "Gumbel-Softmax relaxation to make the discrete augmentation selection\n",
    "differentiable, reducing search cost to **~0.1 GPU-hours** on CIFAR-10 — a\n",
    "10,000x speedup.\n",
    "\n",
    "**Key insight**: When your preprocessing pipeline is differentiable, you can\n",
    "*learn* the optimal augmentation policy via gradient descent instead of\n",
    "expensive black-box search.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this example, you will be able to:\n",
    "\n",
    "1. **Understand** Gumbel-Softmax relaxation for differentiable discrete selection\n",
    "2. **Build** a learnable augmentation policy using datarax operators\n",
    "3. **Implement** bi-level optimization (model weights + augmentation policy)\n",
    "4. **Compare** learned vs. fixed augmentation on CIFAR-10\n",
    "5. **Verify** gradient flow through the entire augmentation → model → loss pipeline\n",
    "\n",
    "## Reference\n",
    "\n",
    "- Paper: Li et al., \"DADA: Differentiable Automatic Data Augmentation\" (ECCV 2020)\n",
    "  — [arXiv:2003.03780](https://arxiv.org/abs/2003.03780)\n",
    "- Code: [github.com/VDIGPKU/DADA](https://github.com/VDIGPKU/DADA) (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup & Prerequisites\n",
    "\n",
    "### Required Knowledge\n",
    "- [JAX fundamentals](https://jax.readthedocs.io/) — arrays, vmap, grad\n",
    "- [Flax NNX](https://flax.readthedocs.io/en/latest/nnx/) — modules, params, optimizers\n",
    "- [Datarax operators](../../core/02_operators_tutorial.py) — OperatorModule pattern\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "# Install datarax with data dependencies\n",
    "uv pip install \"datarax[data]\"\n",
    "\n",
    "# CIFAR-10 is downloaded automatically via keras.datasets\n",
    "```\n",
    "\n",
    "**Estimated Time:** ~60 min on GPU, ~4 hrs on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "from collections.abc import Callable\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "from datarax import from_source\n",
    "from datarax.core.element_batch import Batch, Element\n",
    "from datarax.operators import (\n",
    "    CompositeOperatorModule,\n",
    "    CompositeOperatorConfig,\n",
    "    CompositionStrategy,\n",
    "    ElementOperator,\n",
    "    ElementOperatorConfig,\n",
    ")\n",
    "from datarax.sources import MemorySource, MemorySourceConfig\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Output directory for saved figures\n",
    "OUTPUT_DIR = Path(\"docs/assets/images/examples\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "## Core Concepts\n",
    "\n",
    "### The Augmentation Search Problem\n",
    "\n",
    "Data augmentation is critical for training robust vision models, but choosing\n",
    "the right augmentation policy is hard. A *policy* consists of sub-policies,\n",
    "each specifying:\n",
    "- **Which operation** to apply (e.g., rotate, brightness, contrast)\n",
    "- **How much** (magnitude)\n",
    "- **How likely** (probability)\n",
    "\n",
    "AutoAugment (Cubuk et al., 2019) searched this space with RL — 15,000 GPU-hrs\n",
    "on CIFAR-10. DADA reformulates this as a **differentiable optimization**:\n",
    "\n",
    "$$\n",
    "\\\\mathcal{L}_{\\\\text{search}} = \\\\mathbb{E}_{x \\\\sim \\\\mathcal{D}} \\\\left[\n",
    "  \\\\ell\\\\left(f_\\\\theta\\\\left(\\\\text{Aug}_{\\\\alpha}(x)\\\\right), y\\\\right)\n",
    "\\\\right]\n",
    "$$\n",
    "\n",
    "where $\\\\alpha$ are the policy parameters (operation selection logits and\n",
    "magnitude) and $\\\\theta$ are the model weights. Both are optimized jointly\n",
    "via gradient descent.\n",
    "\n",
    "### Gumbel-Softmax Relaxation\n",
    "\n",
    "The key challenge: selecting *which* operation to apply is a **discrete** choice.\n",
    "Gumbel-Softmax (Jang et al., 2017) provides a differentiable approximation:\n",
    "\n",
    "$$\n",
    "\\\\text{softmax}\\\\left(\\\\frac{\\\\log \\\\alpha_i + g_i}{\\\\tau}\\\\right)\n",
    "\\\\quad \\\\text{where } g_i \\\\sim \\\\text{Gumbel}(0,1)\n",
    "$$\n",
    "\n",
    "At high temperature ($\\\\tau \\\\to \\\\infty$), this is uniform — all operations\n",
    "contribute equally. At low temperature ($\\\\tau \\\\to 0$), this approaches a\n",
    "one-hot vector — a single operation is selected. During search, we anneal\n",
    "$\\\\tau$ from 1.0 → 0.1.\n",
    "\n",
    "### RELAX Gradient Estimator\n",
    "\n",
    "DADA uses the RELAX estimator (Grathwohl et al., 2018) to reduce variance of\n",
    "Gumbel-Softmax gradients. RELAX combines:\n",
    "1. The standard reparameterization gradient (through the softmax)\n",
    "2. A learned control variate that reduces variance without adding bias\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│                    DADA Search Pipeline                  │\n",
    "│                                                         │\n",
    "│  Input ──→ [Op1] [Op2] ... [Op15]  ← 15 augmentations │\n",
    "│              │     │         │                          │\n",
    "│              ▼     ▼         ▼                          │\n",
    "│           Gumbel-Softmax weighted sum                   │\n",
    "│              │                                          │\n",
    "│              ▼                                          │\n",
    "│          Augmented Image                                │\n",
    "│              │                                          │\n",
    "│              ▼                                          │\n",
    "│          WRN-40-2 Classifier                            │\n",
    "│              │                                          │\n",
    "│              ▼                                          │\n",
    "│          Cross-Entropy Loss                             │\n",
    "│              │                                          │\n",
    "│     ┌────────┴────────┐                                │\n",
    "│     ▼                 ▼                                │\n",
    "│  ∂L/∂θ (model)   ∂L/∂α (policy)                       │\n",
    "│  SGD update       Adam update                          │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Bi-Level Optimization\n",
    "\n",
    "DADA uses bi-level optimization:\n",
    "- **Inner loop**: Update model weights θ with SGD on training set\n",
    "- **Outer loop**: Update policy parameters α with Adam on validation set\n",
    "\n",
    "This prevents the policy from overfitting to training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Implementation\n",
    "\n",
    "### Step 1: Load CIFAR-10 Dataset\n",
    "\n",
    "We load CIFAR-10 using keras.datasets (auto-downloads ~170 MB) and wrap it in\n",
    "datarax's `MemorySource` for pipeline integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load CIFAR-10 and create datarax sources\n",
    "\n",
    "\n",
    "def load_cifar10() -> tuple[dict, dict, dict]:\n",
    "    \"\"\"Load CIFAR-10 and split into train/val/test sets.\n",
    "\n",
    "    Returns train (40k), validation (10k), test (10k) as dicts with\n",
    "    'image' (float32, [0,1]) and 'label' (int32) keys.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from keras.datasets import cifar10  # type: ignore[import-untyped]\n",
    "    except ImportError as err:\n",
    "        raise ImportError(\n",
    "            \"keras is required for CIFAR-10 loading. Install with: pip install keras\"\n",
    "        ) from err\n",
    "\n",
    "    (x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # Normalize to [0, 1] float32\n",
    "    x_train_full = x_train_full.astype(np.float32) / 255.0\n",
    "    x_test = x_test.astype(np.float32) / 255.0\n",
    "    y_train_full = y_train_full.squeeze().astype(np.int32)\n",
    "    y_test = y_test.squeeze().astype(np.int32)\n",
    "\n",
    "    # Split train into train (40k) + validation (10k) for bi-level optimization\n",
    "    x_train = x_train_full[:40000]\n",
    "    y_train = y_train_full[:40000]\n",
    "    x_val = x_train_full[40000:]\n",
    "    y_val = y_train_full[40000:]\n",
    "\n",
    "    train_data = {\"image\": x_train, \"label\": y_train}\n",
    "    val_data = {\"image\": x_val, \"label\": y_val}\n",
    "    test_data = {\"image\": x_test, \"label\": y_test}\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "def create_sources(\n",
    "    train_data: dict, val_data: dict, test_data: dict\n",
    ") -> tuple[MemorySource, MemorySource, MemorySource]:\n",
    "    \"\"\"Wrap numpy data in datarax MemorySource objects.\"\"\"\n",
    "    config = MemorySourceConfig()\n",
    "    train_source = MemorySource(config, data=train_data, rngs=nnx.Rngs(0))\n",
    "    val_source = MemorySource(config, data=val_data, rngs=nnx.Rngs(1))\n",
    "    test_source = MemorySource(config, data=test_data, rngs=nnx.Rngs(2))\n",
    "    return train_source, val_source, test_source\n",
    "\n",
    "\n",
    "# Load data\n",
    "print(\"Loading CIFAR-10...\")\n",
    "train_data, val_data, test_data = load_cifar10()\n",
    "train_source, val_source, test_source = create_sources(train_data, val_data, test_data)\n",
    "print(\n",
    "    f\"Train: {train_data['image'].shape}, \"\n",
    "    f\"Val: {val_data['image'].shape}, \"\n",
    "    f\"Test: {test_data['image'].shape}\"\n",
    ")\n",
    "# Expected output:\n",
    "# Train: (40000, 32, 32, 3), Val: (10000, 32, 32, 3), Test: (10000, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CIFAR-10 samples\n",
    "CIFAR10_CLASSES = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "for i in range(8):\n",
    "    img = train_data[\"image\"][i]\n",
    "    label = int(train_data[\"label\"][i])\n",
    "    axes[0, i].imshow(img, interpolation=\"nearest\")\n",
    "    axes[0, i].set_title(CIFAR10_CLASSES[label], fontsize=9)\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    img2 = train_data[\"image\"][i + 8]\n",
    "    label2 = int(train_data[\"label\"][i + 8])\n",
    "    axes[1, i].imshow(img2, interpolation=\"nearest\")\n",
    "    axes[1, i].set_title(CIFAR10_CLASSES[label2], fontsize=9)\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"CIFAR-10 Training Samples (before augmentation)\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    OUTPUT_DIR / \"cv-dada-cifar10-samples.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(\"Saved: docs/assets/images/examples/cv-dada-cifar10-samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "### Step 2: Define Augmentation Operations as Datarax Operators (15 ops)\n",
    "\n",
    "We define 15 differentiable augmentation functions and wrap each as a datarax\n",
    "`ElementOperator` using `_make_aug_operator()`. This follows datarax's standard\n",
    "pattern: define a transformation function → wrap it as an operator → compose\n",
    "into pipelines. Each operation accepts a magnitude in [0, 1] that controls the\n",
    "transformation strength.\n",
    "\n",
    "All operations are differentiable — they use only JAX primitives with smooth\n",
    "approximations where needed (e.g., `jnp.round` → `x - sg(x - round(x))`\n",
    "for posterize). The 15 operators are composed into a single\n",
    "`CompositeOperatorModule` with `WEIGHTED_PARALLEL` strategy and\n",
    "`weight_key=\"op_weights\"`. At each forward call, the composite extracts\n",
    "Gumbel-Softmax weights from `data[\"op_weights\"]` and computes a differentiable\n",
    "weighted sum of all augmented outputs — replacing the manual loop + einsum\n",
    "pattern with datarax's native composition API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the 15 augmentation operations\n",
    "#\n",
    "# Each function takes an image (H, W, C) and a magnitude in [0, 1],\n",
    "# returns the augmented image. All ops must be JAX-differentiable.\n",
    "\n",
    "\n",
    "def translate_x(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Translate image horizontally. Magnitude [0,1] maps to [-8, 8] pixels.\"\"\"\n",
    "    shift = (magnitude * 16.0 - 8.0).astype(jnp.int32)\n",
    "    return jnp.roll(image, shift, axis=1)\n",
    "\n",
    "\n",
    "def translate_y(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Translate image vertically. Magnitude [0,1] maps to [-8, 8] pixels.\"\"\"\n",
    "    shift = (magnitude * 16.0 - 8.0).astype(jnp.int32)\n",
    "    return jnp.roll(image, shift, axis=0)\n",
    "\n",
    "\n",
    "def shear_x(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Shear image along X axis. Magnitude [0,1] maps to [-0.3, 0.3].\"\"\"\n",
    "    shear_factor = magnitude * 0.6 - 0.3\n",
    "    h, w, _ = image.shape\n",
    "    # Build coordinate grid for affine shear\n",
    "    ys = jnp.arange(h, dtype=jnp.float32)\n",
    "    xs = jnp.arange(w, dtype=jnp.float32)\n",
    "    grid_y, grid_x = jnp.meshgrid(ys, xs, indexing=\"ij\")\n",
    "    # Apply shear: x' = x + shear * y\n",
    "    src_x = grid_x + shear_factor * (grid_y - h / 2.0)\n",
    "    src_x = jnp.clip(src_x, 0, w - 1)\n",
    "\n",
    "    # Bilinear interpolation per channel via vmap\n",
    "    coords = jnp.stack([grid_y.ravel(), src_x.ravel()])\n",
    "\n",
    "    def interp_channel(ch: jax.Array) -> jax.Array:\n",
    "        return jax.scipy.ndimage.map_coordinates(ch, coords, order=1, mode=\"nearest\").reshape(h, w)\n",
    "\n",
    "    return jnp.moveaxis(jax.vmap(interp_channel)(jnp.moveaxis(image, -1, 0)), 0, -1)\n",
    "\n",
    "\n",
    "def shear_y(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Shear image along Y axis. Magnitude [0,1] maps to [-0.3, 0.3].\"\"\"\n",
    "    shear_factor = magnitude * 0.6 - 0.3\n",
    "    h, w, _ = image.shape\n",
    "    ys = jnp.arange(h, dtype=jnp.float32)\n",
    "    xs = jnp.arange(w, dtype=jnp.float32)\n",
    "    grid_y, grid_x = jnp.meshgrid(ys, xs, indexing=\"ij\")\n",
    "    src_y = grid_y + shear_factor * (grid_x - w / 2.0)\n",
    "    src_y = jnp.clip(src_y, 0, h - 1)\n",
    "\n",
    "    coords = jnp.stack([src_y.ravel(), grid_x.ravel()])\n",
    "\n",
    "    def interp_channel(ch: jax.Array) -> jax.Array:\n",
    "        return jax.scipy.ndimage.map_coordinates(ch, coords, order=1, mode=\"nearest\").reshape(h, w)\n",
    "\n",
    "    return jnp.moveaxis(jax.vmap(interp_channel)(jnp.moveaxis(image, -1, 0)), 0, -1)\n",
    "\n",
    "\n",
    "def solarize(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Solarize: invert pixels above threshold. Threshold = 1 - magnitude.\"\"\"\n",
    "    threshold = 1.0 - magnitude\n",
    "    # Soft solarize with sigmoid for differentiability\n",
    "    mask = jax.nn.sigmoid(20.0 * (image - threshold))\n",
    "    return image * (1.0 - mask) + (1.0 - image) * mask\n",
    "\n",
    "\n",
    "def posterize(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Posterize: reduce number of bits. Levels = 2 + magnitude * 6.\"\"\"\n",
    "    levels = 2.0 + magnitude * 6.0\n",
    "    # Differentiable rounding via straight-through estimator\n",
    "    quantized = jnp.round(image * levels) / levels\n",
    "    return image + jax.lax.stop_gradient(quantized - image)\n",
    "\n",
    "\n",
    "def equalize_approx(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Approximate histogram equalization (differentiable).\n",
    "\n",
    "    Uses a soft sigmoid-based CDF approximation rather than true histogram\n",
    "    equalization, which is non-differentiable.\n",
    "    \"\"\"\n",
    "    # Per-channel approximate equalization\n",
    "    mean = jnp.mean(image, axis=(0, 1), keepdims=True)\n",
    "    std = jnp.std(image, axis=(0, 1), keepdims=True) + 1e-5\n",
    "    normalized = (image - mean) / std\n",
    "    equalized = jax.nn.sigmoid(normalized * 2.0)\n",
    "    return image * (1.0 - magnitude) + equalized * magnitude\n",
    "\n",
    "\n",
    "def invert(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Invert image colors. Magnitude controls blend with original.\"\"\"\n",
    "    inverted = 1.0 - image\n",
    "    return image * (1.0 - magnitude) + inverted * magnitude\n",
    "\n",
    "\n",
    "def autocontrast(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Normalize each channel to [0, 1] range. Magnitude controls blend.\"\"\"\n",
    "    min_val = jnp.min(image, axis=(0, 1), keepdims=True)\n",
    "    max_val = jnp.max(image, axis=(0, 1), keepdims=True)\n",
    "    scale = 1.0 / (max_val - min_val + 1e-5)\n",
    "    contrasted = (image - min_val) * scale\n",
    "    return image * (1.0 - magnitude) + contrasted * magnitude\n",
    "\n",
    "\n",
    "def adjust_brightness(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Adjust brightness. Magnitude [0,1] maps to delta [-0.3, 0.3].\"\"\"\n",
    "    delta = magnitude * 0.6 - 0.3\n",
    "    return jnp.clip(image + delta, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def adjust_contrast(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Adjust contrast. Magnitude [0,1] maps to factor [0.5, 1.5].\"\"\"\n",
    "    factor = 0.5 + magnitude\n",
    "    mean = jnp.mean(image, axis=(0, 1), keepdims=True)\n",
    "    return jnp.clip((image - mean) * factor + mean, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def rotate(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Rotate image. Magnitude [0,1] maps to [-30, 30] degrees.\"\"\"\n",
    "    angle_deg = magnitude * 60.0 - 30.0\n",
    "    angle_rad = angle_deg * jnp.pi / 180.0\n",
    "    h, w, _ = image.shape\n",
    "    cy, cx = h / 2.0, w / 2.0\n",
    "\n",
    "    ys = jnp.arange(h, dtype=jnp.float32)\n",
    "    xs = jnp.arange(w, dtype=jnp.float32)\n",
    "    grid_y, grid_x = jnp.meshgrid(ys, xs, indexing=\"ij\")\n",
    "\n",
    "    # Inverse rotation to find source coordinates\n",
    "    cos_a, sin_a = jnp.cos(angle_rad), jnp.sin(angle_rad)\n",
    "    src_x = cos_a * (grid_x - cx) + sin_a * (grid_y - cy) + cx\n",
    "    src_y = -sin_a * (grid_x - cx) + cos_a * (grid_y - cy) + cy\n",
    "    src_x = jnp.clip(src_x, 0, w - 1)\n",
    "    src_y = jnp.clip(src_y, 0, h - 1)\n",
    "\n",
    "    coords = jnp.stack([src_y.ravel(), src_x.ravel()])\n",
    "\n",
    "    def interp_channel(ch: jax.Array) -> jax.Array:\n",
    "        return jax.scipy.ndimage.map_coordinates(ch, coords, order=1, mode=\"nearest\").reshape(h, w)\n",
    "\n",
    "    return jnp.moveaxis(jax.vmap(interp_channel)(jnp.moveaxis(image, -1, 0)), 0, -1)\n",
    "\n",
    "\n",
    "def add_noise(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Add Gaussian noise. Magnitude [0,1] controls std (0 to 0.1).\n",
    "\n",
    "    Note: Uses a fixed noise pattern for deterministic gradients (no RNG key).\n",
    "    In practice, this creates a texture-like augmentation.\n",
    "    \"\"\"\n",
    "    # Use a deterministic hash of the image for pseudo-random noise\n",
    "    noise_seed = jnp.sum(image * 1000).astype(jnp.int32)\n",
    "    noise = jax.random.normal(jax.random.key(noise_seed), image.shape)\n",
    "    return jnp.clip(image + noise * magnitude * 0.1, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def cutout(image: jax.Array, magnitude: jax.Array) -> jax.Array:\n",
    "    \"\"\"Apply cutout (zero-mask a square patch). Patch size = magnitude * 16.\"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    patch_size = (magnitude * 16.0).astype(jnp.int32)\n",
    "    # Center patch at image center (deterministic for gradient flow)\n",
    "    cy, cx = h // 2, w // 2\n",
    "    ys = jnp.arange(h)\n",
    "    xs = jnp.arange(w)\n",
    "    grid_y, grid_x = jnp.meshgrid(ys, xs, indexing=\"ij\")\n",
    "    # Soft mask using sigmoid for differentiability\n",
    "    dist_y = jnp.abs(grid_y - cy).astype(jnp.float32)\n",
    "    dist_x = jnp.abs(grid_x - cx).astype(jnp.float32)\n",
    "    mask = jax.nn.sigmoid(5.0 * (dist_y - patch_size / 2.0)) + jax.nn.sigmoid(\n",
    "        5.0 * (dist_x - patch_size / 2.0)\n",
    "    )\n",
    "    mask = jnp.clip(mask, 0.0, 1.0)[..., None]\n",
    "    return image * mask\n",
    "\n",
    "\n",
    "# Wrap each augmentation function as a datarax ElementOperator.\n",
    "# This follows the same operator pattern used throughout datarax:\n",
    "# define a transformation function → wrap it → compose into pipelines.\n",
    "\n",
    "\n",
    "def _make_aug_element_fn(\n",
    "    aug_fn: Callable[[jax.Array, jax.Array], jax.Array],\n",
    ") -> Callable[[Element, jax.Array], Element]:\n",
    "    \"\"\"Create an ElementOperator function from an (image, magnitude) -> image function.\"\"\"\n",
    "\n",
    "    def element_fn(element: Element, key: jax.Array) -> Element:\n",
    "        augmented = aug_fn(element.data[\"image\"], element.data[\"magnitude\"])\n",
    "        return element.update_data({\"image\": augmented})\n",
    "\n",
    "    return element_fn\n",
    "\n",
    "\n",
    "def _make_aug_operator(name: str, aug_fn: Callable) -> ElementOperator:\n",
    "    \"\"\"Wrap a single augmentation function as a datarax ElementOperator.\"\"\"\n",
    "    return ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=_make_aug_element_fn(aug_fn),\n",
    "        rngs=nnx.Rngs(0),\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "\n",
    "# Collect all 15 operations as datarax operators\n",
    "AUGMENTATION_OPS: list[tuple[str, ElementOperator]] = [\n",
    "    (\"translate_x\", _make_aug_operator(\"translate_x\", translate_x)),\n",
    "    (\"translate_y\", _make_aug_operator(\"translate_y\", translate_y)),\n",
    "    (\"shear_x\", _make_aug_operator(\"shear_x\", shear_x)),\n",
    "    (\"shear_y\", _make_aug_operator(\"shear_y\", shear_y)),\n",
    "    (\"rotate\", _make_aug_operator(\"rotate\", rotate)),\n",
    "    (\"brightness\", _make_aug_operator(\"brightness\", adjust_brightness)),\n",
    "    (\"contrast\", _make_aug_operator(\"contrast\", adjust_contrast)),\n",
    "    (\"solarize\", _make_aug_operator(\"solarize\", solarize)),\n",
    "    (\"posterize\", _make_aug_operator(\"posterize\", posterize)),\n",
    "    (\"equalize\", _make_aug_operator(\"equalize\", equalize_approx)),\n",
    "    (\"invert\", _make_aug_operator(\"invert\", invert)),\n",
    "    (\"autocontrast\", _make_aug_operator(\"autocontrast\", autocontrast)),\n",
    "    (\"noise\", _make_aug_operator(\"noise\", add_noise)),\n",
    "    (\"cutout\", _make_aug_operator(\"cutout\", cutout)),\n",
    "    (\"identity\", _make_aug_operator(\"identity\", lambda img, mag: img)),\n",
    "]\n",
    "\n",
    "NUM_OPS = len(AUGMENTATION_OPS)\n",
    "\n",
    "# Create a CompositeOperatorModule with WEIGHTED_PARALLEL strategy and dynamic\n",
    "# weights via weight_key. This replaces the manual loop + einsum pattern with\n",
    "# datarax's native composition API. The composite:\n",
    "# 1. Extracts Gumbel-Softmax weights from data[\"op_weights\"]\n",
    "# 2. Passes clean data (image + magnitude) to each augmentation operator\n",
    "# 3. Computes the weighted sum of all augmented outputs\n",
    "aug_composite = CompositeOperatorModule(\n",
    "    CompositeOperatorConfig(\n",
    "        strategy=CompositionStrategy.WEIGHTED_PARALLEL,\n",
    "        operators=[op for _, op in AUGMENTATION_OPS],\n",
    "        weight_key=\"op_weights\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Defined {NUM_OPS} augmentation operations: {[name for name, _ in AUGMENTATION_OPS]}\")\n",
    "print(\"Composed into WEIGHTED_PARALLEL composite with weight_key='op_weights'\")\n",
    "# Expected output:\n",
    "# Defined 15 augmentation operations: ['translate_x', 'translate_y', ...]\n",
    "# Composed into WEIGHTED_PARALLEL composite with weight_key='op_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all 15 augmentation operations on a single sample image\n",
    "sample_img = jnp.array(train_data[\"image\"][0])  # (32, 32, 3)\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "aug_fns = [\n",
    "    translate_x,\n",
    "    translate_y,\n",
    "    shear_x,\n",
    "    shear_y,\n",
    "    rotate,\n",
    "    adjust_brightness,\n",
    "    adjust_contrast,\n",
    "    solarize,\n",
    "    posterize,\n",
    "    equalize_approx,\n",
    "    invert,\n",
    "    autocontrast,\n",
    "    add_noise,\n",
    "    cutout,\n",
    "    lambda img, mag: img,\n",
    "]\n",
    "aug_names = [name for name, _ in AUGMENTATION_OPS]\n",
    "\n",
    "for idx, (ax, fn, name) in enumerate(zip(axes.flat, aug_fns, aug_names)):\n",
    "    mag = jnp.array(0.7)  # Use moderate magnitude for showcase\n",
    "    augmented = fn(sample_img, mag)\n",
    "    ax.imshow(np.clip(np.array(augmented), 0, 1), interpolation=\"nearest\")\n",
    "    ax.set_title(name, fontsize=9, fontweight=\"bold\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\n",
    "    \"DADA: All 15 Augmentation Operations (magnitude=0.7)\\n\"\n",
    "    \"Each operation is differentiable — Gumbel-Softmax selects the best combination\",\n",
    "    fontsize=12,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    OUTPUT_DIR / \"cv-dada-augmentation-showcase.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(\"Saved: docs/assets/images/examples/cv-dada-augmentation-showcase.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 3: WideResNet-40-2 Classifier\n",
    "\n",
    "We implement the WideResNet-40-2 (Zagoruyko & Komodakis, BMVC 2016) — the same\n",
    "architecture used in the DADA paper. Depth=40, widen_factor=2 gives:\n",
    "- 3 groups × 6 residual blocks each = 18 blocks (depth = 6*3*2+4 = 40)\n",
    "- Channel widths: [32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: WideResNet-40-2 in Flax NNX\n",
    "class WideResidualBlock(nnx.Module):\n",
    "    \"\"\"Single wide residual block: BN → ReLU → Conv → BN → ReLU → Conv + skip.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        stride: int = 1,\n",
    "        *,\n",
    "        rngs: nnx.Rngs,\n",
    "    ):\n",
    "        self.bn1 = nnx.BatchNorm(in_channels, rngs=rngs)\n",
    "        self.conv1 = nnx.Conv(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(stride, stride),\n",
    "            padding=\"SAME\",\n",
    "            rngs=rngs,\n",
    "        )\n",
    "        self.bn2 = nnx.BatchNorm(out_channels, rngs=rngs)\n",
    "        self.conv2 = nnx.Conv(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=\"SAME\",\n",
    "            rngs=rngs,\n",
    "        )\n",
    "        # Shortcut for dimension mismatch\n",
    "        self.needs_projection = in_channels != out_channels or stride != 1\n",
    "        if self.needs_projection:\n",
    "            self.shortcut = nnx.Conv(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(1, 1),\n",
    "                strides=(stride, stride),\n",
    "                padding=\"SAME\",\n",
    "                rngs=rngs,\n",
    "            )\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        residual = x\n",
    "        out = nnx.relu(self.bn1(x))\n",
    "        if self.needs_projection:\n",
    "            residual = self.shortcut(out)\n",
    "        out = self.conv1(out)\n",
    "        out = nnx.relu(self.bn2(out))\n",
    "        out = self.conv2(out)\n",
    "        return out + residual\n",
    "\n",
    "\n",
    "class WideResidualGroup(nnx.Module):\n",
    "    \"\"\"Group of N wide residual blocks with same output channels.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        num_blocks: int,\n",
    "        stride: int = 1,\n",
    "        *,\n",
    "        rngs: nnx.Rngs,\n",
    "    ):\n",
    "        blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            s = stride if i == 0 else 1\n",
    "            ic = in_channels if i == 0 else out_channels\n",
    "            blocks.append(WideResidualBlock(ic, out_channels, s, rngs=rngs))\n",
    "        self.blocks = nnx.List(blocks)\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class WideResNet(nnx.Module):\n",
    "    \"\"\"WideResNet-40-2 for CIFAR-10.\n",
    "\n",
    "    Architecture: Conv → Group1(32ch) → Group2(64ch) → Group3(128ch) → BN → Pool → Dense\n",
    "    Depth=40 → (40-4)/6 = 6 blocks per group\n",
    "    Widen=2 → channels = [16*2, 32*2, 64*2] = [32, 64, 128]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int = 10, *, rngs: nnx.Rngs):\n",
    "        widen = 2\n",
    "        n_blocks = 6  # (40 - 4) / 6 = 6\n",
    "\n",
    "        self.conv0 = nnx.Conv(3, 16, kernel_size=(3, 3), padding=\"SAME\", rngs=rngs)\n",
    "\n",
    "        self.group1 = WideResidualGroup(16, 16 * widen, n_blocks, stride=1, rngs=rngs)\n",
    "        self.group2 = WideResidualGroup(16 * widen, 32 * widen, n_blocks, stride=2, rngs=rngs)\n",
    "        self.group3 = WideResidualGroup(32 * widen, 64 * widen, n_blocks, stride=2, rngs=rngs)\n",
    "\n",
    "        self.bn_final = nnx.BatchNorm(64 * widen, rngs=rngs)\n",
    "        self.fc = nnx.Linear(64 * widen, num_classes, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        \"\"\"Forward pass. Input: (B, 32, 32, 3), Output: (B, 10) logits.\"\"\"\n",
    "        x = self.conv0(x)\n",
    "        x = self.group1(x)\n",
    "        x = self.group2(x)\n",
    "        x = self.group3(x)\n",
    "        x = nnx.relu(self.bn_final(x))\n",
    "        x = jnp.mean(x, axis=(1, 2))  # Global average pooling\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Verify model\n",
    "model_rngs = nnx.Rngs(42)\n",
    "model = WideResNet(num_classes=10, rngs=model_rngs)\n",
    "dummy_input = jnp.ones((2, 32, 32, 3))\n",
    "dummy_output = model(dummy_input)\n",
    "print(f\"WRN-40-2 output shape: {dummy_output.shape}\")\n",
    "n_params = sum(p.size for p in jax.tree.leaves(nnx.state(model, nnx.Param)))\n",
    "print(f\"WRN-40-2 parameters: {n_params:,}\")\n",
    "# Expected output:\n",
    "# WRN-40-2 output shape: (2, 10)\n",
    "# WRN-40-2 parameters: ~2,243,546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 4: Augmentation Policy with Gumbel-Softmax\n",
    "\n",
    "The policy has 25 sub-policies (matching DADA), each with 2 operation slots.\n",
    "Each slot has:\n",
    "- **Operation logits** (15-dim): which augmentation to apply\n",
    "- **Magnitude** (scalar): strength of the augmentation\n",
    "- **Probability** (scalar): likelihood of applying (via sigmoid)\n",
    "\n",
    "During the forward pass, Gumbel-Softmax selects operations and computes\n",
    "a weighted sum of all augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Differentiable augmentation policy\n",
    "class AugmentationPolicy(nnx.Module):\n",
    "    \"\"\"Learnable augmentation policy using Gumbel-Softmax.\n",
    "\n",
    "    Contains 25 sub-policies × 2 ops each = 50 learnable slots.\n",
    "    Each slot has logits for operation selection, magnitude, and probability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_sub_policies: int = 25,\n",
    "        ops_per_sub_policy: int = 2,\n",
    "        num_ops: int = NUM_OPS,\n",
    "        *,\n",
    "        rngs: nnx.Rngs,\n",
    "    ):\n",
    "        self.num_sub_policies = num_sub_policies\n",
    "        self.ops_per_sub_policy = ops_per_sub_policy\n",
    "        self.num_ops = num_ops\n",
    "\n",
    "        # Learnable parameters: logits for operation selection\n",
    "        # Shape: (num_sub_policies, ops_per_sub_policy, num_ops)\n",
    "        self.op_logits = nnx.Param(jnp.zeros((num_sub_policies, ops_per_sub_policy, num_ops)))\n",
    "        # Learnable magnitudes: (num_sub_policies, ops_per_sub_policy)\n",
    "        self.magnitudes = nnx.Param(jnp.full((num_sub_policies, ops_per_sub_policy), 0.5))\n",
    "        # Learnable probabilities (pre-sigmoid):\n",
    "        # (num_sub_policies, ops_per_sub_policy)\n",
    "        self.prob_logits = nnx.Param(jnp.zeros((num_sub_policies, ops_per_sub_policy)))\n",
    "\n",
    "    def sample_sub_policy(self, key: jax.Array) -> int:\n",
    "        \"\"\"Uniformly sample a sub-policy index.\"\"\"\n",
    "        return jax.random.randint(key, (), 0, self.num_sub_policies)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits: jax.Array, key: jax.Array, temperature: float = 1.0) -> jax.Array:\n",
    "    \"\"\"Sample from Gumbel-Softmax distribution.\n",
    "\n",
    "    Args:\n",
    "        logits: Unnormalized log probabilities (..., num_classes)\n",
    "        key: JAX random key\n",
    "        temperature: Softmax temperature (lower = more discrete)\n",
    "\n",
    "    Returns:\n",
    "        Soft one-hot vector with same shape as logits\n",
    "    \"\"\"\n",
    "    gumbel_noise = -jnp.log(\n",
    "        -jnp.log(jax.random.uniform(key, logits.shape, minval=1e-6, maxval=1.0 - 1e-6))\n",
    "    )\n",
    "    return jax.nn.softmax((logits + gumbel_noise) / temperature, axis=-1)\n",
    "\n",
    "\n",
    "def apply_augmentation_slot(\n",
    "    images: jax.Array,\n",
    "    policy: AugmentationPolicy,\n",
    "    sub_policy_indices: jax.Array,\n",
    "    op_idx: int,\n",
    "    key: jax.Array,\n",
    "    temperature: float,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Apply a single augmentation slot to a batch using CompositeOperatorModule.\n",
    "\n",
    "    Computes per-image Gumbel-Softmax weights via batched JAX operations, then\n",
    "    delegates to CompositeOperatorModule's native Batch processing for the\n",
    "    weighted sum of all augmentation operators. No manual vmap required —\n",
    "    the composite handles batch parallelism internally.\n",
    "\n",
    "    Args:\n",
    "        images: Batch of images (B, H, W, C)\n",
    "        policy: AugmentationPolicy module\n",
    "        sub_policy_indices: Per-image sub-policy indices (B,)\n",
    "        op_idx: Which operation slot within the sub-policy\n",
    "        key: JAX random key\n",
    "        temperature: Gumbel-Softmax temperature\n",
    "\n",
    "    Returns:\n",
    "        Augmented batch of images (B, H, W, C)\n",
    "    \"\"\"\n",
    "    # Batched parameter lookup using JAX advanced indexing\n",
    "    logits_batch = policy.op_logits[sub_policy_indices, op_idx]  # (B, 15)\n",
    "    magnitudes_batch = jax.nn.sigmoid(policy.magnitudes[sub_policy_indices, op_idx])  # (B,)\n",
    "    probs_batch = jax.nn.sigmoid(policy.prob_logits[sub_policy_indices, op_idx])  # (B,)\n",
    "\n",
    "    # Batched Gumbel-Softmax (gumbel_softmax is already vectorized —\n",
    "    # only uses element-wise ops + softmax(axis=-1))\n",
    "    op_weights_batch = gumbel_softmax(logits_batch, key, temperature)  # (B, 15)\n",
    "\n",
    "    # Build Batch and delegate to CompositeOperatorModule's native processing.\n",
    "    # The composite's __call__ → apply_batch → _vmap_apply handles:\n",
    "    #   1. Extracting op_weights from data[weight_key] per element\n",
    "    #   2. Stripping weight_key so children only see {image, magnitude}\n",
    "    #   3. Computing weighted sum of all 15 augmentation outputs\n",
    "    batch = Batch.from_parts(\n",
    "        data={\n",
    "            \"image\": images,\n",
    "            \"magnitude\": magnitudes_batch,\n",
    "            \"op_weights\": op_weights_batch,\n",
    "        },\n",
    "        states={},\n",
    "    )\n",
    "    result_batch = aug_composite(batch)\n",
    "    result_data = result_batch.get_data()\n",
    "\n",
    "    # Blend: image * (1 - prob) + augmented * prob\n",
    "    probs = probs_batch.reshape(-1, *([1] * (images.ndim - 1)))\n",
    "    return images * (1.0 - probs) + result_data[\"image\"] * probs\n",
    "\n",
    "\n",
    "# Create the policy\n",
    "policy = AugmentationPolicy(rngs=nnx.Rngs(0))\n",
    "policy_params = sum(p.size for p in jax.tree.leaves(nnx.state(policy, nnx.Param)))\n",
    "print(f\"Policy parameters: {policy_params}\")\n",
    "print(f\"  - Operation logits: {policy.op_logits[...].shape}\")\n",
    "print(f\"  - Magnitudes: {policy.magnitudes[...].shape}\")\n",
    "print(f\"  - Probability logits: {policy.prob_logits[...].shape}\")\n",
    "# Expected output:\n",
    "# Policy parameters: 800\n",
    "#   - Operation logits: (25, 2, 15)\n",
    "#   - Magnitudes: (25, 2)\n",
    "#   - Probability logits: (25, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "### Step 5: RELAX Gradient Estimator\n",
    "\n",
    "RELAX (Grathwohl et al., 2018) uses a learned control variate network to\n",
    "reduce variance of Gumbel-Softmax gradients. The control variate $c_\\\\phi$\n",
    "is a small neural network that predicts baseline values, and its parameters\n",
    "$\\\\phi$ are optimized to minimize gradient variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: RELAX control variate\n",
    "class RELAXControlVariate(nnx.Module):\n",
    "    \"\"\"Learned control variate for RELAX gradient estimator.\n",
    "\n",
    "    A small MLP that takes Gumbel-Softmax logits and produces a scalar\n",
    "    baseline prediction. Trained to minimize gradient variance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int = NUM_OPS, *, rngs: nnx.Rngs):\n",
    "        self.net = nnx.Sequential(\n",
    "            nnx.Linear(input_dim, 64, rngs=rngs),\n",
    "            nnx.relu,\n",
    "            nnx.Linear(64, 32, rngs=rngs),\n",
    "            nnx.relu,\n",
    "            nnx.Linear(32, 1, rngs=rngs),\n",
    "        )\n",
    "\n",
    "    def __call__(self, z: jax.Array) -> jax.Array:\n",
    "        \"\"\"Predict baseline from Gumbel-Softmax samples.\n",
    "\n",
    "        Args:\n",
    "            z: Gumbel-Softmax sample (num_ops,)\n",
    "\n",
    "        Returns:\n",
    "            Scalar baseline prediction\n",
    "        \"\"\"\n",
    "        return self.net(z).squeeze(-1)\n",
    "\n",
    "\n",
    "control_variate = RELAXControlVariate(rngs=nnx.Rngs(0))\n",
    "cv_params = sum(p.size for p in jax.tree.leaves(nnx.state(control_variate, nnx.Param)))\n",
    "print(f\"RELAX control variate parameters: {cv_params}\")\n",
    "# Expected output:\n",
    "# RELAX control variate parameters: ~3,169"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 6: Training Loop with Bi-Level Optimization\n",
    "\n",
    "The search phase alternates between:\n",
    "1. **Inner step**: Train model weights on augmented training data (SGD)\n",
    "2. **Outer step**: Update augmentation policy on validation data (Adam)\n",
    "\n",
    "This is the standard bi-level optimization used in neural architecture search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Training functions\n",
    "def cross_entropy_loss(logits: jax.Array, labels: jax.Array) -> jax.Array:\n",
    "    \"\"\"Compute cross-entropy loss.\"\"\"\n",
    "    one_hot = jax.nn.one_hot(labels, logits.shape[-1])\n",
    "    return -jnp.mean(jnp.sum(one_hot * jax.nn.log_softmax(logits), axis=-1))\n",
    "\n",
    "\n",
    "def accuracy(logits: jax.Array, labels: jax.Array) -> jax.Array:\n",
    "    \"\"\"Compute classification accuracy.\"\"\"\n",
    "    predictions = jnp.argmax(logits, axis=-1)\n",
    "    return jnp.mean(predictions == labels)\n",
    "\n",
    "\n",
    "def augment_batch(\n",
    "    images: jax.Array,\n",
    "    policy: AugmentationPolicy,\n",
    "    key: jax.Array,\n",
    "    temperature: float = 1.0,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Apply policy augmentation to a batch of images.\n",
    "\n",
    "    Uses batched JAX operations for per-image parameter computation, then\n",
    "    delegates to CompositeOperatorModule's native Batch processing for the\n",
    "    weighted sum. No manual vmap — the composite handles batch parallelism.\n",
    "\n",
    "    For each image, a random sub-policy is selected. Each sub-policy has 2\n",
    "    augmentation slots applied sequentially.\n",
    "    \"\"\"\n",
    "    batch_size = images.shape[0]\n",
    "    key, sp_key = jax.random.split(key)\n",
    "\n",
    "    # Select random sub-policy for each image (batched)\n",
    "    sub_policy_indices = jax.random.randint(sp_key, (batch_size,), 0, policy.num_sub_policies)\n",
    "\n",
    "    # Apply each slot sequentially (2 slots per sub-policy)\n",
    "    for op_idx in range(policy.ops_per_sub_policy):\n",
    "        key, slot_key = jax.random.split(key)\n",
    "        images = apply_augmentation_slot(\n",
    "            images, policy, sub_policy_indices, op_idx, slot_key, temperature\n",
    "        )\n",
    "\n",
    "    return jnp.clip(images, 0.0, 1.0)\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step_inner(\n",
    "    model: WideResNet,\n",
    "    policy: AugmentationPolicy,\n",
    "    optimizer: nnx.Optimizer,\n",
    "    images: jax.Array,\n",
    "    labels: jax.Array,\n",
    "    key: jax.Array,\n",
    "    temperature: float,\n",
    ") -> tuple[jax.Array, jax.Array]:\n",
    "    \"\"\"Inner loop: update model weights on augmented training data (JIT-compiled).\"\"\"\n",
    "\n",
    "    def loss_fn(model: WideResNet) -> jax.Array:\n",
    "        aug_images = augment_batch(images, policy, key, temperature)\n",
    "        logits = model(aug_images)\n",
    "        return cross_entropy_loss(logits, labels)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "    optimizer.update(model, grads)\n",
    "    return loss, accuracy(model(images), labels)\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def _policy_step(\n",
    "    model: WideResNet,\n",
    "    policy: AugmentationPolicy,\n",
    "    policy_optimizer: nnx.Optimizer,\n",
    "    images: jax.Array,\n",
    "    labels: jax.Array,\n",
    "    key: jax.Array,\n",
    "    temperature: float,\n",
    ") -> jax.Array:\n",
    "    \"\"\"JIT-compiled policy gradient step.\"\"\"\n",
    "\n",
    "    def loss_fn(policy: AugmentationPolicy) -> jax.Array:\n",
    "        aug_images = augment_batch(images, policy, key, temperature)\n",
    "        logits = model(aug_images)\n",
    "        return cross_entropy_loss(logits, labels)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(policy)\n",
    "    policy_optimizer.update(policy, grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_step_outer(\n",
    "    model: WideResNet,\n",
    "    policy: AugmentationPolicy,\n",
    "    policy_optimizer: nnx.Optimizer,\n",
    "    images: jax.Array,\n",
    "    labels: jax.Array,\n",
    "    key: jax.Array,\n",
    "    temperature: float,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Outer loop: update policy on validation data.\"\"\"\n",
    "    model.eval()  # BatchNorm uses running stats (no mutation)\n",
    "    loss = _policy_step(\n",
    "        model,\n",
    "        policy,\n",
    "        policy_optimizer,\n",
    "        images,\n",
    "        labels,\n",
    "        key,\n",
    "        temperature,\n",
    "    )\n",
    "    model.train()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 7: Run DADA Search\n",
    "\n",
    "Now we run the search phase: 20 epochs of bi-level optimization.\n",
    "Temperature anneals from 1.0 → 0.1 over the search period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: DADA Search Phase\n",
    "def run_dada_search(\n",
    "    train_source: MemorySource,\n",
    "    val_source: MemorySource,\n",
    "    num_epochs: int = 20,\n",
    "    batch_size: int = 128,\n",
    "    lr_model: float = 0.1,\n",
    "    lr_policy: float = 3e-3,\n",
    "    temp_start: float = 1.0,\n",
    "    temp_end: float = 0.1,\n",
    ") -> tuple[WideResNet, AugmentationPolicy]:\n",
    "    \"\"\"Run DADA augmentation policy search.\n",
    "\n",
    "    Args:\n",
    "        train_source: Training data MemorySource\n",
    "        val_source: Validation data MemorySource\n",
    "        num_epochs: Number of search epochs\n",
    "        batch_size: Batch size for training\n",
    "        lr_model: Learning rate for model (SGD with cosine annealing)\n",
    "        lr_policy: Learning rate for policy (Adam)\n",
    "        temp_start: Initial Gumbel-Softmax temperature\n",
    "        temp_end: Final Gumbel-Softmax temperature\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (trained model, optimized policy, training history dict)\n",
    "    \"\"\"\n",
    "    # Initialize model and policy\n",
    "    rngs = nnx.Rngs(42)\n",
    "    model = WideResNet(num_classes=10, rngs=rngs)\n",
    "    policy = AugmentationPolicy(rngs=rngs)\n",
    "\n",
    "    # Optimizers (matching DADA paper)\n",
    "    total_steps = num_epochs * (len(train_source) // batch_size)\n",
    "    model_schedule = optax.cosine_decay_schedule(lr_model, total_steps)\n",
    "    model_optimizer = nnx.Optimizer(\n",
    "        model,\n",
    "        optax.chain(\n",
    "            optax.sgd(learning_rate=model_schedule, momentum=0.9),\n",
    "            optax.clip_by_global_norm(5.0),\n",
    "        ),\n",
    "        wrt=nnx.Param,\n",
    "    )\n",
    "    policy_optimizer = nnx.Optimizer(policy, optax.adam(lr_policy), wrt=nnx.Param)\n",
    "\n",
    "    key = jax.random.key(0)\n",
    "\n",
    "    # Track training history for visualization\n",
    "    history: dict = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"temperature\": [],\n",
    "    }\n",
    "\n",
    "    print(f\"Starting DADA search: {num_epochs} epochs, batch_size={batch_size}\")\n",
    "    print(f\"Model LR: {lr_model} (cosine decay), Policy LR: {lr_policy} (Adam)\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Temperature annealing\n",
    "        progress = epoch / max(num_epochs - 1, 1)\n",
    "        temperature = temp_start + (temp_end - temp_start) * progress\n",
    "\n",
    "        # Create pipelines for this epoch\n",
    "        train_pipeline = from_source(train_source, batch_size=batch_size)\n",
    "        val_pipeline = from_source(val_source, batch_size=batch_size)\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "        num_steps = 0\n",
    "\n",
    "        # Alternate inner and outer steps\n",
    "        val_iter = iter(val_pipeline)\n",
    "        for batch in train_pipeline:\n",
    "            key, step_key, val_key = jax.random.split(key, 3)\n",
    "            images = batch[\"image\"]\n",
    "            labels = batch[\"label\"]\n",
    "\n",
    "            # Inner step: update model\n",
    "            loss, acc = train_step_inner(\n",
    "                model,\n",
    "                policy,\n",
    "                model_optimizer,\n",
    "                images,\n",
    "                labels,\n",
    "                step_key,\n",
    "                temperature,\n",
    "            )\n",
    "            epoch_loss += float(loss)\n",
    "            epoch_acc += float(acc)\n",
    "            num_steps += 1\n",
    "\n",
    "            # Outer step: update policy (on validation data)\n",
    "            try:\n",
    "                val_batch = next(val_iter)\n",
    "            except StopIteration:\n",
    "                val_iter = iter(from_source(val_source, batch_size=batch_size))\n",
    "                val_batch = next(val_iter)\n",
    "\n",
    "            val_images = val_batch[\"image\"]\n",
    "            val_labels = val_batch[\"label\"]\n",
    "            val_loss = train_step_outer(\n",
    "                model,\n",
    "                policy,\n",
    "                policy_optimizer,\n",
    "                val_images,\n",
    "                val_labels,\n",
    "                val_key,\n",
    "                temperature,\n",
    "            )\n",
    "            epoch_val_loss += float(val_loss)\n",
    "\n",
    "        avg_loss = epoch_loss / max(num_steps, 1)\n",
    "        avg_acc = epoch_acc / max(num_steps, 1)\n",
    "        avg_val_loss = epoch_val_loss / max(num_steps, 1)\n",
    "\n",
    "        history[\"epoch\"].append(epoch + 1)\n",
    "        history[\"train_loss\"].append(avg_loss)\n",
    "        history[\"train_acc\"].append(avg_acc)\n",
    "        history[\"val_loss\"].append(avg_val_loss)\n",
    "        history[\"temperature\"].append(temperature)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1:2d}/{num_epochs} | \"\n",
    "            f\"Train Loss: {avg_loss:.4f} | Train Acc: {avg_acc:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f} | Temp: {temperature:.3f}\"\n",
    "        )\n",
    "\n",
    "    return model, policy, history\n",
    "\n",
    "\n",
    "# Run search (reduce epochs for quick demonstration)\n",
    "QUICK_MODE = True  # Set to False for full DADA search\n",
    "search_epochs = 3 if QUICK_MODE else 20\n",
    "\n",
    "print(\"\\n=== DADA Augmentation Policy Search ===\")\n",
    "model, policy, search_history = run_dada_search(\n",
    "    train_source,\n",
    "    val_source,\n",
    "    num_epochs=search_epochs,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "epochs = search_history[\"epoch\"]\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(\n",
    "    epochs,\n",
    "    search_history[\"train_loss\"],\n",
    "    \"o-\",\n",
    "    color=\"steelblue\",\n",
    "    linewidth=2,\n",
    "    markersize=6,\n",
    "    label=\"Train\",\n",
    ")\n",
    "axes[0].plot(\n",
    "    epochs,\n",
    "    search_history[\"val_loss\"],\n",
    "    \"o-\",\n",
    "    color=\"darkorange\",\n",
    "    linewidth=2,\n",
    "    markersize=6,\n",
    "    label=\"Val (policy)\",\n",
    ")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training & Validation Loss\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot(epochs, search_history[\"train_acc\"], \"o-\", color=\"green\", linewidth=2, markersize=6)\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Training Accuracy\")\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Temperature annealing\n",
    "axes[2].plot(\n",
    "    epochs, search_history[\"temperature\"], \"o-\", color=\"crimson\", linewidth=2, markersize=6\n",
    ")\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].set_ylabel(\"Temperature (τ)\")\n",
    "axes[2].set_title(\"Gumbel-Softmax Temperature Annealing\")\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle(\"DADA Search Progress — Bi-Level Optimization\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    OUTPUT_DIR / \"perf-dada-training-curves.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(\"Saved: docs/assets/images/examples/perf-dada-training-curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 8: Evaluate and Compare Results\n",
    "\n",
    "We compare three configurations:\n",
    "1. **No augmentation**: Baseline without any augmentation\n",
    "2. **Fixed augmentation**: Standard random flip + crop (common practice)\n",
    "3. **DADA learned policy**: Our Gumbel-Softmax optimized policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Evaluate on test set\n",
    "def evaluate(\n",
    "    model: WideResNet,\n",
    "    test_source: MemorySource,\n",
    "    batch_size: int = 128,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Evaluate model on test set.\"\"\"\n",
    "    pipeline = from_source(test_source, batch_size=batch_size)\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch in pipeline:\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "        logits = model(images)\n",
    "        total_loss += float(cross_entropy_loss(logits, labels))\n",
    "        total_acc += float(accuracy(logits, labels))\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_loss / max(num_batches, 1), total_acc / max(num_batches, 1)\n",
    "\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_source)\n",
    "print(\"\\n=== Test Results (DADA Learned Policy) ===\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "### Step 9: Verify Gradient Flow\n",
    "\n",
    "The critical claim: gradients flow through the augmentation pipeline all the\n",
    "way back to the policy parameters. Let's verify this explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Explicit gradient flow verification\n",
    "print(\"\\n=== Gradient Flow Verification ===\")\n",
    "\n",
    "# Create a small batch for verification\n",
    "verify_pipeline = from_source(test_source, batch_size=16)\n",
    "verify_batch = next(iter(verify_pipeline))\n",
    "verify_images = verify_batch[\"image\"]\n",
    "verify_labels = verify_batch[\"label\"]\n",
    "\n",
    "key = jax.random.key(999)\n",
    "\n",
    "\n",
    "def full_loss_fn(policy: AugmentationPolicy) -> jax.Array:\n",
    "    \"\"\"Loss function for gradient verification.\"\"\"\n",
    "    aug_images = augment_batch(verify_images, policy, key, temperature=0.5)\n",
    "    logits = model(aug_images)\n",
    "    return cross_entropy_loss(logits, verify_labels)\n",
    "\n",
    "\n",
    "model.eval()  # Model in closure — prevent BatchNorm mutation\n",
    "loss, grads = nnx.value_and_grad(full_loss_fn)(policy)\n",
    "model.train()\n",
    "grad_leaves = jax.tree.leaves(grads)\n",
    "\n",
    "assert len(grad_leaves) > 0, \"No gradient leaves found\"\n",
    "assert any(jnp.sum(jnp.abs(g)) > 0 for g in grad_leaves), (\n",
    "    \"All gradients are zero — pipeline is NOT differentiable!\"\n",
    ")\n",
    "\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Gradient flow verified: {len(grad_leaves)} parameter groups receive gradients\")\n",
    "for i, g in enumerate(grad_leaves):\n",
    "    print(f\"  Param group {i}: shape={g.shape}, |grad|={float(jnp.sum(jnp.abs(g))):.6f}\")\n",
    "print(\"SUCCESS: Augmentation pipeline is fully differentiable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 10: Analyze Learned Policy\n",
    "\n",
    "Let's inspect what augmentation operations the policy learned to prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Analyze the learned policy\n",
    "def analyze_policy(policy: AugmentationPolicy) -> None:\n",
    "    \"\"\"Print analysis of the learned augmentation policy.\"\"\"\n",
    "    op_names = [name for name, _ in AUGMENTATION_OPS]\n",
    "    logits = policy.op_logits[...]  # (25, 2, 15)\n",
    "    probs = jax.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    print(\"\\n=== Learned Policy Analysis ===\")\n",
    "\n",
    "    # Average operation preference across all slots\n",
    "    avg_probs = jnp.mean(probs, axis=(0, 1))  # (15,)\n",
    "    ranked = jnp.argsort(-avg_probs)\n",
    "\n",
    "    print(\"\\nOperation preferences (averaged across all sub-policies):\")\n",
    "    for rank, idx in enumerate(ranked):\n",
    "        idx = int(idx)\n",
    "        print(f\"  {rank + 1:2d}. {op_names[idx]:15s} — {float(avg_probs[idx]):.4f}\")\n",
    "\n",
    "    # Average magnitudes\n",
    "    magnitudes = jax.nn.sigmoid(policy.magnitudes[...])\n",
    "    print(f\"\\nAverage magnitude: {float(jnp.mean(magnitudes)):.4f}\")\n",
    "\n",
    "    # Average probabilities\n",
    "    probs_apply = jax.nn.sigmoid(policy.prob_logits[...])\n",
    "    print(f\"Average apply probability: {float(jnp.mean(probs_apply)):.4f}\")\n",
    "\n",
    "    # Top 3 sub-policies\n",
    "    print(\"\\nTop 3 sub-policies (by max operation probability):\")\n",
    "    for sp_idx in range(min(3, policy.num_sub_policies)):\n",
    "        print(f\"  Sub-policy {sp_idx}:\")\n",
    "        for op_slot in range(policy.ops_per_sub_policy):\n",
    "            slot_probs = probs[sp_idx, op_slot]\n",
    "            top_op = int(jnp.argmax(slot_probs))\n",
    "            mag = float(jax.nn.sigmoid(policy.magnitudes[sp_idx, op_slot]))\n",
    "            prob = float(jax.nn.sigmoid(policy.prob_logits[sp_idx, op_slot]))\n",
    "            print(\n",
    "                f\"    Slot {op_slot}: {op_names[top_op]:15s} \"\n",
    "                f\"(p={float(slot_probs[top_op]):.3f}, mag={mag:.3f}, apply={prob:.3f})\"\n",
    "            )\n",
    "\n",
    "\n",
    "analyze_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize learned policy: operation preferences as bar chart\n",
    "op_names = [name for name, _ in AUGMENTATION_OPS]\n",
    "logits = policy.op_logits[...]  # (25, 2, 15)\n",
    "probs = jax.nn.softmax(logits, axis=-1)\n",
    "avg_probs = np.array(jnp.mean(probs, axis=(0, 1)))  # (15,)\n",
    "ranked_idx = np.argsort(-avg_probs)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart of operation preferences (ranked)\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, NUM_OPS))\n",
    "ranked_names = [op_names[i] for i in ranked_idx]\n",
    "ranked_probs = [float(avg_probs[i]) for i in ranked_idx]\n",
    "bars = ax1.barh(\n",
    "    range(NUM_OPS),\n",
    "    ranked_probs,\n",
    "    color=[colors[i] for i in ranked_idx],\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "ax1.set_yticks(range(NUM_OPS))\n",
    "ax1.set_yticklabels(ranked_names)\n",
    "ax1.set_xlabel(\"Average Selection Probability\")\n",
    "ax1.set_title(\"Learned Operation Preferences (Ranked)\")\n",
    "ax1.invert_yaxis()\n",
    "ax1.grid(True, alpha=0.3, axis=\"x\")\n",
    "for bar, val in zip(bars, ranked_probs):\n",
    "    ax1.text(val + 0.002, bar.get_y() + bar.get_height() / 2, f\"{val:.3f}\", va=\"center\", fontsize=8)\n",
    "\n",
    "# Show augmented samples with learned policy\n",
    "key = jax.random.key(42)\n",
    "sample_images = jnp.array(train_data[\"image\"][:8])\n",
    "model.eval()\n",
    "aug_images = augment_batch(sample_images, policy, key, temperature=0.5)\n",
    "model.train()\n",
    "\n",
    "for i in range(8):\n",
    "    ax2_sub = fig.add_axes([0.55 + (i % 4) * 0.11, 0.55 - (i // 4) * 0.45, 0.1, 0.35])\n",
    "    ax2_sub.imshow(np.clip(np.array(aug_images[i]), 0, 1), interpolation=\"nearest\")\n",
    "    ax2_sub.axis(\"off\")\n",
    "    if i < 4:\n",
    "        ax2_sub.set_title(f\"Aug #{i + 1}\", fontsize=8)\n",
    "\n",
    "ax2.axis(\"off\")\n",
    "ax2.set_title(\"Augmented Samples (learned policy, τ=0.5)\", fontsize=11)\n",
    "\n",
    "fig.suptitle(\"DADA Learned Augmentation Policy Analysis\", fontsize=13)\n",
    "plt.savefig(\n",
    "    OUTPUT_DIR / \"cv-dada-policy-analysis.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(\"Saved: docs/assets/images/examples/cv-dada-policy-analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results & Evaluation\n",
    "\n",
    "### What We Achieved\n",
    "\n",
    "This example demonstrates that datarax's operator library enables\n",
    "differentiable augmentation policy search — the core innovation of DADA.\n",
    "\n",
    "### Expected Results (Full Training)\n",
    "\n",
    "| Configuration | Test Accuracy | Search Cost | Notes |\n",
    "|---------------|---------------|-------------|-------|\n",
    "| No augmentation | ~93.5% | 0 | Baseline WRN-40-2 |\n",
    "| Fixed (flip+crop) | ~95.5% | 0 | Standard practice |\n",
    "| **DADA (learned)** | **~97.0%** | ~0.1 GPU-hrs | Gradient-based search |\n",
    "| DADA (paper) | 97.3% | 0.1 GPU-hrs | Reference result |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Differentiability enables search**: Gumbel-Softmax makes discrete\n",
    "   augmentation selection differentiable, enabling gradient-based policy search.\n",
    "\n",
    "2. **10,000x speedup**: DADA achieves comparable accuracy to AutoAugment\n",
    "   (15,000 GPU-hrs) in ~0.1 GPU-hrs.\n",
    "\n",
    "3. **datarax makes it natural**: Each augmentation operation can be a datarax\n",
    "   operator with learnable parameters. The pipeline is end-to-end differentiable\n",
    "   by construction.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "The learned policy typically favors geometric augmentations (rotation, shear,\n",
    "translation) for CIFAR-10, which makes intuitive sense — these create the most\n",
    "useful training signal for a classifier that needs to recognize objects at\n",
    "different orientations and positions. Color augmentations (brightness, contrast)\n",
    "are usually assigned lower magnitudes and probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps & Resources\n",
    "\n",
    "### Try These Experiments\n",
    "\n",
    "1. **Different architectures**: Replace WRN-40-2 with ResNet-18 or\n",
    "   Vision Transformer (ViT) and compare learned policies.\n",
    "\n",
    "2. **Transfer the policy**: Use the learned policy on a different dataset\n",
    "   (e.g., CIFAR-100, SVHN) — does it generalize?\n",
    "\n",
    "3. **Add more operations**: Extend AUGMENTATION_OPS with new augmentations\n",
    "   (e.g., elastic deformation, grid distortion) and re-run search.\n",
    "\n",
    "4. **Temperature schedule**: Try different annealing schedules (linear,\n",
    "   exponential, cosine) and compare convergence.\n",
    "\n",
    "### Related Examples\n",
    "\n",
    "- [Learned ISP Guide](02_learned_isp_guide.py) — DAG-based differentiable\n",
    "  image processing pipeline\n",
    "- [DDSP Audio Synthesis](03_ddsp_audio_synthesis_guide.py) — Custom operators\n",
    "  for differentiable audio processing\n",
    "- [End-to-End CIFAR-10](../training/01_e2e_cifar10_guide.py) — Standard\n",
    "  training pipeline (non-differentiable augmentation)\n",
    "\n",
    "### API Reference\n",
    "\n",
    "- [OperatorModule](../../../docs/core/operator.md) — Base operator class\n",
    "- [ElementOperator](../../../docs/operators/element_operator.md) — Function wrapping\n",
    "- [DAGExecutor](../../../docs/dag/dag_executor.md) — Pipeline executor\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- [DADA Paper (arXiv)](https://arxiv.org/abs/2003.03780) — Full paper\n",
    "- [Gumbel-Softmax (Jang et al.)](https://arxiv.org/abs/1611.01144) — The relaxation technique\n",
    "- [RELAX (Grathwohl et al.)](https://arxiv.org/abs/1711.00123) — Variance reduction\n",
    "- [AutoAugment (Cubuk et al.)](https://arxiv.org/abs/1805.09501) — The RL baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main entry point for command-line execution.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DADA: Differentiable Automatic Data Augmentation\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Load data\n",
    "    print(\"\\n[1/5] Loading CIFAR-10...\")\n",
    "    train_data, val_data, test_data = load_cifar10()\n",
    "    train_source, val_source, test_source = create_sources(train_data, val_data, test_data)\n",
    "    print(f\"  Train: {train_data['image'].shape}\")\n",
    "    print(f\"  Val:   {val_data['image'].shape}\")\n",
    "    print(f\"  Test:  {test_data['image'].shape}\")\n",
    "\n",
    "    # Run search\n",
    "    print(\"\\n[2/5] Running DADA policy search...\")\n",
    "    model, policy, _ = run_dada_search(\n",
    "        train_source,\n",
    "        val_source,\n",
    "        num_epochs=20,\n",
    "        batch_size=128,\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"\\n[3/5] Evaluating on test set...\")\n",
    "    test_loss, test_acc = evaluate(model, test_source)\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Verify gradient flow\n",
    "    print(\"\\n[4/5] Verifying gradient flow...\")\n",
    "    verify_pipeline = from_source(test_source, batch_size=16)\n",
    "    verify_batch = next(iter(verify_pipeline))\n",
    "    key = jax.random.key(999)\n",
    "\n",
    "    def loss_fn(policy: AugmentationPolicy) -> jax.Array:\n",
    "        aug = augment_batch(verify_batch[\"image\"], policy, key, 0.5)\n",
    "        logits = model(aug)\n",
    "        return cross_entropy_loss(logits, verify_batch[\"label\"])\n",
    "\n",
    "    model.eval()  # Model in closure — prevent BatchNorm mutation\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(policy)\n",
    "    model.train()\n",
    "    grad_leaves = jax.tree.leaves(grads)\n",
    "    assert len(grad_leaves) > 0, \"No gradient leaves\"\n",
    "    assert any(jnp.sum(jnp.abs(g)) > 0 for g in grad_leaves), \"Zero gradients\"\n",
    "    print(f\"  Gradient flow: VERIFIED ({len(grad_leaves)} param groups)\")\n",
    "\n",
    "    # Analyze policy\n",
    "    print(\"\\n[5/5] Analyzing learned policy...\")\n",
    "    analyze_policy(policy)\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DADA search complete!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
