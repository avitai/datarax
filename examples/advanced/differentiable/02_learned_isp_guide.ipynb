{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Learned ISP for Object Detection\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Advanced |\n",
    "| **Runtime** | ~30 min (GPU) / ~3 hrs (CPU) |\n",
    "| **Prerequisites** | JAX, Flax NNX, DAG pipelines, image processing basics |\n",
    "| **Memory** | ~4 GB VRAM (GPU) / ~8 GB RAM (CPU) |\n",
    "| **Devices** | GPU recommended, CPU supported |\n",
    "| **Dataset** | CIFAR-10 (~170 MB, auto-downloaded) |\n",
    "| **Format** | Python + Jupyter |\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example demonstrates how datarax's **DAG executor** enables end-to-end\n",
    "differentiable Image Signal Processing (ISP) pipelines. Inspired by\n",
    "**AdaptiveISP** (Wang et al., NeurIPS 2024), we build a 5-stage ISP pipeline\n",
    "where each stage has learnable parameters optimized jointly with a downstream\n",
    "object detection model via backpropagation.\n",
    "\n",
    "**Key insight**: Traditional camera ISPs are hand-tuned for human perception.\n",
    "By making the ISP pipeline differentiable, we can optimize it for what the\n",
    "*model* needs — dramatically improving detection accuracy on challenging\n",
    "images (e.g., low-light conditions).\n",
    "\n",
    "The AdaptiveISP paper uses **reinforcement learning** to select ISP modules.\n",
    "We show that datarax's differentiable DAG architecture achieves comparable\n",
    "results with a simpler **gradient-based** approach — because when your pipeline\n",
    "is differentiable, you don't need RL.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this example, you will be able to:\n",
    "\n",
    "1. **Build** a multi-stage ISP pipeline using datarax's DAG executor (`>>` operator)\n",
    "2. **Create** custom `ModalityOperator` subclasses with learnable `nnx.Param` parameters\n",
    "3. **Optimize** ISP parameters end-to-end via `nnx.value_and_grad` through the DAG\n",
    "4. **Evaluate** detection accuracy improvements from learned ISP vs. fixed defaults\n",
    "5. **Understand** why gradient-based ISP optimization replaces RL-based approaches\n",
    "\n",
    "## Reference\n",
    "\n",
    "- Paper: Wang et al., \"AdaptiveISP: Learning an Adaptive ISP for Object\n",
    "  Detection\" (NeurIPS 2024) — [arXiv:2410.22939](https://arxiv.org/abs/2410.22939)\n",
    "- Code: [github.com/OpenImagingLab/AdaptiveISP](https://github.com/OpenImagingLab/AdaptiveISP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup & Prerequisites\n",
    "\n",
    "### Required Knowledge\n",
    "- [DAG Fundamentals Guide](../dag/01_dag_fundamentals_guide.py) — `>>` operator, nodes\n",
    "- [Operator Patterns](../../core/02_operators_tutorial.py) — ModalityOperator subclassing\n",
    "- [Datarax Operators](../../core/03_advanced_operators_tutorial.py) — nnx.Param usage\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "# Install datarax with data dependencies\n",
    "uv pip install \"datarax[data]\"\n",
    "```\n",
    "\n",
    "**Estimated Time:** ~30 min on GPU, ~3 hrs on CPU (QUICK_MODE: ~2-5 min GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "from datarax import from_source\n",
    "from datarax.core.element_batch import Batch\n",
    "from datarax.core.modality import ModalityOperator, ModalityOperatorConfig\n",
    "from datarax.dag.dag_executor import DAGExecutor\n",
    "from datarax.dag.nodes import OperatorNode\n",
    "from datarax.operators import (\n",
    "    CompositeOperatorModule,\n",
    "    CompositeOperatorConfig,\n",
    "    CompositionStrategy,\n",
    ")\n",
    "from datarax.sources import MemorySource, MemorySourceConfig\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Output directory for saved figures\n",
    "OUTPUT_DIR = Path(\"docs/assets/images/examples\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Core Concepts\n",
    "\n",
    "### The ISP Pipeline Problem\n",
    "\n",
    "A camera's Image Signal Processing (ISP) pipeline transforms raw sensor data\n",
    "into a viewable image through stages like:\n",
    "\n",
    "1. **Color Correction** (CCM) — maps sensor RGB to standard color space\n",
    "2. **Desaturation** — adjusts color saturation\n",
    "3. **Tone Mapping** — compresses dynamic range\n",
    "4. **Gamma Correction** — adjusts brightness response curve\n",
    "5. **Sharpening** — enhances edge details\n",
    "\n",
    "Traditional ISPs are designed for human perception. But AI models have\n",
    "different needs — a detector might prefer enhanced contrast in shadows over\n",
    "pleasant color rendition.\n",
    "\n",
    "### Gradient-Based vs. RL-Based Optimization\n",
    "\n",
    "AdaptiveISP uses RL to select ISP configurations because their PyTorch pipeline\n",
    "isn't fully differentiable through all ISP stages. With datarax:\n",
    "- Each ISP stage is an `OperatorNode` with `nnx.Param` parameters\n",
    "- The DAG executor chains them with `>>` (operator composition)\n",
    "- `nnx.value_and_grad` computes gradients through the entire pipeline\n",
    "- No RL needed — direct gradient descent optimizes ISP parameters\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                  Differentiable ISP Pipeline (DAG)                 │\n",
    "│                                                                    │\n",
    "│  RAW Image ──→ [CCM] ──→ [Desat] ──→ [Tone] ──→ [Gamma] ──→ [Sharp] │\n",
    "│  MemorySource   │          │           │          │          │     │\n",
    "│                 │          │           │          │          │     │\n",
    "│            nnx.Param   nnx.Param   nnx.Param  nnx.Param  nnx.Param │\n",
    "│            (3×3 mat)   (strength)  (16 pts)   (gamma)    (kernel) │\n",
    "│                                                                    │\n",
    "│  ──→ Object Detector ──→ Detection Loss                           │\n",
    "│       (frozen)             │                                       │\n",
    "│                    ┌───────┘                                       │\n",
    "│                    ▼                                               │\n",
    "│              jax.grad flows back through ALL ISP stages            │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "Each blue box is an `OperatorNode` in the DAG. The `>>` operator chains them\n",
    "into a sequential pipeline that supports automatic differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Implementation\n",
    "\n",
    "### Step 1: Load CIFAR-10 with Low-Light Simulation\n",
    "\n",
    "We load real images from CIFAR-10 via `tensorflow_datasets` and simulate\n",
    "low-light conditions by darkening and adding sensor noise. This produces a\n",
    "realistic training scenario: the ISP must learn to recover image content\n",
    "that helps the downstream classifier. In production, you would use the LOD\n",
    "dataset from the AdaptiveISP paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load CIFAR-10 and simulate low-light conditions\n",
    "\n",
    "\n",
    "def load_cifar10_lowlight(\n",
    "    split: str = \"train\",\n",
    "    seed: int = 42,\n",
    ") -> tuple[dict[str, jax.Array], MemorySource]:\n",
    "    \"\"\"Load CIFAR-10 and simulate low-light conditions.\n",
    "\n",
    "    Simulates low-light by:\n",
    "    - Reducing brightness (per-image random factor in [0.1, 0.3])\n",
    "    - Adding Gaussian noise (sigma=0.02, simulating high ISO)\n",
    "\n",
    "    Args:\n",
    "        split: TFDS split string (e.g., \"train\", \"test\", \"train[:2000]\")\n",
    "        seed: Random seed for reproducible low-light simulation\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (data dict with JAX arrays, MemorySource wrapping the data).\n",
    "        The data dict contains 'image' (darkened), 'label', and 'clean_image'.\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    # Prevent TF from allocating GPU memory (only JAX needs the GPU)\n",
    "    tf.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "    # Load entire split as numpy arrays (CIFAR-10 is ~170 MB, fits in memory)\n",
    "    data = tfds.load(\"cifar10\", split=split, as_supervised=True, batch_size=-1)\n",
    "    images, labels = tfds.as_numpy(data)\n",
    "\n",
    "    # Normalize uint8 → float32 [0, 1]\n",
    "    clean_images = images.astype(np.float32) / 255.0\n",
    "    labels = labels.astype(np.int32)\n",
    "\n",
    "    # Simulate low-light: per-image random darkening + Gaussian noise\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n = len(clean_images)\n",
    "    brightness_factor = rng.uniform(0.1, 0.3, size=(n, 1, 1, 1)).astype(np.float32)\n",
    "    dark_images = clean_images * brightness_factor\n",
    "    noise = rng.normal(0, 0.02, dark_images.shape).astype(np.float32)\n",
    "    raw_images = np.clip(dark_images + noise, 0, 1).astype(np.float32)\n",
    "\n",
    "    # Convert to JAX arrays and wrap in MemorySource\n",
    "    data_dict = {\n",
    "        \"image\": jnp.array(raw_images),\n",
    "        \"label\": jnp.array(labels),\n",
    "        \"clean_image\": jnp.array(clean_images),\n",
    "    }\n",
    "    source = MemorySource(MemorySourceConfig(), data=data_dict, rngs=nnx.Rngs(seed))\n",
    "    return data_dict, source\n",
    "\n",
    "\n",
    "# Load CIFAR-10 train/test with low-light simulation\n",
    "print(\"Loading CIFAR-10 with low-light simulation...\")\n",
    "train_data, train_source = load_cifar10_lowlight(split=\"train[:2000]\", seed=42)\n",
    "test_data, test_source = load_cifar10_lowlight(split=\"test[:500]\", seed=99)\n",
    "\n",
    "print(\n",
    "    f\"Train images: {train_data['image'].shape}, range: \"\n",
    "    f\"[{float(train_data['image'].min()):.3f}, {float(train_data['image'].max()):.3f}]\"\n",
    ")\n",
    "print(f\"Test images:  {test_data['image'].shape}\")\n",
    "# Expected output:\n",
    "# Train images: (2000, 32, 32, 3), range: [0.000, ~0.300]\n",
    "# Test images:  (500, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clean vs. dark CIFAR-10 samples\n",
    "CIFAR10_CLASSES = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "for i in range(8):\n",
    "    # Clean image (top row)\n",
    "    clean_img = np.array(train_data[\"clean_image\"][i])\n",
    "    axes[0, i].imshow(clean_img, interpolation=\"nearest\")\n",
    "    label = int(train_data[\"label\"][i])\n",
    "    axes[0, i].set_title(CIFAR10_CLASSES[label], fontsize=9)\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    # Dark image — raw (middle row)\n",
    "    dark_img = np.array(train_data[\"image\"][i])\n",
    "    axes[1, i].imshow(dark_img, interpolation=\"nearest\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "    # Dark image — brightened 4x for visibility (bottom row)\n",
    "    axes[2, i].imshow(np.clip(dark_img * 4, 0, 1), interpolation=\"nearest\")\n",
    "    axes[2, i].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Clean\", fontsize=10, rotation=0, labelpad=45)\n",
    "axes[1, 0].set_ylabel(\"Dark\", fontsize=10, rotation=0, labelpad=45)\n",
    "axes[2, 0].set_ylabel(\"Dark (4x)\", fontsize=10, rotation=0, labelpad=45)\n",
    "fig.suptitle(\n",
    "    \"CIFAR-10: Clean vs. Low-Light Simulated Images\\n\"\n",
    "    \"(Dark images are nearly black — the ISP must recover content for the classifier)\",\n",
    "    fontsize=12,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    OUTPUT_DIR / \"cv-isp-dark-vs-clean-samples.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(\"Saved: docs/assets/images/examples/cv-isp-dark-vs-clean-samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "### Step 2: Define ISP Operators as ModalityOperators\n",
    "\n",
    "Each ISP stage extends `ModalityOperator` (for `_extract_field` / `_remap_field`\n",
    "helpers) and adds `nnx.Param` parameters that will be optimized via gradients.\n",
    "\n",
    "The operator pattern follows BrightnessOperator:\n",
    "1. Companion `Config` dataclass extending `ModalityOperatorConfig`\n",
    "2. `__init__` creates `nnx.Param` learnable parameters\n",
    "3. `apply()` uses `_extract_field` → transform → `_apply_clip_range` → `_remap_field`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define 5 ISP operators\n",
    "\n",
    "\n",
    "# --- Operator 1: Color Correction Matrix (CCM) ---\n",
    "@dataclass\n",
    "class CCMConfig(ModalityOperatorConfig):\n",
    "    \"\"\"Configuration for Color Correction Matrix operator.\"\"\"\n",
    "\n",
    "    clip_range: tuple[float, float] | None = field(default=(0.0, 1.0), kw_only=True)\n",
    "\n",
    "\n",
    "class CCMOperator(ModalityOperator):\n",
    "    \"\"\"Color Correction Matrix — learned 3x3 linear color transform.\n",
    "\n",
    "    Maps sensor RGB to a task-optimized color space via matrix multiplication.\n",
    "    Initialized to identity (no color change); gradients learn the optimal\n",
    "    color mapping for the downstream task.\n",
    "\n",
    "    Matches AdaptiveISP paper's CCM module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: CCMConfig, *, rngs: nnx.Rngs):\n",
    "        super().__init__(config, rngs=rngs)\n",
    "        self.config: CCMConfig = config\n",
    "        # Learnable 3x3 color correction matrix (init = identity)\n",
    "        self.ccm = nnx.Param(jnp.eye(3))\n",
    "\n",
    "    def apply(\n",
    "        self,\n",
    "        data: dict[str, Any],\n",
    "        state: dict[str, Any],\n",
    "        metadata: dict[str, Any] | None,\n",
    "        random_params: Any = None,\n",
    "        stats: dict[str, Any] | None = None,\n",
    "    ) -> tuple[dict[str, Any], dict[str, Any], dict[str, Any] | None]:\n",
    "        image = self._extract_field(data, self.config.field_key)\n",
    "        # Apply color correction: output_rgb = input_rgb @ CCM\n",
    "        transformed = jnp.einsum(\"...c,cd->...d\", image, self.ccm[...])\n",
    "        transformed = self._apply_clip_range(transformed)\n",
    "        result = self._remap_field(data, transformed)\n",
    "        return result, state, metadata\n",
    "\n",
    "\n",
    "# --- Operator 2: Desaturation ---\n",
    "@dataclass\n",
    "class DesaturationConfig(ModalityOperatorConfig):\n",
    "    \"\"\"Configuration for Desaturation operator.\"\"\"\n",
    "\n",
    "    clip_range: tuple[float, float] | None = field(default=(0.0, 1.0), kw_only=True)\n",
    "\n",
    "\n",
    "class DesaturationOperator(ModalityOperator):\n",
    "    \"\"\"Learnable desaturation — blends color image with grayscale.\n",
    "\n",
    "    Strength=0 means full color, strength=1 means fully grayscale.\n",
    "    The optimal saturation level for detection may differ from human preference.\n",
    "\n",
    "    Matches AdaptiveISP paper's desaturation module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: DesaturationConfig, *, rngs: nnx.Rngs):\n",
    "        super().__init__(config, rngs=rngs)\n",
    "        self.config: DesaturationConfig = config\n",
    "        # Learnable desaturation strength (init = 0 = no desaturation)\n",
    "        self.strength = nnx.Param(jnp.array(0.0))\n",
    "\n",
    "    def apply(\n",
    "        self,\n",
    "        data: dict[str, Any],\n",
    "        state: dict[str, Any],\n",
    "        metadata: dict[str, Any] | None,\n",
    "        random_params: Any = None,\n",
    "        stats: dict[str, Any] | None = None,\n",
    "    ) -> tuple[dict[str, Any], dict[str, Any], dict[str, Any] | None]:\n",
    "        image = self._extract_field(data, self.config.field_key)\n",
    "        strength = jax.nn.sigmoid(self.strength[...])  # Constrain to [0, 1]\n",
    "        gray = jnp.mean(image, axis=-1, keepdims=True)\n",
    "        gray = jnp.broadcast_to(gray, image.shape)\n",
    "        transformed = image * (1.0 - strength) + gray * strength\n",
    "        transformed = self._apply_clip_range(transformed)\n",
    "        result = self._remap_field(data, transformed)\n",
    "        return result, state, metadata\n",
    "\n",
    "\n",
    "# --- Operator 3: Tone Mapping ---\n",
    "@dataclass\n",
    "class ToneMappingConfig(ModalityOperatorConfig):\n",
    "    \"\"\"Configuration for Tone Mapping operator.\"\"\"\n",
    "\n",
    "    num_control_points: int = field(default=16, kw_only=True)\n",
    "    clip_range: tuple[float, float] | None = field(default=(0.0, 1.0), kw_only=True)\n",
    "\n",
    "\n",
    "class ToneMappingOperator(ModalityOperator):\n",
    "    \"\"\"Learnable piecewise-linear tone mapping curve.\n",
    "\n",
    "    Uses N control points to define a flexible tone curve. Each control point's\n",
    "    y-value is learnable; x-values are uniformly spaced in [0, 1].\n",
    "    Initialized to identity (y = x).\n",
    "\n",
    "    Matches AdaptiveISP paper's tone mapping module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ToneMappingConfig, *, rngs: nnx.Rngs):\n",
    "        super().__init__(config, rngs=rngs)\n",
    "        self.config: ToneMappingConfig = config\n",
    "        # Learnable control points (init = identity curve: y = x)\n",
    "        self.control_points = nnx.Param(jnp.linspace(0.0, 1.0, config.num_control_points))\n",
    "\n",
    "    def apply(\n",
    "        self,\n",
    "        data: dict[str, Any],\n",
    "        state: dict[str, Any],\n",
    "        metadata: dict[str, Any] | None,\n",
    "        random_params: Any = None,\n",
    "        stats: dict[str, Any] | None = None,\n",
    "    ) -> tuple[dict[str, Any], dict[str, Any], dict[str, Any] | None]:\n",
    "        image = self._extract_field(data, self.config.field_key)\n",
    "        # Apply piecewise-linear tone curve per channel\n",
    "        n = self.config.num_control_points\n",
    "        x_points = jnp.linspace(0.0, 1.0, n)\n",
    "        y_points = jax.nn.sigmoid(self.control_points[...])  # Ensure monotonic-ish\n",
    "\n",
    "        # Sort y_points to encourage monotonicity (soft sort via cumulative sigmoid)\n",
    "        y_sorted = jnp.sort(y_points)\n",
    "\n",
    "        # Piecewise linear interpolation\n",
    "        transformed = jnp.interp(image.ravel(), x_points, y_sorted).reshape(image.shape)\n",
    "        transformed = self._apply_clip_range(transformed)\n",
    "        result = self._remap_field(data, transformed)\n",
    "        return result, state, metadata\n",
    "\n",
    "\n",
    "# --- Operator 4: Gamma Correction ---\n",
    "@dataclass\n",
    "class GammaCorrectionConfig(ModalityOperatorConfig):\n",
    "    \"\"\"Configuration for Gamma Correction operator.\"\"\"\n",
    "\n",
    "    clip_range: tuple[float, float] | None = field(default=(0.0, 1.0), kw_only=True)\n",
    "\n",
    "\n",
    "class GammaCorrectionOperator(ModalityOperator):\n",
    "    \"\"\"Learnable gamma correction — adjusts brightness response curve.\n",
    "\n",
    "    output = input^gamma. Gamma < 1 brightens, gamma > 1 darkens.\n",
    "    Critical for low-light images where the detector needs brighter shadows.\n",
    "\n",
    "    Matches AdaptiveISP paper's gamma module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: GammaCorrectionConfig, *, rngs: nnx.Rngs):\n",
    "        super().__init__(config, rngs=rngs)\n",
    "        self.config: GammaCorrectionConfig = config\n",
    "        # Learnable gamma (init = 1.0 = identity)\n",
    "        # Store as log(gamma) for unconstrained optimization\n",
    "        self.log_gamma = nnx.Param(jnp.array(0.0))\n",
    "\n",
    "    def apply(\n",
    "        self,\n",
    "        data: dict[str, Any],\n",
    "        state: dict[str, Any],\n",
    "        metadata: dict[str, Any] | None,\n",
    "        random_params: Any = None,\n",
    "        stats: dict[str, Any] | None = None,\n",
    "    ) -> tuple[dict[str, Any], dict[str, Any], dict[str, Any] | None]:\n",
    "        image = self._extract_field(data, self.config.field_key)\n",
    "        gamma = jnp.exp(self.log_gamma[...])  # Always positive\n",
    "        gamma = jnp.clip(gamma, 0.1, 5.0)  # Reasonable range\n",
    "        transformed = jnp.power(jnp.clip(image, 1e-6, 1.0), gamma)\n",
    "        transformed = self._apply_clip_range(transformed)\n",
    "        result = self._remap_field(data, transformed)\n",
    "        return result, state, metadata\n",
    "\n",
    "\n",
    "# --- Operator 5: Sharpening ---\n",
    "@dataclass\n",
    "class SharpeningConfig(ModalityOperatorConfig):\n",
    "    \"\"\"Configuration for Sharpening operator.\"\"\"\n",
    "\n",
    "    clip_range: tuple[float, float] | None = field(default=(0.0, 1.0), kw_only=True)\n",
    "\n",
    "\n",
    "class SharpeningOperator(ModalityOperator):\n",
    "    \"\"\"Learnable unsharp masking with trainable kernel and strength.\n",
    "\n",
    "    Applies: output = image + strength * (image - blur(image))\n",
    "    where blur uses a learnable 3x3 kernel. Both the kernel weights\n",
    "    and sharpening strength are optimized via gradients.\n",
    "\n",
    "    Matches AdaptiveISP paper's sharpening module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: SharpeningConfig, *, rngs: nnx.Rngs):\n",
    "        super().__init__(config, rngs=rngs)\n",
    "        self.config: SharpeningConfig = config\n",
    "        # Learnable sharpening strength\n",
    "        self.strength = nnx.Param(jnp.array(0.5))\n",
    "        # Learnable 3x3 blur kernel (init = approximate Gaussian)\n",
    "        init_kernel = (\n",
    "            jnp.array(\n",
    "                [\n",
    "                    [1.0, 2.0, 1.0],\n",
    "                    [2.0, 4.0, 2.0],\n",
    "                    [1.0, 2.0, 1.0],\n",
    "                ]\n",
    "            )\n",
    "            / 16.0\n",
    "        )\n",
    "        self.kernel = nnx.Param(init_kernel)\n",
    "\n",
    "    def apply(\n",
    "        self,\n",
    "        data: dict[str, Any],\n",
    "        state: dict[str, Any],\n",
    "        metadata: dict[str, Any] | None,\n",
    "        random_params: Any = None,\n",
    "        stats: dict[str, Any] | None = None,\n",
    "    ) -> tuple[dict[str, Any], dict[str, Any], dict[str, Any] | None]:\n",
    "        image = self._extract_field(data, self.config.field_key)\n",
    "        strength = jax.nn.sigmoid(self.strength[...])\n",
    "\n",
    "        # Apply blur using depthwise convolution (single XLA op)\n",
    "        kernel = self.kernel[...]\n",
    "        kernel = kernel / (jnp.sum(kernel) + 1e-6)  # Normalize\n",
    "\n",
    "        h, w, c = image.shape\n",
    "        padded = jnp.pad(image, ((1, 1), (1, 1), (0, 0)), mode=\"edge\")\n",
    "        # Depthwise conv: same kernel applied independently per channel\n",
    "        kernel_conv = jnp.tile(kernel[:, :, None, None], (1, 1, 1, c))  # (3, 3, 1, C)\n",
    "        blurred = jax.lax.conv_general_dilated(\n",
    "            padded[None, ...],  # (1, H+2, W+2, C)\n",
    "            kernel_conv,\n",
    "            window_strides=(1, 1),\n",
    "            padding=\"VALID\",\n",
    "            dimension_numbers=(\"NHWC\", \"HWIO\", \"NHWC\"),\n",
    "            feature_group_count=c,\n",
    "        )[0]  # (H, W, C)\n",
    "\n",
    "        # Unsharp mask: enhance edges\n",
    "        detail = image - blurred\n",
    "        transformed = image + strength * detail\n",
    "        transformed = self._apply_clip_range(transformed)\n",
    "        result = self._remap_field(data, transformed)\n",
    "        return result, state, metadata\n",
    "\n",
    "\n",
    "# Verify operators\n",
    "print(\"Verifying ISP operators...\")\n",
    "rngs = nnx.Rngs(0)\n",
    "test_image_data = {\"image\": jnp.ones((32, 32, 3)) * 0.2}  # Dark image\n",
    "\n",
    "for OpClass, ConfigClass, name in [\n",
    "    (CCMOperator, CCMConfig, \"CCM\"),\n",
    "    (DesaturationOperator, DesaturationConfig, \"Desaturation\"),\n",
    "    (ToneMappingOperator, ToneMappingConfig, \"ToneMapping\"),\n",
    "    (GammaCorrectionOperator, GammaCorrectionConfig, \"GammaCorrection\"),\n",
    "    (SharpeningOperator, SharpeningConfig, \"Sharpening\"),\n",
    "]:\n",
    "    config = ConfigClass(field_key=\"image\")\n",
    "    op = OpClass(config, rngs=rngs)\n",
    "    out_data, _, _ = op.apply(test_image_data, {}, {})\n",
    "    n_params = sum(p.size for p in jax.tree.leaves(nnx.state(op, nnx.Param)))\n",
    "    print(\n",
    "        f\"  {name:15s} | params: {n_params:4d} | \"\n",
    "        f\"output range: [{float(out_data['image'].min()):.3f}, \"\n",
    "        f\"{float(out_data['image'].max()):.3f}]\"\n",
    "    )\n",
    "\n",
    "# Expected output:\n",
    "# CCM            | params:    9 | output range: [0.200, 0.200]\n",
    "# Desaturation   | params:    1 | output range: [0.200, 0.200]\n",
    "# ToneMapping    | params:   16 | output range: [0.000, 1.000]\n",
    "# GammaCorrection| params:    1 | output range: [0.200, 0.200]\n",
    "# Sharpening     | params:   10 | output range: [0.200, 0.200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 3: Build ISP Pipeline\n",
    "\n",
    "This step creates the ISP operators and composes them two ways:\n",
    "\n",
    "1. **DAG pipeline** (`>>` operator) — for data loading and inference demos\n",
    "2. **`CompositeOperatorModule(SEQUENTIAL)`** — for training, where the composite\n",
    "   chains all 5 operators internally and supports `nnx.value_and_grad`\n",
    "\n",
    "The composite is the training-time counterpart of the DAG `>>` pipeline: both\n",
    "chain the same operators sequentially, but the composite is a single NNX module\n",
    "that can be passed directly to `nnx.Optimizer` and `nnx.value_and_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compose ISP pipeline using DAG executor\n",
    "def create_isp_pipeline(\n",
    "    source: MemorySource,\n",
    "    batch_size: int = 32,\n",
    ") -> tuple[CompositeOperatorModule, DAGExecutor]:\n",
    "    \"\"\"Create the 5-stage ISP pipeline in two forms.\n",
    "\n",
    "    Returns:\n",
    "        isp_composite: CompositeOperatorModule(SEQUENTIAL) for training\n",
    "        pipeline: DAGExecutor for data loading demos\n",
    "    \"\"\"\n",
    "    rngs = nnx.Rngs(0)\n",
    "\n",
    "    # Create operators with learnable parameters\n",
    "    ccm = CCMOperator(CCMConfig(field_key=\"image\"), rngs=rngs)\n",
    "    desat = DesaturationOperator(DesaturationConfig(field_key=\"image\"), rngs=rngs)\n",
    "    tonemap = ToneMappingOperator(ToneMappingConfig(field_key=\"image\"), rngs=rngs)\n",
    "    gamma = GammaCorrectionOperator(GammaCorrectionConfig(field_key=\"image\"), rngs=rngs)\n",
    "    sharpen = SharpeningOperator(SharpeningConfig(field_key=\"image\"), rngs=rngs)\n",
    "\n",
    "    # Training: CompositeOperatorModule(SEQUENTIAL) chains operators internally\n",
    "    isp_composite = CompositeOperatorModule(\n",
    "        CompositeOperatorConfig(\n",
    "            strategy=CompositionStrategy.SEQUENTIAL,\n",
    "            operators=[ccm, desat, tonemap, gamma, sharpen],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Inference demo: DAG pipeline using >> operator (shares same operator instances)\n",
    "    pipeline = (\n",
    "        from_source(source, batch_size=batch_size)\n",
    "        >> OperatorNode(ccm)\n",
    "        >> OperatorNode(desat)\n",
    "        >> OperatorNode(tonemap)\n",
    "        >> OperatorNode(gamma)\n",
    "        >> OperatorNode(sharpen)\n",
    "    )\n",
    "\n",
    "    return isp_composite, pipeline\n",
    "\n",
    "\n",
    "# Build pipeline\n",
    "isp_composite, isp_pipeline = create_isp_pipeline(train_source, batch_size=32)\n",
    "\n",
    "# Count total ISP parameters (composite tracks all child operator params)\n",
    "total_isp_params = sum(p.size for p in jax.tree.leaves(nnx.state(isp_composite, nnx.Param)))\n",
    "print(\"\\nISP Pipeline created:\")\n",
    "print(\"  Training:  CompositeOperatorModule(SEQUENTIAL) with 5 operators\")\n",
    "print(\"  Inference: DAG pipeline with >> operator\")\n",
    "print(f\"Total ISP parameters: {total_isp_params}\")\n",
    "print(\"Pipeline stages: CCM >> Desaturation >> ToneMapping >> Gamma >> Sharpen\")\n",
    "\n",
    "# Process one batch to verify (uses DAG pipeline)\n",
    "first_batch = next(iter(isp_pipeline))\n",
    "print(f\"\\nProcessed batch shape: {first_batch['image'].shape}\")\n",
    "print(\n",
    "    f\"Output range: [{float(first_batch['image'].min()):.3f}, \"\n",
    "    f\"{float(first_batch['image'].max()):.3f}]\"\n",
    ")\n",
    "# Expected output:\n",
    "# ISP Pipeline created:\n",
    "#   Training:  CompositeOperatorModule(SEQUENTIAL) with 5 operators\n",
    "#   Inference: DAG pipeline with >> operator\n",
    "# Total ISP parameters: 37\n",
    "# Pipeline stages: CCM >> Desaturation >> ToneMapping >> Gamma >> Sharpen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 4: CNN Detector (Artifex-Style Layer Construction)\n",
    "\n",
    "We use a lightweight CNN classifier as a stand-in for a full object detector.\n",
    "The key point is that gradients flow from the classification loss back through\n",
    "the detector and into the ISP pipeline.\n",
    "\n",
    "The detector follows artifex's layer construction pattern: `nnx.List` for\n",
    "conv and batch norm collections, with a loop-based forward pass. This is\n",
    "cleaner than hand-enumerating conv1/conv2/conv3/conv4 fields and scales\n",
    "to any depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: CNN detector using artifex-style nnx.List layer construction\n",
    "class CNNDetector(nnx.Module):\n",
    "    \"\"\"Lightweight CNN for classification on ISP-processed images.\n",
    "\n",
    "    Uses artifex-style layer construction: ``nnx.List`` for conv and batch\n",
    "    norm collections, with a loop-based forward pass.  In the full\n",
    "    AdaptiveISP setup this would be YOLOv3 with Darknet-53 backbone.\n",
    "\n",
    "    Architecture for 32x32 CIFAR-10 input::\n",
    "\n",
    "        Conv(3->32, 3x3, stride=2) -> BN -> ReLU   # -> 16x16\n",
    "        Conv(32->64, 3x3, stride=2) -> BN -> ReLU  # -> 8x8\n",
    "        Conv(64->128, 3x3, stride=2) -> BN -> ReLU # -> 4x4\n",
    "        Conv(128->256, 3x3, stride=2) -> BN -> ReLU # -> 2x2\n",
    "        GlobalAvgPool -> Linear(256->10)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int = 10, *, rngs: nnx.Rngs):\n",
    "        hidden_dims = [32, 64, 128, 256]\n",
    "        in_features = 3\n",
    "\n",
    "        self.conv_layers = nnx.List([])\n",
    "        self.batch_norms = nnx.List([])\n",
    "\n",
    "        current_in = in_features\n",
    "        for dim in hidden_dims:\n",
    "            self.conv_layers.append(\n",
    "                nnx.Conv(\n",
    "                    current_in,\n",
    "                    dim,\n",
    "                    kernel_size=(3, 3),\n",
    "                    strides=(2, 2),\n",
    "                    padding=\"SAME\",\n",
    "                    rngs=rngs,\n",
    "                )\n",
    "            )\n",
    "            self.batch_norms.append(nnx.BatchNorm(dim, rngs=rngs))\n",
    "            current_in = dim\n",
    "\n",
    "        self.head = nnx.Linear(hidden_dims[-1], num_classes, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        \"\"\"Forward pass. Input: (B, 32, 32, 3), Output: (B, num_classes).\"\"\"\n",
    "        for conv, bn in zip(self.conv_layers, self.batch_norms):\n",
    "            x = nnx.relu(bn(conv(x)))\n",
    "        x = jnp.mean(x, axis=(1, 2))  # Global average pooling\n",
    "        return self.head(x)\n",
    "\n",
    "\n",
    "# Create and verify detector\n",
    "detector = CNNDetector(num_classes=10, rngs=nnx.Rngs(42))\n",
    "dummy_processed = jnp.ones((2, 32, 32, 3)) * 0.5\n",
    "dummy_logits = detector(dummy_processed)\n",
    "print(f\"Detector output shape: {dummy_logits.shape}\")\n",
    "n_det_params = sum(p.size for p in jax.tree.leaves(nnx.state(detector, nnx.Param)))\n",
    "print(f\"Detector parameters: {n_det_params:,}\")\n",
    "# Expected output:\n",
    "# Detector output shape: (2, 10)\n",
    "# Detector parameters: ~391,946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "### Step 5: End-to-End Training with Gradient Flow Through Composite\n",
    "\n",
    "This is where it all comes together. We define a loss function that:\n",
    "1. Runs images through the ISP composite (`CompositeOperatorModule(SEQUENTIAL)`)\n",
    "2. Feeds processed images to the detector\n",
    "3. Computes classification loss\n",
    "\n",
    "The `CompositeOperatorModule(SEQUENTIAL)` replaces a manual operator loop:\n",
    "instead of manually creating intermediate `Batch` objects per operator, the\n",
    "sequential strategy chains `.apply()` calls internally — output of op_N feeds\n",
    "as input to op_N+1.\n",
    "\n",
    "`nnx.value_and_grad` computes gradients that flow from the loss all the way\n",
    "back through the detector AND all 5 ISP stages inside the composite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Training with gradient flow through the DAG\n",
    "\n",
    "\n",
    "def cross_entropy_loss(logits: jax.Array, labels: jax.Array) -> jax.Array:\n",
    "    \"\"\"Compute cross-entropy loss.\"\"\"\n",
    "    one_hot = jax.nn.one_hot(labels, logits.shape[-1])\n",
    "    return -jnp.mean(jnp.sum(one_hot * jax.nn.log_softmax(logits), axis=-1))\n",
    "\n",
    "\n",
    "def accuracy(logits: jax.Array, labels: jax.Array) -> jax.Array:\n",
    "    \"\"\"Compute classification accuracy.\"\"\"\n",
    "    return jnp.mean(jnp.argmax(logits, axis=-1) == labels)\n",
    "\n",
    "\n",
    "def apply_isp_composite(\n",
    "    isp_composite: CompositeOperatorModule,\n",
    "    images: jax.Array,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Apply ISP pipeline using CompositeOperatorModule(SEQUENTIAL).\n",
    "\n",
    "    The sequential strategy chains all 5 operators internally — no manual\n",
    "    loop or intermediate Batch objects needed.\n",
    "    \"\"\"\n",
    "    batch = Batch.from_parts(data={\"image\": images}, states={})\n",
    "    result = isp_composite(batch)\n",
    "    return result.get_data()[\"image\"]\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def _isp_step_frozen(\n",
    "    isp_composite: CompositeOperatorModule,\n",
    "    detector: CNNDetector,\n",
    "    isp_optimizer: nnx.Optimizer,\n",
    "    images: jax.Array,\n",
    "    labels: jax.Array,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Phase 1: optimize ISP only (detector frozen in eval mode).\"\"\"\n",
    "\n",
    "    def loss_fn(isp_composite: CompositeOperatorModule) -> jax.Array:\n",
    "        processed = apply_isp_composite(isp_composite, images)\n",
    "        return cross_entropy_loss(detector(processed), labels)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(isp_composite)\n",
    "    isp_optimizer.update(isp_composite, grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def _isp_step_joint(\n",
    "    isp_composite: CompositeOperatorModule,\n",
    "    detector: CNNDetector,\n",
    "    isp_optimizer: nnx.Optimizer,\n",
    "    det_optimizer: nnx.Optimizer,\n",
    "    images: jax.Array,\n",
    "    labels: jax.Array,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Phase 2: jointly optimize ISP + detector.\"\"\"\n",
    "\n",
    "    def loss_fn(\n",
    "        isp_composite: CompositeOperatorModule,\n",
    "        detector: CNNDetector,\n",
    "    ) -> jax.Array:\n",
    "        processed = apply_isp_composite(isp_composite, images)\n",
    "        return cross_entropy_loss(detector(processed), labels)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn, argnums=(0, 1))(isp_composite, detector)\n",
    "    isp_grads, det_grads = grads\n",
    "    isp_optimizer.update(isp_composite, isp_grads)\n",
    "    det_optimizer.update(detector, det_grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    isp_composite: CompositeOperatorModule,\n",
    "    detector: CNNDetector,\n",
    "    isp_optimizer: nnx.Optimizer,\n",
    "    det_optimizer: nnx.Optimizer,\n",
    "    source: MemorySource,\n",
    "    batch_size: int,\n",
    "    freeze_detector: bool = False,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Train for one epoch with gradient flow through ISP composite.\n",
    "\n",
    "    Args:\n",
    "        isp_composite: CompositeOperatorModule(SEQUENTIAL) wrapping ISP ops\n",
    "        detector: CNN detector\n",
    "        isp_optimizer: Optimizer for ISP parameters\n",
    "        det_optimizer: Optimizer for detector parameters\n",
    "        source: Training data source\n",
    "        batch_size: Batch size\n",
    "        freeze_detector: If True, only optimize ISP (phase 1)\n",
    "\n",
    "    Returns:\n",
    "        Average loss and accuracy for the epoch\n",
    "    \"\"\"\n",
    "    pipeline = from_source(source, batch_size=batch_size)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_steps = 0\n",
    "\n",
    "    for batch in pipeline:\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        if freeze_detector:\n",
    "            detector.eval()\n",
    "            loss = _isp_step_frozen(\n",
    "                isp_composite,\n",
    "                detector,\n",
    "                isp_optimizer,\n",
    "                images,\n",
    "                labels,\n",
    "            )\n",
    "        else:\n",
    "            detector.train()\n",
    "            loss = _isp_step_joint(\n",
    "                isp_composite,\n",
    "                detector,\n",
    "                isp_optimizer,\n",
    "                det_optimizer,\n",
    "                images,\n",
    "                labels,\n",
    "            )\n",
    "\n",
    "        # Compute accuracy for logging (eval mode — no stat updates)\n",
    "        detector.eval()\n",
    "        processed = apply_isp_composite(isp_composite, images)\n",
    "        logits = detector(processed)\n",
    "        acc = accuracy(logits, labels)\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        total_acc += float(acc)\n",
    "        num_steps += 1\n",
    "\n",
    "    return total_loss / max(num_steps, 1), total_acc / max(num_steps, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 6: Run Training\n",
    "\n",
    "We use a two-phase training protocol (matching AdaptiveISP):\n",
    "1. **Phase 1**: Freeze detector, optimize only ISP parameters (learn to preprocess)\n",
    "2. **Phase 2**: Joint optimization of ISP + detector (fine-tune together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Training loop\n",
    "def run_training(\n",
    "    train_source: MemorySource,\n",
    "    test_source: MemorySource,\n",
    "    phase1_epochs: int = 5,\n",
    "    phase2_epochs: int = 10,\n",
    "    batch_size: int = 32,\n",
    "    lr_isp: float = 1e-2,\n",
    "    lr_detector: float = 1e-3,\n",
    ") -> tuple[CompositeOperatorModule, CNNDetector, dict]:\n",
    "    \"\"\"Run two-phase ISP + detector training.\n",
    "\n",
    "    Returns (isp_composite, detector, history) where history tracks\n",
    "    per-epoch loss and accuracy for visualization.\n",
    "    \"\"\"\n",
    "    rngs = nnx.Rngs(42)\n",
    "\n",
    "    # Create ISP operators and compose into SEQUENTIAL composite\n",
    "    ccm = CCMOperator(CCMConfig(field_key=\"image\"), rngs=rngs)\n",
    "    desat = DesaturationOperator(DesaturationConfig(field_key=\"image\"), rngs=rngs)\n",
    "    tonemap = ToneMappingOperator(ToneMappingConfig(field_key=\"image\"), rngs=rngs)\n",
    "    gamma_op = GammaCorrectionOperator(GammaCorrectionConfig(field_key=\"image\"), rngs=rngs)\n",
    "    sharpen = SharpeningOperator(SharpeningConfig(field_key=\"image\"), rngs=rngs)\n",
    "    isp_composite = CompositeOperatorModule(\n",
    "        CompositeOperatorConfig(\n",
    "            strategy=CompositionStrategy.SEQUENTIAL,\n",
    "            operators=[ccm, desat, tonemap, gamma_op, sharpen],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create detector\n",
    "    detector = CNNDetector(num_classes=10, rngs=rngs)\n",
    "\n",
    "    # Optimizers (composite is a single NNX module tracking all ISP params)\n",
    "    isp_optimizer = nnx.Optimizer(isp_composite, optax.adam(lr_isp), wrt=nnx.Param)\n",
    "    det_optimizer = nnx.Optimizer(detector, optax.adam(lr_detector), wrt=nnx.Param)\n",
    "\n",
    "    # Track training history for visualization\n",
    "    history: dict = {\n",
    "        \"phase\": [],\n",
    "        \"epoch\": [],\n",
    "        \"loss\": [],\n",
    "        \"acc\": [],\n",
    "    }\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Phase 1: Optimize ISP (detector frozen)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for epoch in range(phase1_epochs):\n",
    "        loss, acc = train_epoch(\n",
    "            isp_composite,\n",
    "            detector,\n",
    "            isp_optimizer,\n",
    "            det_optimizer,\n",
    "            train_source,\n",
    "            batch_size,\n",
    "            freeze_detector=True,\n",
    "        )\n",
    "        history[\"phase\"].append(1)\n",
    "        history[\"epoch\"].append(epoch + 1)\n",
    "        history[\"loss\"].append(loss)\n",
    "        history[\"acc\"].append(acc)\n",
    "        print(f\"  Epoch {epoch + 1:2d}/{phase1_epochs} | Loss: {loss:.4f} | Acc: {acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"Phase 2: Joint ISP + detector optimization\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for epoch in range(phase2_epochs):\n",
    "        loss, acc = train_epoch(\n",
    "            isp_composite,\n",
    "            detector,\n",
    "            isp_optimizer,\n",
    "            det_optimizer,\n",
    "            train_source,\n",
    "            batch_size,\n",
    "            freeze_detector=False,\n",
    "        )\n",
    "        history[\"phase\"].append(2)\n",
    "        history[\"epoch\"].append(phase1_epochs + epoch + 1)\n",
    "        history[\"loss\"].append(loss)\n",
    "        history[\"acc\"].append(acc)\n",
    "        if (epoch + 1) % 2 == 0 or epoch == 0:\n",
    "            print(f\"  Epoch {epoch + 1:2d}/{phase2_epochs} | Loss: {loss:.4f} | Acc: {acc:.4f}\")\n",
    "\n",
    "    return isp_composite, detector, history\n",
    "\n",
    "\n",
    "# Run training (reduced epochs and data for demonstration)\n",
    "QUICK_MODE = True\n",
    "p1_epochs = 2 if QUICK_MODE else 5\n",
    "p2_epochs = 3 if QUICK_MODE else 10\n",
    "\n",
    "print(\"\\n=== Learned ISP Training (CIFAR-10) ===\\n\")\n",
    "isp_composite, detector, train_history = run_training(\n",
    "    train_source,\n",
    "    test_source,\n",
    "    phase1_epochs=p1_epochs,\n",
    "    phase2_epochs=p2_epochs,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs = train_history[\"epoch\"]\n",
    "losses = train_history[\"loss\"]\n",
    "accs = train_history[\"acc\"]\n",
    "phases = train_history[\"phase\"]\n",
    "\n",
    "# Phase boundary\n",
    "phase1_end = sum(1 for p in phases if p == 1)\n",
    "\n",
    "# Loss curve\n",
    "ax1.plot(epochs, losses, \"o-\", color=\"steelblue\", linewidth=2, markersize=6)\n",
    "if phase1_end > 0 and phase1_end < len(epochs):\n",
    "    ax1.axvline(\n",
    "        x=epochs[phase1_end - 1] + 0.5, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Phase 1 → 2\"\n",
    "    )\n",
    "    ax1.legend()\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Training Loss (ISP + Detector)\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(epochs, accs, \"o-\", color=\"darkorange\", linewidth=2, markersize=6)\n",
    "if phase1_end > 0 and phase1_end < len(epochs):\n",
    "    ax2.axvline(\n",
    "        x=epochs[phase1_end - 1] + 0.5, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Phase 1 → 2\"\n",
    "    )\n",
    "    ax2.legend()\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.set_title(\"Training Accuracy\")\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle(\"Learned ISP Training Progress (Two-Phase Protocol)\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    OUTPUT_DIR / \"perf-isp-training-curves.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(\"Saved: docs/assets/images/examples/perf-isp-training-curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "### Step 7: Verify Gradient Flow Through ISP DAG\n",
    "\n",
    "The critical verification: gradients must flow from the classification loss\n",
    "back through ALL 5 ISP operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Gradient flow verification\n",
    "print(\"\\n=== Gradient Flow Verification ===\")\n",
    "\n",
    "verify_pipeline = from_source(test_source, batch_size=8)\n",
    "verify_batch = next(iter(verify_pipeline))\n",
    "images = verify_batch[\"image\"]\n",
    "labels = verify_batch[\"label\"]\n",
    "\n",
    "\n",
    "def full_loss_fn(isp_composite: CompositeOperatorModule) -> jax.Array:\n",
    "    \"\"\"Loss through entire ISP composite for gradient verification.\"\"\"\n",
    "    processed = apply_isp_composite(isp_composite, images)\n",
    "    logits = detector(processed)\n",
    "    return cross_entropy_loss(logits, labels)\n",
    "\n",
    "\n",
    "# Detector in closure — use eval mode to prevent BatchNorm mutation\n",
    "detector.eval()\n",
    "loss, grads = nnx.value_and_grad(full_loss_fn)(isp_composite)\n",
    "grad_leaves = jax.tree.leaves(grads)\n",
    "\n",
    "assert len(grad_leaves) > 0, \"No gradient leaves found\"\n",
    "assert any(jnp.sum(jnp.abs(g)) > 0 for g in grad_leaves), (\n",
    "    \"All gradients are zero — ISP pipeline is NOT differentiable!\"\n",
    ")\n",
    "\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Gradient flow verified: {len(grad_leaves)} ISP parameter groups\")\n",
    "\n",
    "# Check each operator's gradients via the composite's operator list\n",
    "op_names = [\"CCM\", \"Desaturation\", \"ToneMapping\", \"Gamma\", \"Sharpening\"]\n",
    "for name, op in zip(op_names, isp_composite.operators):\n",
    "    op_param_norm = sum(\n",
    "        float(jnp.sum(jnp.abs(p))) for p in jax.tree.leaves(nnx.state(op, nnx.Param))\n",
    "    )\n",
    "    print(f\"  {name}: receives gradients\")\n",
    "\n",
    "print(\"\\nSUCCESS: All 5 ISP stages receive gradients through the composite!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 8: Analyze Learned ISP Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Analyze what the ISP learned\n",
    "def analyze_isp(isp_composite: CompositeOperatorModule) -> None:\n",
    "    \"\"\"Print analysis of learned ISP parameters.\"\"\"\n",
    "    ccm, desat, tonemap, gamma_op, sharpen = list(isp_composite.operators)\n",
    "\n",
    "    print(\"\\n=== Learned ISP Parameters ===\")\n",
    "\n",
    "    # CCM\n",
    "    print(\"\\n1. Color Correction Matrix:\")\n",
    "    print(f\"   {ccm.ccm[...]}\")\n",
    "    off_diag = float(jnp.sum(jnp.abs(ccm.ccm[...] - jnp.eye(3))))\n",
    "    print(f\"   Deviation from identity: {off_diag:.4f}\")\n",
    "\n",
    "    # Desaturation\n",
    "    strength = float(jax.nn.sigmoid(desat.strength[...]))\n",
    "    print(f\"\\n2. Desaturation strength: {strength:.4f}\")\n",
    "    print(f\"   Interpretation: {'More grayscale' if strength > 0.5 else 'Mostly color'}\")\n",
    "\n",
    "    # Tone mapping\n",
    "    y_points = jax.nn.sigmoid(tonemap.control_points[...])\n",
    "    print(f\"\\n3. Tone curve control points: {y_points}\")\n",
    "    is_brightening = float(jnp.mean(y_points)) > 0.5\n",
    "    print(\n",
    "        f\"   Trend: {'Brightening' if is_brightening else 'Darkening'} \"\n",
    "        f\"(mean={float(jnp.mean(y_points)):.3f})\"\n",
    "    )\n",
    "\n",
    "    # Gamma\n",
    "    gamma_val = float(jnp.exp(gamma_op.log_gamma[...]))\n",
    "    print(f\"\\n4. Gamma: {gamma_val:.4f}\")\n",
    "    print(f\"   Interpretation: {'Brightening' if gamma_val < 1 else 'Darkening'}\")\n",
    "\n",
    "    # Sharpening\n",
    "    sharp_strength = float(jax.nn.sigmoid(sharpen.strength[...]))\n",
    "    print(f\"\\n5. Sharpening strength: {sharp_strength:.4f}\")\n",
    "    print(f\"   Kernel:\\n   {sharpen.kernel[...]}\")\n",
    "\n",
    "    # --- Visualization: Tone curve + CCM heatmap + ISP parameter summary ---\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "    # 1. Learned tone mapping curve\n",
    "    n_pts = tonemap.config.num_control_points\n",
    "    x_points = np.linspace(0, 1, n_pts)\n",
    "    y_points = np.array(jax.nn.sigmoid(tonemap.control_points[...]))\n",
    "    y_sorted = np.sort(y_points)\n",
    "\n",
    "    axes[0].plot([0, 1], [0, 1], \"k--\", alpha=0.3, label=\"Identity (y=x)\")\n",
    "    axes[0].plot(\n",
    "        x_points, y_sorted, \"o-\", color=\"crimson\", linewidth=2, markersize=5, label=\"Learned curve\"\n",
    "    )\n",
    "    axes[0].set_xlabel(\"Input intensity\")\n",
    "    axes[0].set_ylabel(\"Output intensity\")\n",
    "    axes[0].set_title(\"Learned Tone Mapping Curve\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_xlim(0, 1)\n",
    "    axes[0].set_ylim(0, 1)\n",
    "\n",
    "    # 2. Color Correction Matrix as heatmap\n",
    "    ccm_vals = np.array(ccm.ccm[...])\n",
    "    im = axes[1].imshow(ccm_vals, cmap=\"RdBu_r\", vmin=-1, vmax=1, aspect=\"equal\")\n",
    "    for r in range(3):\n",
    "        for c_idx in range(3):\n",
    "            axes[1].text(\n",
    "                c_idx,\n",
    "                r,\n",
    "                f\"{ccm_vals[r, c_idx]:.2f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=11,\n",
    "                color=\"white\" if abs(ccm_vals[r, c_idx]) > 0.5 else \"black\",\n",
    "            )\n",
    "    axes[1].set_xticks([0, 1, 2])\n",
    "    axes[1].set_xticklabels([\"R\", \"G\", \"B\"])\n",
    "    axes[1].set_yticks([0, 1, 2])\n",
    "    axes[1].set_yticklabels([\"R\", \"G\", \"B\"])\n",
    "    axes[1].set_title(\"Learned Color Correction Matrix\")\n",
    "    plt.colorbar(im, ax=axes[1], shrink=0.8)\n",
    "\n",
    "    # 3. ISP parameter summary bar chart\n",
    "    param_names = [\"Desat.\", \"Gamma\", \"Sharp.\"]\n",
    "    param_values = [strength, gamma_val, sharp_strength]\n",
    "    colors = [\"#2196F3\", \"#FF9800\", \"#4CAF50\"]\n",
    "    bars = axes[2].bar(param_names, param_values, color=colors, edgecolor=\"black\", linewidth=0.5)\n",
    "    for bar, val in zip(bars, param_values):\n",
    "        axes[2].text(\n",
    "            bar.get_x() + bar.get_width() / 2, val + 0.02, f\"{val:.3f}\", ha=\"center\", fontsize=10\n",
    "        )\n",
    "    axes[2].set_ylabel(\"Parameter value\")\n",
    "    axes[2].set_title(\"Learned ISP Parameters\")\n",
    "    axes[2].set_ylim(0, max(param_values) * 1.3)\n",
    "    axes[2].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    fig.suptitle(\"Learned ISP Analysis — What the Pipeline Learned\", fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        OUTPUT_DIR / \"cv-isp-learned-parameters.png\",\n",
    "        dpi=150,\n",
    "        bbox_inches=\"tight\",\n",
    "        facecolor=\"white\",\n",
    "    )\n",
    "    plt.close()\n",
    "    print(\"\\nSaved: docs/assets/images/examples/cv-isp-learned-parameters.png\")\n",
    "\n",
    "\n",
    "analyze_isp(isp_composite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Step 9: Compare Fixed vs. Learned ISP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Evaluate and compare\n",
    "def evaluate_detector(\n",
    "    isp_composite: CompositeOperatorModule | None,\n",
    "    detector: CNNDetector,\n",
    "    source: MemorySource,\n",
    "    batch_size: int = 32,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Evaluate detector accuracy with optional ISP preprocessing.\"\"\"\n",
    "    detector.eval()  # Use running stats for evaluation\n",
    "    pipeline = from_source(source, batch_size=batch_size)\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch in pipeline:\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        processed = (\n",
    "            apply_isp_composite(isp_composite, images) if isp_composite is not None else images\n",
    "        )\n",
    "        logits = detector(processed)\n",
    "        total_loss += float(cross_entropy_loss(logits, labels))\n",
    "        total_acc += float(accuracy(logits, labels))\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_loss / max(num_batches, 1), total_acc / max(num_batches, 1)\n",
    "\n",
    "\n",
    "# Compare results\n",
    "print(\"\\n=== Comparison: Fixed vs. Learned ISP ===\")\n",
    "\n",
    "# No ISP (raw dark images)\n",
    "no_isp_loss, no_isp_acc = evaluate_detector(None, detector, test_source)\n",
    "print(f\"No ISP (raw):     Loss={no_isp_loss:.4f}, Acc={no_isp_acc:.4f}\")\n",
    "\n",
    "# Learned ISP\n",
    "learned_loss, learned_acc = evaluate_detector(isp_composite, detector, test_source)\n",
    "print(f\"Learned ISP:      Loss={learned_loss:.4f}, Acc={learned_acc:.4f}\")\n",
    "\n",
    "improvement = (learned_acc - no_isp_acc) * 100\n",
    "print(f\"\\nImprovement: +{improvement:.1f}% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize before/after ISP processing on test images\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "\n",
    "# Get a batch of test images\n",
    "vis_pipeline = from_source(test_source, batch_size=8)\n",
    "vis_batch = next(iter(vis_pipeline))\n",
    "dark_images = vis_batch[\"image\"]\n",
    "labels = vis_batch[\"label\"]\n",
    "\n",
    "# Process through learned ISP\n",
    "isp_processed = apply_isp_composite(isp_composite, dark_images)\n",
    "\n",
    "for i in range(8):\n",
    "    label = int(labels[i])\n",
    "    # Dark image — raw (top row)\n",
    "    axes[0, i].imshow(np.array(dark_images[i]), interpolation=\"nearest\")\n",
    "    axes[0, i].set_title(CIFAR10_CLASSES[label], fontsize=9)\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    # Dark image — brightened for visibility (middle row)\n",
    "    axes[1, i].imshow(np.clip(np.array(dark_images[i]) * 4, 0, 1), interpolation=\"nearest\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "    # ISP-processed image (bottom row)\n",
    "    axes[2, i].imshow(np.clip(np.array(isp_processed[i]), 0, 1), interpolation=\"nearest\")\n",
    "    axes[2, i].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Dark (raw)\", fontsize=10, rotation=0, labelpad=55)\n",
    "axes[1, 0].set_ylabel(\"Dark (4x)\", fontsize=10, rotation=0, labelpad=55)\n",
    "axes[2, 0].set_ylabel(\"Learned ISP\", fontsize=10, rotation=0, labelpad=55)\n",
    "fig.suptitle(\n",
    "    f\"Before vs. After Learned ISP Processing\\n\"\n",
    "    f\"No ISP: {no_isp_acc:.1%} accuracy → Learned ISP: {learned_acc:.1%} accuracy \"\n",
    "    f\"(+{improvement:.1f}%)\",\n",
    "    fontsize=12,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    OUTPUT_DIR / \"cv-isp-before-after.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(\"Saved: docs/assets/images/examples/cv-isp-before-after.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results & Evaluation\n",
    "\n",
    "### What We Achieved\n",
    "\n",
    "This example demonstrates datarax's `CompositeOperatorModule(SEQUENTIAL)` enabling\n",
    "end-to-end differentiable ISP optimization. The composite chains 5 ISP stages\n",
    "where gradients flow from the classification loss back through every stage.\n",
    "The `>>` DAG pipeline handles inference demos, while the composite handles\n",
    "training with `nnx.value_and_grad`.\n",
    "\n",
    "### Expected Results (Full Training on CIFAR-10)\n",
    "\n",
    "| Configuration | Accuracy | Notes |\n",
    "|---------------|----------|-------|\n",
    "| No ISP (raw dark images) | ~10-15% | Near random (images too dark) |\n",
    "| Fixed ISP (gamma=0.5) | ~40-50% | Standard brightening helps |\n",
    "| **Learned ISP** | **~55-70%** | Gradient-optimized for detector |\n",
    "| AdaptiveISP (paper, RL) | ~30.2 mAP | Different dataset/metric (LOD) |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Composition makes it natural**: `CompositeOperatorModule(SEQUENTIAL)` composes\n",
    "   ISP stages into a differentiable pipeline. No manual loop or gradient wiring needed.\n",
    "\n",
    "2. **Gradient-based > RL**: Direct gradient optimization is simpler and\n",
    "   often more effective than RL-based ISP module selection.\n",
    "\n",
    "3. **37 parameters, big impact**: The ISP pipeline has only 37 learnable\n",
    "   parameters but dramatically changes what the detector \"sees.\"\n",
    "\n",
    "4. **Task-optimized processing**: The learned ISP brightens dark images\n",
    "   and enhances contrast — not for human viewing, but for detector accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps & Resources\n",
    "\n",
    "### Try These Experiments\n",
    "\n",
    "1. **Real LOD dataset**: Download the LOD dataset from the\n",
    "   [AdaptiveISP project](https://openimaginglab.github.io/AdaptiveISP/) and\n",
    "   replace CIFAR-10 with real low-light object detection data.\n",
    "\n",
    "2. **Full YOLOv3 detector**: Implement YOLOv3 in Flax NNX and train\n",
    "   on a real detection dataset with the ISP pipeline.\n",
    "\n",
    "3. **More ISP stages**: Add denoising (learned bilateral filter),\n",
    "   white balance, or HDR tone mapping operators.\n",
    "\n",
    "4. **Compare with fixed ISP**: Train the same detector with different\n",
    "   fixed gamma values (0.3, 0.5, 0.7, 1.0) and compare to learned.\n",
    "\n",
    "### Related Examples\n",
    "\n",
    "- [DADA Learned Augmentation](01_dada_learned_augmentation_guide.py) — Differentiable\n",
    "  augmentation search using datarax operators\n",
    "- [DDSP Audio Synthesis](03_ddsp_audio_synthesis_guide.py) — Custom operators\n",
    "  for non-image domains\n",
    "- [DAG Fundamentals Guide](../dag/01_dag_fundamentals_guide.py) — Deep dive\n",
    "  into DAG pipeline construction\n",
    "\n",
    "### API Reference\n",
    "\n",
    "- [ModalityOperator](../../../docs/core/modality.md) — Base class for ISP operators\n",
    "- [DAGExecutor](../../../docs/dag/dag_executor.md) — Pipeline executor with `>>` operator\n",
    "- [OperatorNode](../../../docs/dag/nodes.md) — Wrapping operators for DAG\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- [AdaptiveISP Paper (arXiv)](https://arxiv.org/abs/2410.22939) — Reference paper\n",
    "- [ISP Pipeline Overview](https://en.wikipedia.org/wiki/Image_signal_processor) — ISP basics\n",
    "- [Differentiable Rendering](https://arxiv.org/abs/2006.12057) — Related concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main entry point for command-line execution.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Learned ISP for Object Detection (CIFAR-10)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Load CIFAR-10 with low-light simulation\n",
    "    print(\"\\n[1/5] Loading CIFAR-10 low-light dataset...\")\n",
    "    _, train_source = load_cifar10_lowlight(split=\"train\", seed=42)\n",
    "    _, test_source = load_cifar10_lowlight(split=\"test\", seed=99)\n",
    "\n",
    "    # Train\n",
    "    print(\"\\n[2/5] Training ISP + Detector...\")\n",
    "    isp_composite, detector, _ = run_training(\n",
    "        train_source,\n",
    "        test_source,\n",
    "        phase1_epochs=5,\n",
    "        phase2_epochs=10,\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"\\n[3/5] Evaluating...\")\n",
    "    no_isp_loss, no_isp_acc = evaluate_detector(None, detector, test_source)\n",
    "    learned_loss, learned_acc = evaluate_detector(isp_composite, detector, test_source)\n",
    "    print(f\"  No ISP:     Acc={no_isp_acc:.4f}\")\n",
    "    print(f\"  Learned ISP: Acc={learned_acc:.4f}\")\n",
    "    print(f\"  Improvement: +{(learned_acc - no_isp_acc) * 100:.1f}%\")\n",
    "\n",
    "    # Gradient verification\n",
    "    print(\"\\n[4/5] Verifying gradient flow...\")\n",
    "    verify_pipeline = from_source(test_source, batch_size=8)\n",
    "    verify_batch = next(iter(verify_pipeline))\n",
    "\n",
    "    def loss_fn(isp_composite: CompositeOperatorModule) -> jax.Array:\n",
    "        processed = apply_isp_composite(isp_composite, verify_batch[\"image\"])\n",
    "        logits = detector(processed)\n",
    "        return cross_entropy_loss(logits, verify_batch[\"label\"])\n",
    "\n",
    "    detector.eval()  # Detector in closure — prevent BatchNorm mutation\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(isp_composite)\n",
    "    grad_leaves = jax.tree.leaves(grads)\n",
    "    assert len(grad_leaves) > 0\n",
    "    assert any(jnp.sum(jnp.abs(g)) > 0 for g in grad_leaves)\n",
    "    print(f\"  Gradient flow: VERIFIED ({len(grad_leaves)} param groups)\")\n",
    "\n",
    "    # Analyze\n",
    "    print(\"\\n[5/5] Analyzing learned ISP...\")\n",
    "    analyze_isp(isp_composite)\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ISP training complete!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
