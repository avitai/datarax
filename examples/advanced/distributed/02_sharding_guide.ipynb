{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Distributed Data Loading with Sharding Guide\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Advanced |\n",
    "| **Runtime** | ~45 min |\n",
    "| **Prerequisites** | Sharding Quick Reference, JAX device placement |\n",
    "| **Format** | Python + Jupyter |\n",
    "| **Memory** | ~2 GB RAM per device |\n",
    "\n",
    "## Overview\n",
    "\n",
    "This in-depth guide covers distributed data loading patterns for\n",
    "multi-device JAX setups. You'll learn to shard data across GPUs/TPUs,\n",
    "optimize throughput for distributed training, and handle common pitfalls.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this guide, you will be able to:\n",
    "\n",
    "1. Design data parallelism strategies for different device topologies\n",
    "2. Implement efficient sharded batch distribution\n",
    "3. Profile and optimize distributed data loading\n",
    "4. Handle edge cases (uneven batches, device failures)\n",
    "5. Integrate sharded pipelines with distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "uv pip install \"datarax[tfds]\" matplotlib\n",
    "```\n",
    "\n",
    "**Requirements**: This guide is designed for multi-device systems.\n",
    "Single-device systems will run in simulation mode showing the concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Memory Configuration\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES_FOR_TF\"] = \"\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "# Core imports\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "from jax.sharding import Mesh, NamedSharding, PartitionSpec\n",
    "\n",
    "# Datarax imports\n",
    "from datarax import from_source\n",
    "from datarax.dag.nodes import OperatorNode\n",
    "from datarax.operators import ElementOperator, ElementOperatorConfig\n",
    "from datarax.sources import TFDSEagerConfig, TFDSEagerSource\n",
    "\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Device count: {len(jax.devices())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 1: Understanding Data Parallelism\n",
    "\n",
    "### Data Parallelism Basics\n",
    "\n",
    "In data parallelism, each device processes a portion of the batch:\n",
    "\n",
    "```\n",
    "Full Batch (B samples)\n",
    "├── Device 0: B/N samples\n",
    "├── Device 1: B/N samples\n",
    "├── ...\n",
    "└── Device N-1: B/N samples\n",
    "```\n",
    "\n",
    "### JAX Sharding Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Mesh** | Logical arrangement of devices |\n",
    "| **PartitionSpec** | How to shard each dimension |\n",
    "| **NamedSharding** | Sharding policy for arrays |\n",
    "| **device_put** | Place data on devices |\n",
    "\n",
    "### Mesh Axis Naming\n",
    "\n",
    "Common conventions:\n",
    "- `\"data\"` or `\"batch\"` - Data parallelism axis\n",
    "- `\"model\"` or `\"tensor\"` - Model/tensor parallelism axis\n",
    "- `\"pipeline\"` - Pipeline parallelism axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "devices = jax.devices()\n",
    "num_devices = len(devices)\n",
    "use_sharding = num_devices >= 2\n",
    "\n",
    "print(f\"Available devices: {num_devices}\")\n",
    "print(f\"Device types: {[str(d.device_kind) for d in devices]}\")\n",
    "\n",
    "if use_sharding:\n",
    "    # Create 1D mesh for pure data parallelism\n",
    "    device_array = np.array(devices)\n",
    "    mesh = Mesh(device_array, axis_names=(\"data\",))\n",
    "    print(f\"\\nCreated mesh: {mesh.shape} with axis 'data'\")\n",
    "else:\n",
    "    mesh = None\n",
    "    print(\"\\nSingle device mode - will simulate sharding concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 2: Sharded Batch Distribution\n",
    "\n",
    "### PartitionSpec Rules\n",
    "\n",
    "| PartitionSpec | Meaning |\n",
    "|---------------|---------|\n",
    "| `(\"data\",)` | Shard along first dim across \"data\" axis |\n",
    "| `(\"data\", None)` | Shard first dim, replicate second |\n",
    "| `(None, \"data\")` | Replicate first dim, shard second |\n",
    "| `(None, None)` | Fully replicate |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sharding_spec(shape, mesh, shard_first_dim=True):\n",
    "    \"\"\"Create appropriate PartitionSpec for a given shape.\n",
    "\n",
    "    Args:\n",
    "        shape: Array shape tuple\n",
    "        mesh: JAX Mesh object\n",
    "        shard_first_dim: Whether to shard along first (batch) dimension\n",
    "\n",
    "    Returns:\n",
    "        NamedSharding for the array\n",
    "    \"\"\"\n",
    "    if mesh is None:\n",
    "        return None\n",
    "\n",
    "    ndim = len(shape)\n",
    "    if shard_first_dim and ndim > 0:\n",
    "        # Shard first dim (batch), replicate rest\n",
    "        spec = (\"data\",) + (None,) * (ndim - 1)\n",
    "    else:\n",
    "        # Fully replicate\n",
    "        spec = (None,) * ndim\n",
    "\n",
    "    return NamedSharding(mesh, PartitionSpec(*spec))\n",
    "\n",
    "\n",
    "# Example sharding specs\n",
    "if mesh is not None:\n",
    "    image_sharding = create_sharding_spec((64, 32, 32, 3), mesh)\n",
    "    label_sharding = create_sharding_spec((64,), mesh)\n",
    "    print(f\"Image sharding: {image_sharding.spec}\")\n",
    "    print(f\"Label sharding: {label_sharding.spec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 3: Create Sharded Data Pipeline\n",
    "\n",
    "We'll build a complete pipeline that produces sharded batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 128  # Total batch size across all devices\n",
    "SAMPLES_PER_DEVICE = BATCH_SIZE // max(num_devices, 1)\n",
    "NUM_SAMPLES = 2048\n",
    "\n",
    "print(\"Batch configuration:\")\n",
    "print(f\"  Total batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Samples per device: {SAMPLES_PER_DEVICE}\")\n",
    "print(f\"  Dataset size: {NUM_SAMPLES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(element, key=None):  # noqa: ARG001\n",
    "    \"\"\"Standard image preprocessing.\"\"\"\n",
    "    del key\n",
    "    image = element.data[\"image\"]\n",
    "\n",
    "    # Normalize to [0, 1]\n",
    "    image = image.astype(jnp.float32) / 255.0\n",
    "\n",
    "    return element.update_data({\"image\": image})\n",
    "\n",
    "\n",
    "def create_pipeline(batch_size=BATCH_SIZE, num_samples=NUM_SAMPLES, seed=42):\n",
    "    \"\"\"Create CIFAR-10 data pipeline.\"\"\"\n",
    "    config = TFDSEagerConfig(\n",
    "        name=\"cifar10\",\n",
    "        split=f\"train[:{num_samples}]\",\n",
    "        shuffle=True,\n",
    "        seed=seed,\n",
    "        exclude_keys={\"id\"},\n",
    "    )\n",
    "\n",
    "    source = TFDSEagerSource(config, rngs=nnx.Rngs(seed))\n",
    "\n",
    "    preprocessor = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=preprocess_image,\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    return from_source(source, batch_size=batch_size).add(OperatorNode(preprocessor))\n",
    "\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = create_pipeline()\n",
    "print(\"Created CIFAR-10 pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_batch(batch, mesh, shard_batch_dim=True):\n",
    "    \"\"\"Distribute batch data across devices.\n",
    "\n",
    "    Args:\n",
    "        batch: Dictionary of batch arrays\n",
    "        mesh: JAX Mesh object\n",
    "        shard_batch_dim: Whether to shard along batch dimension\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with sharded arrays\n",
    "    \"\"\"\n",
    "    if mesh is None:\n",
    "        return batch\n",
    "\n",
    "    distributed = {}\n",
    "    for key, array in batch.items():\n",
    "        if hasattr(array, \"shape\"):\n",
    "            sharding = create_sharding_spec(array.shape, mesh, shard_batch_dim)\n",
    "            distributed[key] = jax.device_put(array, sharding)\n",
    "        else:\n",
    "            distributed[key] = array\n",
    "\n",
    "    return distributed\n",
    "\n",
    "\n",
    "# Test distribution\n",
    "if mesh is not None:\n",
    "    test_batch = next(iter(pipeline))\n",
    "    with mesh:\n",
    "        sharded_batch = distribute_batch(test_batch, mesh)\n",
    "        print(\"\\nDistributed batch:\")\n",
    "        print(f\"  Image shape: {sharded_batch['image'].shape}\")\n",
    "        print(f\"  Image sharding: {sharded_batch['image'].sharding.spec}\")\n",
    "else:\n",
    "    test_batch = next(iter(pipeline))\n",
    "    print(\"\\nSingle-device batch:\")\n",
    "    print(f\"  Image shape: {test_batch['image'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 4: Sharded Training Loop Pattern\n",
    "\n",
    "Complete pattern for distributed training with sharded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharded_training_step(batch, _mesh):\n",
    "    \"\"\"Example sharded training step (computation only).\"\"\"\n",
    "    # In a real training loop, this would be your model forward/backward pass\n",
    "    images = batch[\"image\"]\n",
    "\n",
    "    # Simple computation for demonstration\n",
    "    mean_value = jnp.mean(images)\n",
    "    batch_size = images.shape[0]\n",
    "\n",
    "    return {\"mean\": mean_value, \"batch_size\": batch_size}\n",
    "\n",
    "\n",
    "# Run sharded iteration\n",
    "print(\"\\nSharded iteration example:\")\n",
    "\n",
    "pipeline = create_pipeline(num_samples=512)\n",
    "metrics = []\n",
    "\n",
    "if mesh is not None:\n",
    "    with mesh:\n",
    "        for i, batch in enumerate(pipeline):\n",
    "            if i >= 5:\n",
    "                break\n",
    "\n",
    "            # Distribute batch\n",
    "            sharded_batch = distribute_batch(batch, mesh)\n",
    "\n",
    "            # Run sharded computation\n",
    "            result = sharded_training_step(sharded_batch, mesh)\n",
    "            metrics.append(result)\n",
    "\n",
    "            print(f\"Batch {i}: size={result['batch_size']}, mean={float(result['mean']):.4f}\")\n",
    "else:\n",
    "    for i, batch in enumerate(pipeline):\n",
    "        if i >= 5:\n",
    "            break\n",
    "\n",
    "        result = sharded_training_step(batch, None)\n",
    "        metrics.append(result)\n",
    "\n",
    "        print(f\"Batch {i}: size={result['batch_size']}, mean={float(result['mean']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 5: Throughput Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"docs/assets/images/examples\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def benchmark_pipeline(batch_size, num_batches=20, mesh=None):\n",
    "    \"\"\"Benchmark pipeline throughput.\"\"\"\n",
    "    pipeline = create_pipeline(batch_size=batch_size, num_samples=batch_size * num_batches)\n",
    "\n",
    "    # Warmup\n",
    "    warmup_batch = next(iter(pipeline))\n",
    "    if mesh is not None:\n",
    "        with mesh:\n",
    "            _ = distribute_batch(warmup_batch, mesh)\n",
    "\n",
    "    # Benchmark\n",
    "    pipeline = create_pipeline(batch_size=batch_size, num_samples=batch_size * num_batches)\n",
    "\n",
    "    start = time.time()\n",
    "    samples = 0\n",
    "\n",
    "    if mesh is not None:\n",
    "        with mesh:\n",
    "            for batch in pipeline:\n",
    "                sharded = distribute_batch(batch, mesh)\n",
    "                _ = sharded[\"image\"].block_until_ready()\n",
    "                samples += batch[\"image\"].shape[0]\n",
    "    else:\n",
    "        for batch in pipeline:\n",
    "            _ = batch[\"image\"].block_until_ready()\n",
    "            samples += batch[\"image\"].shape[0]\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return samples / elapsed\n",
    "\n",
    "\n",
    "# Benchmark different batch sizes\n",
    "batch_sizes = [32, 64, 128, 256]\n",
    "throughputs = []\n",
    "\n",
    "print(\"\\nBenchmarking throughput:\")\n",
    "for bs in batch_sizes:\n",
    "    tp = benchmark_pipeline(bs, mesh=mesh)\n",
    "    throughputs.append(tp)\n",
    "    print(f\"  Batch size {bs}: {tp:.0f} samples/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot throughput vs batch size\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Throughput vs batch size\n",
    "axes[0].plot(batch_sizes, throughputs, \"o-\", linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel(\"Batch Size\")\n",
    "axes[0].set_ylabel(\"Throughput (samples/second)\")\n",
    "axes[0].set_title(f\"Data Loading Throughput ({num_devices} device(s))\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xscale(\"log\", base=2)\n",
    "\n",
    "# Throughput as bar chart with values labeled\n",
    "bars = axes[1].bar([str(bs) for bs in batch_sizes], throughputs, color=\"steelblue\")\n",
    "axes[1].set_xlabel(\"Batch Size\")\n",
    "axes[1].set_ylabel(\"Throughput (samples/second)\")\n",
    "axes[1].set_title(\"Throughput by Batch Size\")\n",
    "\n",
    "# Label each bar with its value\n",
    "for bar, tp in zip(bars, throughputs):\n",
    "    axes[1].text(bar.get_x() + bar.get_width() / 2, tp + 50, f\"{tp:,.0f}\", ha=\"center\", fontsize=9)\n",
    "\n",
    "axes[1].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"dist-sharding-throughput-scaling.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'dist-sharding-throughput-scaling.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 6: Memory Analysis\n",
    "\n",
    "Understanding memory distribution across devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate memory distribution\n",
    "batch_size = 128\n",
    "image_shape = (32, 32, 3)\n",
    "float_bytes = 4  # float32\n",
    "\n",
    "# Memory per batch\n",
    "image_memory = batch_size * np.prod(image_shape) * float_bytes\n",
    "label_memory = batch_size * 4  # int32\n",
    "batch_memory = image_memory + label_memory\n",
    "\n",
    "# Memory per device (sharded)\n",
    "memory_per_device_sharded = batch_memory / max(num_devices, 1)\n",
    "memory_per_device_replicated = batch_memory\n",
    "\n",
    "print(f\"Memory analysis (batch_size={batch_size}):\")\n",
    "print(f\"  Image memory per batch: {image_memory / 1e6:.2f} MB\")\n",
    "print(f\"  Total batch memory: {batch_memory / 1e6:.2f} MB\")\n",
    "print(f\"  Memory per device (sharded): {memory_per_device_sharded / 1e6:.2f} MB\")\n",
    "print(f\"  Memory per device (replicated): {memory_per_device_replicated / 1e6:.2f} MB\")\n",
    "print(f\"  Memory savings from sharding: {(1 - 1 / max(num_devices, 1)) * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot memory distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "device_labels = [f\"Device {i}\" for i in range(max(num_devices, 2))]\n",
    "sharded_memory = [memory_per_device_sharded / 1e6] * max(num_devices, 2)\n",
    "replicated_memory = [memory_per_device_replicated / 1e6] * max(num_devices, 2)\n",
    "\n",
    "x = np.arange(len(device_labels))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width / 2, sharded_memory, width, label=\"Sharded\", color=\"steelblue\")\n",
    "bars2 = ax.bar(\n",
    "    x + width / 2, replicated_memory, width, label=\"Replicated\", color=\"coral\", alpha=0.7\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Memory (MB)\")\n",
    "ax.set_xlabel(\"Device\")\n",
    "ax.set_title(\"Memory Distribution: Sharded vs Replicated\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(device_labels)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"dist-sharding-memory-per-device.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'dist-sharding-memory-per-device.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 7: Device Utilization Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate device utilization during data loading\n",
    "num_steps = 50\n",
    "device_utilization = np.zeros((max(num_devices, 2), num_steps))\n",
    "\n",
    "# Simulate loading pattern\n",
    "for step in range(num_steps):\n",
    "    # Data loading phase (some variance)\n",
    "    base_util = 0.7 + 0.2 * np.random.random()\n",
    "    for dev in range(max(num_devices, 2)):\n",
    "        # Add device-specific variance\n",
    "        device_utilization[dev, step] = base_util + 0.1 * np.random.random()\n",
    "\n",
    "# Plot utilization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for dev in range(min(max(num_devices, 2), 4)):  # Show up to 4 devices\n",
    "    ax.plot(device_utilization[dev], label=f\"Device {dev}\", alpha=0.8)\n",
    "\n",
    "ax.axhline(y=np.mean(device_utilization), color=\"red\", linestyle=\"--\", label=\"Mean\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Utilization\")\n",
    "ax.set_title(\"Device Utilization During Sharded Data Loading\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"dist-sharding-device-utilization.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'dist-sharding-device-utilization.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 8: Batch Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how batches are distributed across devices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Batch distribution diagram\n",
    "ax1 = axes[0]\n",
    "batch_data = np.random.rand(BATCH_SIZE // max(num_devices, 1), max(num_devices, 2))\n",
    "\n",
    "im = ax1.imshow(batch_data.T, aspect=\"auto\", cmap=\"viridis\")\n",
    "ax1.set_ylabel(\"Device\")\n",
    "ax1.set_xlabel(\"Sample Index (within device)\")\n",
    "ax1.set_title(\"Batch Distribution Across Devices\")\n",
    "ax1.set_yticks(range(max(num_devices, 2)))\n",
    "ax1.set_yticklabels([f\"Dev {i}\" for i in range(max(num_devices, 2))])\n",
    "plt.colorbar(im, ax=ax1, label=\"Data Value\")\n",
    "\n",
    "# Samples per device bar chart\n",
    "ax2 = axes[1]\n",
    "samples_per_dev = [BATCH_SIZE // max(num_devices, 1)] * max(num_devices, 2)\n",
    "ax2.bar(range(max(num_devices, 2)), samples_per_dev, color=\"steelblue\")\n",
    "ax2.set_xlabel(\"Device\")\n",
    "ax2.set_ylabel(\"Samples\")\n",
    "ax2.set_title(f\"Samples per Device (Total: {BATCH_SIZE})\")\n",
    "ax2.set_xticks(range(max(num_devices, 2)))\n",
    "ax2.set_xticklabels([f\"Dev {i}\" for i in range(max(num_devices, 2))])\n",
    "\n",
    "for i, v in enumerate(samples_per_dev):\n",
    "    ax2.text(i, v + 1, str(v), ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / \"dist-sharding-batch-distribution.png\",\n",
    "    dpi=150,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir / 'dist-sharding-batch-distribution.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "### Sharding Strategies\n",
    "\n",
    "| Strategy | Use Case | Mesh Shape |\n",
    "|----------|----------|------------|\n",
    "| Pure Data Parallel | Most common | (N,) \"data\" |\n",
    "| 2D Data + Model | Large models | (D, M) \"data\", \"model\" |\n",
    "| Pipeline Parallel | Very long sequences | (P,) \"pipeline\" |\n",
    "\n",
    "### Performance Guidelines\n",
    "\n",
    "| Batch Size | Recommendation |\n",
    "|------------|----------------|\n",
    "| < 32 | Overhead may exceed benefit |\n",
    "| 64-256 | Good balance |\n",
    "| > 256 | Check memory constraints |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Batch size**: Should be divisible by device count\n",
    "2. **Memory**: Sharding reduces per-device memory linearly\n",
    "3. **Overhead**: Distribution has fixed cost - larger batches amortize it\n",
    "4. **Mesh context**: All sharded operations must be within mesh context\n",
    "5. **Fallback**: Code should handle single-device gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Checkpointing**: [Resumable training](../checkpointing/02_resumable_training_guide.ipynb)\n",
    "- **Performance**: [Optimization guide](../performance/01_optimization_guide.ipynb)\n",
    "- **Full training**: [End-to-end CIFAR-10](../training/01_e2e_cifar10_guide.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the distributed sharding guide.\"\"\"\n",
    "    print(\"Distributed Data Loading with Sharding Guide\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    devices = jax.devices()\n",
    "    num_devices = len(devices)\n",
    "    print(f\"Devices available: {num_devices}\")\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = create_pipeline(batch_size=64, num_samples=256)\n",
    "\n",
    "    # Process with optional sharding\n",
    "    total_samples = 0\n",
    "    if num_devices >= 2:\n",
    "        mesh = Mesh(np.array(devices), axis_names=(\"data\",))\n",
    "        with mesh:\n",
    "            for batch in pipeline:\n",
    "                sharded = distribute_batch(batch, mesh)\n",
    "                total_samples += sharded[\"image\"].shape[0]\n",
    "    else:\n",
    "        for batch in pipeline:\n",
    "            total_samples += batch[\"image\"].shape[0]\n",
    "\n",
    "    print(f\"Processed {total_samples} samples\")\n",
    "    print(\"Guide completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
