{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enhanced Comparison: Distributed Processing and Memory Management.\n",
    "\n",
    "This example demonstrates how datarax's stateful approach provides\n",
    "superior multi-worker coordination, memory efficiency, and JAX sharding\n",
    "integration compared to Grain's stateless design.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import queue\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import flax.nnx as nnx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "============================================================================\n",
    "GRAIN (STATELESS) DISTRIBUTED IMPLEMENTATION\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GrainShardOptions:\n",
    "    \"\"\"Grain-style sharding configuration.\"\"\"\n",
    "\n",
    "    num_shards: int\n",
    "    shard_id: int\n",
    "    drop_remainder: bool = True\n",
    "\n",
    "    def get_shard_indices(self, total_samples: int) -> tuple[int, int]:\n",
    "        \"\"\"Calculate shard boundaries.\"\"\"\n",
    "        samples_per_shard = total_samples // self.num_shards\n",
    "        start = self.shard_id * samples_per_shard\n",
    "\n",
    "        if self.shard_id == self.num_shards - 1 and not self.drop_remainder:\n",
    "            # Last shard gets remaining samples\n",
    "            end = total_samples\n",
    "        else:\n",
    "            end = start + samples_per_shard\n",
    "\n",
    "        return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class GrainDistributedLoader:\n",
    "    \"\"\"Grain-style distributed loader with manual coordination.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        num_workers: int = 4,\n",
    "        shard_options: GrainShardOptions | None = None,\n",
    "        prefetch_size: int = 10,\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.num_workers = num_workers\n",
    "        self.shard_options = shard_options or GrainShardOptions(1, 0)\n",
    "        self.prefetch_size = prefetch_size\n",
    "\n",
    "        # Calculate shard boundaries\n",
    "        self.shard_start, self.shard_end = self.shard_options.get_shard_indices(len(data))\n",
    "        self.shard_data = data[self.shard_start : self.shard_end]\n",
    "\n",
    "        # Manual worker state management\n",
    "        self.worker_states = []\n",
    "        for i in range(num_workers):\n",
    "            # Each worker processes strided indices\n",
    "            self.worker_states.append(\n",
    "                {\n",
    "                    \"worker_id\": i,\n",
    "                    \"current_index\": i,\n",
    "                    \"samples_processed\": 0,\n",
    "                    \"errors\": 0,\n",
    "                    \"last_batch_time\": 0.0,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Manual coordination structures\n",
    "        self.data_queue = queue.Queue(maxsize=prefetch_size)\n",
    "        self.workers = []\n",
    "        self.stop_event = threading.Event()\n",
    "        self.coordinator_state = {\n",
    "            \"batches_produced\": 0,\n",
    "            \"total_samples\": 0,\n",
    "            \"coordination_overhead\": 0.0,\n",
    "        }\n",
    "\n",
    "    def _worker_function(self, worker_id: int, state: dict):\n",
    "        \"\"\"Worker function with manual state tracking.\"\"\"\n",
    "        while not self.stop_event.is_set():\n",
    "            try:\n",
    "                # Check if more data to process\n",
    "                if state[\"current_index\"] >= len(self.shard_data):\n",
    "                    break\n",
    "\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Get data sample\n",
    "                sample = self.shard_data[state[\"current_index\"]]\n",
    "\n",
    "                # Manual state update\n",
    "                state[\"current_index\"] += self.num_workers\n",
    "                state[\"samples_processed\"] += 1\n",
    "                state[\"last_batch_time\"] = time.time() - start_time\n",
    "\n",
    "                # Put in queue with state copy\n",
    "                self.data_queue.put((sample, state.copy()), timeout=1.0)\n",
    "\n",
    "            except queue.Full:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                state[\"errors\"] += 1\n",
    "                print(f\"Worker {worker_id} error: {e}\")\n",
    "\n",
    "    def start_workers(self):\n",
    "        \"\"\"Start worker threads with manual coordination.\"\"\"\n",
    "        for i in range(self.num_workers):\n",
    "            worker = threading.Thread(\n",
    "                target=self._worker_function, args=(i, self.worker_states[i]), daemon=True\n",
    "            )\n",
    "            worker.start()\n",
    "            self.workers.append(worker)\n",
    "\n",
    "    def get_batch(self, batch_size: int, timeout: float = 5.0) -> tuple[np.ndarray, dict] | None:\n",
    "        \"\"\"Get batch with manual aggregation and state merging.\"\"\"\n",
    "        batch = []\n",
    "        batch_states = []\n",
    "        deadline = time.time() + timeout\n",
    "\n",
    "        while len(batch) < batch_size and time.time() < deadline:\n",
    "            try:\n",
    "                remaining_time = deadline - time.time()\n",
    "                if remaining_time <= 0:\n",
    "                    break\n",
    "\n",
    "                sample, worker_state = self.data_queue.get(timeout=min(remaining_time, 0.1))\n",
    "                batch.append(sample)\n",
    "                batch_states.append(worker_state)\n",
    "\n",
    "            except queue.Empty:\n",
    "                if not any(w.is_alive() for w in self.workers):\n",
    "                    break\n",
    "\n",
    "        if not batch:\n",
    "            return None\n",
    "\n",
    "        # Manual state aggregation\n",
    "        aggregated_state = {\n",
    "            \"workers\": batch_states,\n",
    "            \"batch_size\": len(batch),\n",
    "            \"coordinator\": self.coordinator_state.copy(),\n",
    "        }\n",
    "\n",
    "        self.coordinator_state[\"batches_produced\"] += 1\n",
    "        self.coordinator_state[\"total_samples\"] += len(batch)\n",
    "\n",
    "        return np.stack(batch), aggregated_state\n",
    "\n",
    "    def get_memory_usage(self) -> dict:\n",
    "        \"\"\"Calculate memory usage with manual tracking.\"\"\"\n",
    "        process = psutil.Process()\n",
    "        memory_info = process.memory_info()\n",
    "\n",
    "        # Manual calculation of data memory\n",
    "        data_memory = self.shard_data.nbytes / (1024 * 1024)  # MB\n",
    "        queue_memory = self.data_queue.qsize() * self.shard_data[0].nbytes / (1024 * 1024)\n",
    "\n",
    "        return {\n",
    "            \"total_mb\": memory_info.rss / (1024 * 1024),\n",
    "            \"data_mb\": data_memory,\n",
    "            \"queue_mb\": queue_memory,\n",
    "            \"overhead_mb\": (memory_info.rss / (1024 * 1024)) - data_memory - queue_memory,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "============================================================================\n",
    "DATARAX (STATEFUL) DISTRIBUTED IMPLEMENTATION\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedMemoryPool(nnx.Module):\n",
    "    \"\"\"Efficient shared memory management with NNX.\"\"\"\n",
    "\n",
    "    def __init__(self, capacity_mb: int = 100):\n",
    "        self.capacity_mb = capacity_mb\n",
    "\n",
    "        # Automatic state tracking\n",
    "        self.allocated_mb = nnx.Variable(0.0)\n",
    "        self.cache_hits = nnx.Variable(0)\n",
    "        self.cache_misses = nnx.Variable(0)\n",
    "        self.evictions = nnx.Variable(0)\n",
    "\n",
    "        # Internal cache\n",
    "        self._cache = {}\n",
    "        self._access_times = {}\n",
    "        self._access_counter = 0\n",
    "\n",
    "    def get_or_create(self, key: str, creator_fn: Callable[[], Any]) -> Any:\n",
    "        \"\"\"Get from cache or create with automatic tracking.\"\"\"\n",
    "        if key in self._cache:\n",
    "            self.cache_hits.value += 1\n",
    "            self._access_times[key] = self._access_counter\n",
    "            self._access_counter += 1\n",
    "            return self._cache[key]\n",
    "\n",
    "        self.cache_misses.value += 1\n",
    "\n",
    "        # Create new data\n",
    "        data = creator_fn()\n",
    "        data_size_mb = data.nbytes / (1024 * 1024) if hasattr(data, \"nbytes\") else 0\n",
    "\n",
    "        # Check capacity and evict if needed\n",
    "        while self.allocated_mb.value + data_size_mb > self.capacity_mb and len(self._cache) > 0:\n",
    "            self._evict_lru()\n",
    "\n",
    "        # Add to cache\n",
    "        if self.allocated_mb.value + data_size_mb <= self.capacity_mb:\n",
    "            self._cache[key] = data\n",
    "            self._access_times[key] = self._access_counter\n",
    "            self._access_counter += 1\n",
    "            self.allocated_mb.value += data_size_mb\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _evict_lru(self):\n",
    "        \"\"\"Evict least recently used item.\"\"\"\n",
    "        if not self._cache:\n",
    "            return\n",
    "\n",
    "        lru_key = min(self._access_times, key=lambda k: self._access_times[k])\n",
    "        data = self._cache.pop(lru_key)\n",
    "        del self._access_times[lru_key]\n",
    "\n",
    "        data_size_mb = data.nbytes / (1024 * 1024) if hasattr(data, \"nbytes\") else 0\n",
    "        self.allocated_mb.value -= data_size_mb\n",
    "        self.evictions.value += 1\n",
    "\n",
    "    @property\n",
    "    def stats(self) -> dict:\n",
    "        \"\"\"Get memory pool statistics.\"\"\"\n",
    "        total_requests = self.cache_hits.value + self.cache_misses.value\n",
    "        hit_rate = self.cache_hits.value / max(total_requests, 1)\n",
    "\n",
    "        return {\n",
    "            \"allocated_mb\": float(self.allocated_mb.value),\n",
    "            \"capacity_mb\": self.capacity_mb,\n",
    "            \"utilization\": float(self.allocated_mb.value / self.capacity_mb),\n",
    "            \"hit_rate\": float(hit_rate),\n",
    "            \"cache_hits\": int(self.cache_hits.value),\n",
    "            \"cache_misses\": int(self.cache_misses.value),\n",
    "            \"evictions\": int(self.evictions.value),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulDistributedLoader(nnx.Module):\n",
    "    \"\"\"Stateful distributed loader with automatic coordination.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        num_workers: int = 4,\n",
    "        shard_id: int = 0,\n",
    "        num_shards: int = 1,\n",
    "        memory_pool_mb: int = 100,\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        # Sharding with NNX Variables\n",
    "        self.shard_id = nnx.Variable(shard_id)\n",
    "        self.num_shards = nnx.Variable(num_shards)\n",
    "\n",
    "        # Calculate shard boundaries\n",
    "        samples_per_shard = len(data) // num_shards\n",
    "        self.shard_start = nnx.Variable(shard_id * samples_per_shard)\n",
    "        self.shard_end = nnx.Variable(\n",
    "            len(data) if shard_id == num_shards - 1 else (shard_id + 1) * samples_per_shard\n",
    "        )\n",
    "\n",
    "        # Shared memory pool\n",
    "        self.memory_pool = SharedMemoryPool(memory_pool_mb)\n",
    "\n",
    "        # Worker coordination state\n",
    "        self.worker_active = [nnx.Variable(False) for _ in range(num_workers)]\n",
    "        self.worker_samples = [nnx.Variable(0) for _ in range(num_workers)]\n",
    "        self.worker_errors = [nnx.Variable(0) for _ in range(num_workers)]\n",
    "\n",
    "        # Global statistics\n",
    "        self.total_samples = nnx.Variable(0)\n",
    "        self.total_batches = nnx.Variable(0)\n",
    "        self.coordination_time = nnx.Variable(0.0)\n",
    "\n",
    "        # Internal structures\n",
    "        self._queue = queue.Queue(maxsize=num_workers * 2)\n",
    "        self._executor = ThreadPoolExecutor(max_workers=num_workers)\n",
    "        self._futures = []\n",
    "        self._stop_event = threading.Event()\n",
    "\n",
    "    def _worker_task(self, worker_id: int):\n",
    "        \"\"\"Worker task with automatic state management.\"\"\"\n",
    "        self.worker_active[worker_id].value = True\n",
    "\n",
    "        # Calculate worker's indices (strided access)\n",
    "        start_idx = self.shard_start.value + worker_id\n",
    "        end_idx = self.shard_end.value\n",
    "\n",
    "        current = start_idx\n",
    "        while current < end_idx and not self._stop_event.is_set():\n",
    "            try:\n",
    "                # Use shared memory pool for data\n",
    "                key = f\"data_{current}\"\n",
    "                sample = self.memory_pool.get_or_create(key, lambda: self.data[current])\n",
    "\n",
    "                # Update worker statistics\n",
    "                self.worker_samples[worker_id].value += 1\n",
    "\n",
    "                # Put in queue\n",
    "                self._queue.put((sample, worker_id), timeout=1.0)\n",
    "\n",
    "                current += self.num_workers\n",
    "\n",
    "            except Exception:\n",
    "                self.worker_errors[worker_id].value += 1\n",
    "\n",
    "        self.worker_active[worker_id].value = False\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start distributed processing.\"\"\"\n",
    "        self._stop_event.clear()\n",
    "\n",
    "        for i in range(self.num_workers):\n",
    "            future = self._executor.submit(self._worker_task, i)\n",
    "            self._futures.append(future)\n",
    "\n",
    "    def get_batch(self, batch_size: int, timeout: float = 5.0) -> jax.Array | None:\n",
    "        \"\"\"Get batch with automatic coordination.\"\"\"\n",
    "        batch = []\n",
    "        worker_ids = []\n",
    "        deadline = time.time() + timeout\n",
    "\n",
    "        coord_start = time.time()\n",
    "\n",
    "        while len(batch) < batch_size and time.time() < deadline:\n",
    "            try:\n",
    "                remaining = deadline - time.time()\n",
    "                if remaining <= 0:\n",
    "                    break\n",
    "\n",
    "                sample, worker_id = self._queue.get(timeout=min(remaining, 0.1))\n",
    "                batch.append(sample)\n",
    "                worker_ids.append(worker_id)\n",
    "\n",
    "            except queue.Empty:\n",
    "                if not any(self.worker_active[i].value for i in range(self.num_workers)):\n",
    "                    break\n",
    "\n",
    "        self.coordination_time.value += time.time() - coord_start\n",
    "\n",
    "        if not batch:\n",
    "            return None\n",
    "\n",
    "        # Update statistics\n",
    "        self.total_samples.value += len(batch)\n",
    "        self.total_batches.value += 1\n",
    "\n",
    "        return jnp.stack(batch)\n",
    "\n",
    "    def shutdown(self):\n",
    "        \"\"\"Clean shutdown.\"\"\"\n",
    "        self._stop_event.set()\n",
    "        self._executor.shutdown(wait=True)\n",
    "\n",
    "    @property\n",
    "    def stats(self) -> dict:\n",
    "        \"\"\"Get comprehensive statistics.\"\"\"\n",
    "        active_workers = sum(w.value for w in self.worker_active)\n",
    "        total_worker_samples = sum(w.value for w in self.worker_samples)\n",
    "        total_errors = sum(e.value for e in self.worker_errors)\n",
    "\n",
    "        return {\n",
    "            \"shard\": {\n",
    "                \"id\": int(self.shard_id.value),\n",
    "                \"total\": int(self.num_shards.value),\n",
    "                \"range\": (int(self.shard_start.value), int(self.shard_end.value)),\n",
    "            },\n",
    "            \"workers\": {\n",
    "                \"active\": active_workers,\n",
    "                \"total\": self.num_workers,\n",
    "                \"samples_processed\": total_worker_samples,\n",
    "                \"errors\": total_errors,\n",
    "            },\n",
    "            \"memory\": self.memory_pool.stats,\n",
    "            \"coordination\": {\n",
    "                \"total_samples\": int(self.total_samples.value),\n",
    "                \"total_batches\": int(self.total_batches.value),\n",
    "                \"avg_coord_time\": float(\n",
    "                    self.coordination_time.value / max(self.total_batches.value, 1)\n",
    "                ),\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class JAXShardedLoader(nnx.Module):\n",
    "    \"\"\"JAX-integrated sharded data loader.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, data: np.ndarray, mesh: jax.sharding.Mesh | None = None, batch_size: int = 32\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # JAX sharding integration\n",
    "        if mesh is not None:\n",
    "            self.mesh = mesh\n",
    "            self.sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(\"data\"))\n",
    "            devices = mesh.devices.flatten()\n",
    "        else:\n",
    "            devices = jax.devices()\n",
    "            self.mesh = None\n",
    "            self.sharding = None\n",
    "\n",
    "        self.num_devices = nnx.Variable(len(devices))\n",
    "        self.device_id = nnx.Variable(jax.process_index() if jax.process_count() > 1 else 0)\n",
    "\n",
    "        # Calculate local shard\n",
    "        samples_per_device = len(data) // len(devices)\n",
    "        self.local_start = nnx.Variable(self.device_id.value * samples_per_device)\n",
    "        self.local_end = nnx.Variable(\n",
    "            len(data)\n",
    "            if self.device_id.value == len(devices) - 1\n",
    "            else (self.device_id.value + 1) * samples_per_device\n",
    "        )\n",
    "\n",
    "        # Iteration state\n",
    "        self.current_idx = nnx.Variable(self.local_start.value)\n",
    "        self.epoch = nnx.Variable(0)\n",
    "        self.total_batches = nnx.Variable(0)\n",
    "\n",
    "    def get_batch(self) -> jax.Array:\n",
    "        \"\"\"Get sharded batch.\"\"\"\n",
    "        batch_indices = []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            if self.current_idx.value >= self.local_end.value:\n",
    "                # Wrap around\n",
    "                self.current_idx.value = self.local_start.value\n",
    "                self.epoch.value += 1\n",
    "\n",
    "            batch_indices.append(self.current_idx.value)\n",
    "            self.current_idx.value += 1\n",
    "\n",
    "        # Get batch data\n",
    "        batch = self.data[batch_indices]\n",
    "        self.total_batches.value += 1\n",
    "\n",
    "        # Apply sharding if configured\n",
    "        if self.sharding is not None:\n",
    "            batch = jax.device_put(batch, self.sharding)\n",
    "\n",
    "        return jnp.array(batch)\n",
    "\n",
    "    @property\n",
    "    def shard_info(self) -> dict:\n",
    "        \"\"\"Get sharding information.\"\"\"\n",
    "        return {\n",
    "            \"num_devices\": int(self.num_devices.value),\n",
    "            \"device_id\": int(self.device_id.value),\n",
    "            \"local_range\": (int(self.local_start.value), int(self.local_end.value)),\n",
    "            \"local_samples\": int(self.local_end.value - self.local_start.value),\n",
    "            \"current_position\": int(self.current_idx.value),\n",
    "            \"epoch\": int(self.epoch.value),\n",
    "            \"total_batches\": int(self.total_batches.value),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "============================================================================\n",
    "PRESSURE TESTING FUNCTIONS\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_large_distributed_dataset(\n",
    "    num_samples: int = 100000, feature_dim: int = 2048\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Create large dataset for distributed testing.\"\"\"\n",
    "    print(\"\\nCreating distributed dataset:\")\n",
    "    print(f\"  Samples: {num_samples:,}\")\n",
    "    print(f\"  Features: {feature_dim}\")\n",
    "    print(f\"  Total size: {(num_samples * feature_dim * 4) / (1024**3):.2f} GB\")\n",
    "\n",
    "    # Create in chunks to manage memory\n",
    "    return np.random.randn(num_samples, feature_dim).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_distributed_performance(\n",
    "    loader_name: str, loader: Any, batch_size: int, num_batches: int, is_stateful: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"Measure distributed loader performance.\"\"\"\n",
    "\n",
    "    print(f\"\\n{loader_name} Distributed Performance:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Start workers if needed\n",
    "    if is_stateful:\n",
    "        loader.start()\n",
    "    else:\n",
    "        loader.start_workers()\n",
    "\n",
    "    # Warmup\n",
    "    for i in range(min(5, num_batches)):\n",
    "        if is_stateful:\n",
    "            batch = loader.get_batch(batch_size)\n",
    "        else:\n",
    "            result = loader.get_batch(batch_size)\n",
    "            if result is not None:\n",
    "                batch, _ = result\n",
    "\n",
    "    # Measure\n",
    "    gc.collect()\n",
    "    times = []\n",
    "    memory_before = psutil.Process().memory_info().rss / (1024 * 1024)\n",
    "\n",
    "    successful_batches = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batch_start = time.time()\n",
    "\n",
    "        if is_stateful:\n",
    "            batch = loader.get_batch(batch_size, timeout=5.0)\n",
    "        else:\n",
    "            result = loader.get_batch(batch_size, timeout=5.0)\n",
    "            batch = result[0] if result else None\n",
    "\n",
    "        if batch is not None:\n",
    "            successful_batches += 1\n",
    "            # Force computation\n",
    "            _ = jnp.mean(batch) if is_stateful else np.mean(batch)\n",
    "\n",
    "        batch_time = time.time() - batch_start\n",
    "        times.append(batch_time)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    memory_after = psutil.Process().memory_info().rss / (1024 * 1024)\n",
    "\n",
    "    # Get statistics\n",
    "    if is_stateful:\n",
    "        stats = loader.stats\n",
    "    else:\n",
    "        memory_stats = loader.get_memory_usage()\n",
    "        stats = {\n",
    "            \"coordinator\": loader.coordinator_state,\n",
    "            \"memory\": memory_stats,\n",
    "            \"workers\": loader.worker_states,\n",
    "        }\n",
    "\n",
    "    # Calculate metrics\n",
    "    times = np.array(times)\n",
    "\n",
    "    results = {\n",
    "        \"total_time\": total_time,\n",
    "        \"successful_batches\": successful_batches,\n",
    "        \"mean_batch_time_ms\": np.mean(times) * 1000,\n",
    "        \"p95_batch_time_ms\": np.percentile(times, 95) * 1000,\n",
    "        \"throughput_batches_per_sec\": successful_batches / total_time,\n",
    "        \"memory_delta_mb\": memory_after - memory_before,\n",
    "        \"stats\": stats,\n",
    "    }\n",
    "\n",
    "    print(f\"  Successful batches: {successful_batches}/{num_batches}\")\n",
    "    print(f\"  Mean batch time: {results['mean_batch_time_ms']:.2f} ms\")\n",
    "    print(f\"  P95 batch time: {results['p95_batch_time_ms']:.2f} ms\")\n",
    "    print(f\"  Throughput: {results['throughput_batches_per_sec']:.1f} batches/sec\")\n",
    "    print(f\"  Memory delta: {results['memory_delta_mb']:.1f} MB\")\n",
    "\n",
    "    if is_stateful and \"memory\" in stats:\n",
    "        print(f\"  Cache hit rate: {stats['memory']['hit_rate']:.2%}\")\n",
    "\n",
    "    # Shutdown\n",
    "    if is_stateful:\n",
    "        loader.shutdown()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_memory_efficiency():\n",
    "    \"\"\"Test memory efficiency with shared memory pools.\"\"\"\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"MEMORY EFFICIENCY COMPARISON\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Create dataset\n",
    "    data = create_large_distributed_dataset(50000, 1024)\n",
    "\n",
    "    print(\"\\n1. GRAIN - Manual Memory Management:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    grain_loader = GrainDistributedLoader(\n",
    "        data, num_workers=4, shard_options=GrainShardOptions(1, 0), prefetch_size=20\n",
    "    )\n",
    "\n",
    "    grain_results = measure_distributed_performance(\n",
    "        \"Grain\", grain_loader, batch_size=64, num_batches=50, is_stateful=False\n",
    "    )\n",
    "\n",
    "    print(\"\\n2. DATARAX - Automatic Memory Pool:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    workshop_loader = StatefulDistributedLoader(\n",
    "        data, num_workers=4, shard_id=0, num_shards=1, memory_pool_mb=200\n",
    "    )\n",
    "\n",
    "    workshop_results = measure_distributed_performance(\n",
    "        \"Workshop\", workshop_loader, batch_size=64, num_batches=50, is_stateful=True\n",
    "    )\n",
    "\n",
    "    # Compare\n",
    "    memory_improvement = 1 - (\n",
    "        workshop_results[\"memory_delta_mb\"] / max(grain_results[\"memory_delta_mb\"], 1)\n",
    "    )\n",
    "    speed_improvement = grain_results[\"mean_batch_time_ms\"] / workshop_results[\"mean_batch_time_ms\"]\n",
    "\n",
    "    print(\"\\nIMPROVEMENTS:\")\n",
    "    print(f\"  Memory efficiency: {memory_improvement * 100:.1f}% better\")\n",
    "    print(f\"  Speed improvement: {speed_improvement:.2f}x\")\n",
    "\n",
    "    if \"memory\" in workshop_results[\"stats\"]:\n",
    "        cache_stats = workshop_results[\"stats\"][\"memory\"]\n",
    "        print(f\"  Cache effectiveness: {cache_stats['hit_rate']:.2%} hit rate\")\n",
    "        print(f\"  Memory utilization: {cache_stats['utilization']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_jax_sharding():\n",
    "    \"\"\"Test JAX sharding integration (Datarax only).\"\"\"\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"JAX SHARDING INTEGRATION (Datarax Exclusive)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Create data\n",
    "    data = create_large_distributed_dataset(10000, 512)\n",
    "\n",
    "    # Get available devices\n",
    "    devices = jax.devices()\n",
    "    print(f\"\\nAvailable devices: {len(devices)}\")\n",
    "    for i, device in enumerate(devices):\n",
    "        print(f\"  Device {i}: {device}\")\n",
    "\n",
    "    # Create mesh if multiple devices\n",
    "    if len(devices) > 1:\n",
    "        mesh = jax.sharding.Mesh(devices, (\"data\",))\n",
    "        print(f\"\\nCreated mesh with {len(devices)} devices\")\n",
    "    else:\n",
    "        mesh = None\n",
    "        print(\"\\nSingle device mode (no mesh)\")\n",
    "\n",
    "    # Create sharded loader\n",
    "    loader = JAXShardedLoader(data, mesh=mesh, batch_size=32)\n",
    "\n",
    "    print(\"\\nSharding Information:\")\n",
    "    shard_info = loader.shard_info\n",
    "    for key, value in shard_info.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    # Get some batches\n",
    "    print(\"\\nProcessing sharded batches:\")\n",
    "    for i in range(5):\n",
    "        batch = loader.get_batch()\n",
    "        print(\n",
    "            f\"  Batch {i + 1}: shape={batch.shape}, \"\n",
    "            f\"device={batch.device if hasattr(batch, 'device') else 'CPU'}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\nGrain equivalent:\")\n",
    "    print(\"  ❌ No native JAX sharding integration\")\n",
    "    print(\"  ❌ Manual device placement required\")\n",
    "    print(\"  ❌ Complex state coordination across devices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scaling_test():\n",
    "    \"\"\"Test scaling with different worker counts.\"\"\"\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SCALING TEST: WORKER COUNT IMPACT\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Create dataset\n",
    "    data = create_large_distributed_dataset(100000, 1024)\n",
    "\n",
    "    worker_counts = [1, 2, 4, 8]\n",
    "    grain_results = []\n",
    "    workshop_results = []\n",
    "\n",
    "    for num_workers in worker_counts:\n",
    "        print(f\"\\nTesting with {num_workers} workers:\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # Grain\n",
    "        grain_loader = GrainDistributedLoader(\n",
    "            data, num_workers=num_workers, prefetch_size=num_workers * 5\n",
    "        )\n",
    "\n",
    "        grain_perf = measure_distributed_performance(\n",
    "            f\"Grain ({num_workers}w)\",\n",
    "            grain_loader,\n",
    "            batch_size=128,\n",
    "            num_batches=30,\n",
    "            is_stateful=False,\n",
    "        )\n",
    "        grain_results.append(grain_perf)\n",
    "\n",
    "        # Workshop\n",
    "        workshop_loader = StatefulDistributedLoader(\n",
    "            data, num_workers=num_workers, memory_pool_mb=100 * num_workers\n",
    "        )\n",
    "\n",
    "        workshop_perf = measure_distributed_performance(\n",
    "            f\"Workshop ({num_workers}w)\",\n",
    "            workshop_loader,\n",
    "            batch_size=128,\n",
    "            num_batches=30,\n",
    "            is_stateful=True,\n",
    "        )\n",
    "        workshop_results.append(workshop_perf)\n",
    "\n",
    "    # Plot scaling\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SCALING RESULTS:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"Workers | Grain (ms) | Workshop (ms) | Speedup\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for i, num_workers in enumerate(worker_counts):\n",
    "        grain_time = grain_results[i][\"mean_batch_time_ms\"]\n",
    "        workshop_time = workshop_results[i][\"mean_batch_time_ms\"]\n",
    "        speedup = grain_time / workshop_time\n",
    "\n",
    "        print(\n",
    "            f\"   {num_workers:2d}   |   {grain_time:7.2f}  |    {workshop_time:7.2f}   |  \"\n",
    "            f\"{speedup:.2f}x\"\n",
    "        )\n",
    "\n",
    "    # Calculate scaling efficiency\n",
    "    grain_scaling = grain_results[0][\"mean_batch_time_ms\"] / grain_results[-1][\"mean_batch_time_ms\"]\n",
    "    workshop_scaling = (\n",
    "        workshop_results[0][\"mean_batch_time_ms\"] / workshop_results[-1][\"mean_batch_time_ms\"]\n",
    "    )\n",
    "\n",
    "    print(f\"\\nScaling efficiency (1 → {worker_counts[-1]} workers):\")\n",
    "    print(f\"  Grain: {grain_scaling:.2f}x\")\n",
    "    print(f\"  Workshop: {workshop_scaling:.2f}x\")\n",
    "    print(f\"  Better scaling: {'Workshop' if workshop_scaling > grain_scaling else 'Grain'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"ENHANCED DISTRIBUTED & MEMORY COMPARISON\")\n",
    "    print(\"All metrics from actual execution\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Test memory efficiency\n",
    "    test_memory_efficiency()\n",
    "\n",
    "    # Test JAX sharding\n",
    "    test_jax_sharding()\n",
    "\n",
    "    # Test scaling\n",
    "    run_scaling_test()\n",
    "\n",
    "    # Final summary\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL SUMMARY - DISTRIBUTED ADVANTAGES\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\n✓ Automatic worker coordination (Workshop)\")\n",
    "    print(\"✓ Built-in memory pooling with caching (Workshop)\")\n",
    "    print(\"✓ Native JAX sharding integration (Workshop)\")\n",
    "    print(\"✓ Automatic state synchronization (Workshop)\")\n",
    "    print(\"✓ Better scaling with worker count (Workshop)\")\n",
    "    print(\"✓ Lower memory footprint (Workshop)\")\n",
    "    print(\"✓ Simpler error handling (Workshop)\")\n",
    "\n",
    "    print(\"\\nConclusion: Datarax's stateful approach provides\")\n",
    "    print(\"superior distributed processing capabilities with less code\")\n",
    "    print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
