{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d47f2f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Monitoring Quick Reference\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Beginner |\n",
    "| **Runtime** | ~5 min |\n",
    "| **Prerequisites** | Basic Python, Simple Pipeline |\n",
    "| **Format** | Python + Jupyter |\n",
    "\n",
    "## Overview\n",
    "\n",
    "This quick reference demonstrates Datarax's built-in monitoring system for\n",
    "tracking pipeline metrics. You'll learn to use `MonitoredPipeline` with\n",
    "`ConsoleReporter` to observe throughput and custom metrics in real-time.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this example, you will be able to:\n",
    "\n",
    "1. Create a `MonitoredPipeline` that collects metrics automatically\n",
    "2. Register a `ConsoleReporter` for real-time metric display\n",
    "3. Record custom metrics during pipeline iteration\n",
    "4. Understand the metrics collection architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bbb03",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "# Install datarax\n",
    "uv pip install datarax\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "\n",
    "from datarax.dag.nodes import BatchNode, OperatorNode\n",
    "from datarax.monitoring.pipeline import MonitoredPipeline\n",
    "from datarax.monitoring.reporters import ConsoleReporter\n",
    "from datarax.operators import ElementOperator, ElementOperatorConfig\n",
    "from datarax.sources.memory_source import MemorySource, MemorySourceConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19515c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Key Concepts\n",
    "\n",
    "### MonitoredPipeline\n",
    "\n",
    "`MonitoredPipeline` extends the standard DAG executor with metrics collection:\n",
    "- Automatically tracks batch production\n",
    "- Records timing information\n",
    "- Provides a `metrics` object for custom metric recording\n",
    "- Supports callback observers for reporting\n",
    "\n",
    "### Reporters\n",
    "\n",
    "Reporters consume collected metrics:\n",
    "\n",
    "| Reporter | Description |\n",
    "|----------|-------------|\n",
    "| `ConsoleReporter` | Prints metrics to console at intervals |\n",
    "| `FileReporter` | Writes metrics to a file |\n",
    "\n",
    "### Metric Types\n",
    "\n",
    "| Metric | Description |\n",
    "|--------|-------------|\n",
    "| `batch_produced` | Count of batches yielded |\n",
    "| `pipeline_iteration` | Total iteration time |\n",
    "| `batch_production` | Per-batch production time |\n",
    "| Custom metrics | User-defined via `record_metric()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e1583e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 1: Create Data Source\n",
    "\n",
    "Start with a simple in-memory data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad93406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "data = [{\"value\": i, \"label\": i % 5} for i in range(200)]\n",
    "\n",
    "source_config = MemorySourceConfig()\n",
    "source = MemorySource(source_config, data=data, rngs=nnx.Rngs(0))\n",
    "\n",
    "print(f\"Data source: {len(data)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1dba5a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 2: Create Monitored Pipeline\n",
    "\n",
    "Use `MonitoredPipeline` instead of the standard `from_source()` API\n",
    "when you need metrics collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create monitored pipeline\n",
    "pipeline = MonitoredPipeline(source, metrics_enabled=True)\n",
    "\n",
    "# Register console reporter (reports every 1 second for demo)\n",
    "reporter = ConsoleReporter(report_interval=1.0)\n",
    "pipeline.callbacks.register(reporter)\n",
    "\n",
    "print(\"Created MonitoredPipeline with ConsoleReporter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924882b0",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 3: Add Pipeline Stages\n",
    "\n",
    "Add batching and transformations as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9078906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple transformation\n",
    "def double_value(element, key=None):  # noqa: ARG001\n",
    "    \"\"\"Double the value field.\"\"\"\n",
    "    del key  # Unused - deterministic operator\n",
    "    result = dict(element.data)\n",
    "    result[\"value\"] = result[\"value\"] * 2\n",
    "    return element.update_data(result)\n",
    "\n",
    "\n",
    "# Add batching (required before operators)\n",
    "pipeline.add(BatchNode(batch_size=32))\n",
    "\n",
    "# Add transformation operator\n",
    "double_op = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=False),\n",
    "    fn=double_value,\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "pipeline.add(OperatorNode(double_op))\n",
    "\n",
    "print(\"Pipeline: Source -> Batch(32) -> DoubleValue -> Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132d777",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 4: Process with Custom Metrics\n",
    "\n",
    "Iterate through the pipeline and record custom metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data with custom metrics\n",
    "print(\"\\nProcessing data with monitoring...\")\n",
    "print(\"(Metrics report will appear periodically)\")\n",
    "print()\n",
    "\n",
    "batch_count = 0\n",
    "total_samples = 0\n",
    "\n",
    "for batch in pipeline:\n",
    "    batch_count += 1\n",
    "\n",
    "    # Get batch data\n",
    "    values = batch[\"value\"]\n",
    "    labels = batch[\"label\"]\n",
    "    batch_size = values.shape[0]\n",
    "    total_samples += batch_size\n",
    "\n",
    "    # Record custom metrics\n",
    "    if pipeline.metrics.enabled:\n",
    "        # Record batch statistics\n",
    "        pipeline.metrics.record_metric(\n",
    "            \"batch_mean_value\",\n",
    "            float(jnp.mean(values)),\n",
    "            \"custom\",\n",
    "        )\n",
    "        pipeline.metrics.record_metric(\n",
    "            \"batch_max_value\",\n",
    "            float(jnp.max(values)),\n",
    "            \"custom\",\n",
    "        )\n",
    "\n",
    "    # Simulate some processing time\n",
    "    time.sleep(0.05)\n",
    "\n",
    "    # Print progress every 2 batches\n",
    "    if batch_count % 2 == 0:\n",
    "        mean_val = float(jnp.mean(values))\n",
    "        print(f\"Batch {batch_count}: {batch_size} samples, mean={mean_val:.1f}\")\n",
    "\n",
    "print(f\"\\nCompleted: {batch_count} batches, {total_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abed9b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "| Component | Value |\n",
    "|-----------|-------|\n",
    "| Data Source | MemorySource (200 samples) |\n",
    "| Batch Size | 32 |\n",
    "| Transformation | Double value field |\n",
    "| Reporter | ConsoleReporter (1s interval) |\n",
    "| Custom Metrics | batch_mean_value, batch_max_value |\n",
    "\n",
    "The monitoring system automatically tracks:\n",
    "- Number of batches produced\n",
    "- Pipeline iteration timing\n",
    "- Node additions to the pipeline\n",
    "- Custom metrics you record explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dcad49",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- **File output**: Use `FileReporter` to persist metrics to disk\n",
    "- **Custom reporters**: Implement `MetricsObserver` for custom destinations\n",
    "- **Distributed metrics**: [Distributed](../distributed/01_sharding_quickref.ipynb)\n",
    "- **API Reference**: [Monitoring module](https://datarax.readthedocs.io/monitoring/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b94d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the monitoring quick reference example.\"\"\"\n",
    "    print(\"Monitoring Quick Reference\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Create data and source\n",
    "    data = [{\"value\": i, \"label\": i % 5} for i in range(100)]\n",
    "    source = MemorySource(MemorySourceConfig(), data=data, rngs=nnx.Rngs(0))\n",
    "\n",
    "    # Create monitored pipeline\n",
    "    pipeline = MonitoredPipeline(source, metrics_enabled=True)\n",
    "    reporter = ConsoleReporter(report_interval=0.5)\n",
    "    pipeline.callbacks.register(reporter)\n",
    "\n",
    "    # Define transformation\n",
    "    def double_value(element, key=None):  # noqa: ARG001\n",
    "        del key\n",
    "        result = dict(element.data)\n",
    "        result[\"value\"] = result[\"value\"] * 2\n",
    "        return element.update_data(result)\n",
    "\n",
    "    # Build pipeline\n",
    "    pipeline.add(BatchNode(batch_size=16))\n",
    "    double_op = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=double_value,\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "    pipeline.add(OperatorNode(double_op))\n",
    "\n",
    "    # Process\n",
    "    total = 0\n",
    "    for batch in pipeline:\n",
    "        total += batch[\"value\"].shape[0]\n",
    "        # Record custom metric\n",
    "        pipeline.metrics.record_metric(\"batch_sum\", float(jnp.sum(batch[\"value\"])), \"example\")\n",
    "        time.sleep(0.02)\n",
    "\n",
    "    print(f\"\\nProcessed {total} samples with monitoring!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
