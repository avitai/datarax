{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cede413b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Simple Pipeline Quick Reference\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Beginner |\n",
    "| **Runtime** | ~5 min |\n",
    "| **Prerequisites** | Basic Python, NumPy fundamentals |\n",
    "| **Format** | Python + Jupyter |\n",
    "\n",
    "## Overview\n",
    "\n",
    "This quick reference demonstrates building a basic data pipeline with Datarax.\n",
    "You'll create an in-memory data source, apply transformations using operators,\n",
    "and iterate through batched data - the core workflow for any Datarax pipeline.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this example, you will be able to:\n",
    "\n",
    "1. Create a `MemorySource` from dictionary data\n",
    "2. Build a pipeline using the DAG-based `from_source()` API\n",
    "3. Apply deterministic and stochastic operators to data\n",
    "4. Iterate through batched pipeline output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02669083",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "# Install datarax\n",
    "uv pip install datarax\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "\n",
    "from datarax import from_source\n",
    "from datarax.dag.nodes import OperatorNode\n",
    "from datarax.operators import ElementOperator, ElementOperatorConfig\n",
    "from datarax.sources import MemorySource, MemorySourceConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd632a46",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 1: Create Sample Data\n",
    "\n",
    "Datarax works with dictionary-based data where each key maps to an array.\n",
    "The first dimension is the sample dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample MNIST-like data\n",
    "num_samples = 1000\n",
    "image_shape = (28, 28, 1)\n",
    "\n",
    "data = {\n",
    "    \"image\": np.random.randint(0, 255, (num_samples, *image_shape)).astype(np.float32),\n",
    "    \"label\": np.random.randint(0, 10, (num_samples,)).astype(np.int32),\n",
    "}\n",
    "\n",
    "print(f\"Created data: image={data['image'].shape}, label={data['label'].shape}\")\n",
    "# Expected output:\n",
    "# Created data: image=(1000, 28, 28, 1), label=(1000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d7f16",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 2: Create Data Source\n",
    "\n",
    "`MemorySource` wraps in-memory data for pipeline consumption.\n",
    "It requires a config object and random number generators (rngs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f9f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source with config-based API\n",
    "source_config = MemorySourceConfig()\n",
    "source = MemorySource(source_config, data=data, rngs=nnx.Rngs(0))\n",
    "\n",
    "print(f\"Source contains {len(source)} samples\")\n",
    "# Expected output:\n",
    "# Source contains 1000 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae56dc4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 3: Define Operators\n",
    "\n",
    "Operators transform data elements. There are two types:\n",
    "- **Deterministic**: Same input always produces same output\n",
    "- **Stochastic**: Uses random keys for randomized transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8017d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic operator: Normalize pixel values to [0, 1]\n",
    "def normalize(element, key=None):\n",
    "    \"\"\"Normalize image pixels to [0, 1] range.\"\"\"\n",
    "    return element.update_data({\"image\": element.data[\"image\"] / 255.0})\n",
    "\n",
    "\n",
    "normalizer_config = ElementOperatorConfig(stochastic=False)\n",
    "normalizer = ElementOperator(normalizer_config, fn=normalize, rngs=nnx.Rngs(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903aa26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic operator: Random horizontal flip\n",
    "def apply_augmentation(element, key):\n",
    "    \"\"\"Randomly flip image horizontally with 50% probability.\"\"\"\n",
    "    key1, _ = jax.random.split(key)\n",
    "    flip = jax.random.bernoulli(key1, 0.5)\n",
    "\n",
    "    def flip_image(img):\n",
    "        return jnp.flip(img, axis=1)\n",
    "\n",
    "    def no_flip(img):\n",
    "        return img\n",
    "\n",
    "    # Use jax.lax.cond for JAX-compatible branching\n",
    "    new_image = jax.lax.cond(flip, flip_image, no_flip, element.data[\"image\"])\n",
    "    return element.update_data({\"image\": new_image})\n",
    "\n",
    "\n",
    "augmenter_config = ElementOperatorConfig(stochastic=True, stream_name=\"augment\")\n",
    "augmenter = ElementOperator(augmenter_config, fn=apply_augmentation, rngs=nnx.Rngs(augment=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba40840",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 4: Build Pipeline\n",
    "\n",
    "Chain the source and operators using the DAG-based API.\n",
    "`from_source()` creates a batched pipeline, then `.add()` appends operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline DAG\n",
    "pipeline = (\n",
    "    from_source(source, batch_size=32).add(OperatorNode(normalizer)).add(OperatorNode(augmenter))\n",
    ")\n",
    "\n",
    "print(\"Pipeline created with batch_size=32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9334ef1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 5: Iterate Through Data\n",
    "\n",
    "The pipeline is iterable. Each iteration yields a batch dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process batches\n",
    "print(\"Processing batches:\")\n",
    "for i, batch in enumerate(pipeline):\n",
    "    if i >= 3:  # Show first 3 batches\n",
    "        break\n",
    "\n",
    "    image_batch = batch[\"image\"]\n",
    "    label_batch = batch[\"label\"]\n",
    "\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(f\"  Image shape: {image_batch.shape}\")\n",
    "    print(f\"  Label shape: {label_batch.shape}\")\n",
    "    print(f\"  Image range: [{image_batch.min():.3f}, {image_batch.max():.3f}]\")\n",
    "\n",
    "# Expected output:\n",
    "# Processing batches:\n",
    "# Batch 0:\n",
    "#   Image shape: (32, 28, 28, 1)\n",
    "#   Label shape: (32,)\n",
    "#   Image range: [0.000, 1.000]\n",
    "# Batch 1:\n",
    "#   Image shape: (32, 28, 28, 1)\n",
    "#   ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f2eeac",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| Data Source | 1000 samples of 28x28 grayscale images |\n",
    "| Batch Size | 32 samples per batch |\n",
    "| Operators | Normalization (deterministic) + Flip (stochastic) |\n",
    "| Output Range | [0.0, 1.0] after normalization |\n",
    "\n",
    "The pipeline processes data lazily - batches are only created when iterated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9776c59",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- **More operators**: See [Operators Tutorial](03_operators_tutorial.ipynb)\n",
    "- **External data**: [TFDS](../integration/tfds/01_tfds_quickref.ipynb) or\n",
    "  [HuggingFace](../integration/huggingface/01_hf_quickref.ipynb)\n",
    "- **Distributed**: [Sharding](../advanced/distributed/01_sharding_quickref.ipynb)\n",
    "- **API Reference**: [MemorySource](https://datarax.readthedocs.io/sources/memory_source/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1baed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the complete pipeline example.\"\"\"\n",
    "    # Create data\n",
    "    num_samples = 1000\n",
    "    data = {\n",
    "        \"image\": np.random.randint(0, 255, (num_samples, 28, 28, 1)).astype(np.float32),\n",
    "        \"label\": np.random.randint(0, 10, (num_samples,)).astype(np.int32),\n",
    "    }\n",
    "\n",
    "    # Create source\n",
    "    source = MemorySource(MemorySourceConfig(), data=data, rngs=nnx.Rngs(0))\n",
    "\n",
    "    # Create operators\n",
    "    normalizer = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False), fn=normalize, rngs=nnx.Rngs(0)\n",
    "    )\n",
    "    augmenter = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=True, stream_name=\"augment\"),\n",
    "        fn=apply_augmentation,\n",
    "        rngs=nnx.Rngs(augment=42),\n",
    "    )\n",
    "\n",
    "    # Build and run pipeline\n",
    "    pipeline = (\n",
    "        from_source(source, batch_size=32)\n",
    "        .add(OperatorNode(normalizer))\n",
    "        .add(OperatorNode(augmenter))\n",
    "    )\n",
    "\n",
    "    total_samples = 0\n",
    "    for batch in pipeline:\n",
    "        total_samples += batch[\"image\"].shape[0]\n",
    "\n",
    "    print(f\"Processed {total_samples} samples successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
