{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c987a4a2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# TFDS Integration Quick Reference\n",
    "\n",
    "| Metadata | Value |\n",
    "|----------|-------|\n",
    "| **Level** | Beginner |\n",
    "| **Runtime** | ~5 min |\n",
    "| **Prerequisites** | Basic Python, NumPy fundamentals |\n",
    "| **Format** | Python + Jupyter |\n",
    "\n",
    "## Overview\n",
    "\n",
    "This quick reference demonstrates loading datasets from TensorFlow Datasets (TFDS)\n",
    "using Datarax's `TFDSSource`. You'll load MNIST, apply transformations, and\n",
    "iterate through batched data using the standard pipeline API.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this example, you will be able to:\n",
    "\n",
    "1. Configure and create a `TFDSSource` with proper config\n",
    "2. Apply transformations to TFDS data\n",
    "3. Build a batched pipeline with operators\n",
    "4. Iterate through transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab5e9a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "# Install datarax with TFDS support\n",
    "uv pip install \"datarax[tfds]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Memory Configuration\n",
    "# Prevent TensorFlow from using GPU (JAX handles GPU computation)\n",
    "# This MUST be set BEFORE importing tensorflow\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES_FOR_TF\"] = \"\"  # TF-specific GPU disable\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # Suppress all TF logs\n",
    "\n",
    "# Force TF to CPU-only mode BEFORE importing JAX\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "# Now import JAX which will handle GPU\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "\n",
    "# Conditionally import TFDS source\n",
    "try:\n",
    "    from datarax.sources import TfdsDataSourceConfig, TFDSSource\n",
    "except ImportError as e:\n",
    "    raise ImportError(\n",
    "        \"This example requires TensorFlow Datasets. Install with: uv pip install datarax[tfds]\"\n",
    "    ) from e\n",
    "\n",
    "from datarax import from_source\n",
    "from datarax.dag.nodes import OperatorNode\n",
    "from datarax.operators import ElementOperator, ElementOperatorConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb088ddd",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 1: Create TFDS Data Source\n",
    "\n",
    "`TFDSSource` wraps TensorFlow Datasets for use in Datarax pipelines.\n",
    "The config specifies the dataset name, split, and shuffling options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957dd7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure TFDS source for MNIST\n",
    "config = TfdsDataSourceConfig(\n",
    "    name=\"mnist\",\n",
    "    split=\"train[:500]\",  # Use subset for quick demo\n",
    "    shuffle=True,\n",
    "    stochastic=True,\n",
    "    stream_name=\"shuffle\",\n",
    ")\n",
    "\n",
    "source = TFDSSource(config, rngs=nnx.Rngs(42, shuffle=42))\n",
    "\n",
    "print(\"Dataset: MNIST\")\n",
    "print(f\"Samples: {len(source)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08fc97",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 2: Define Transformations\n",
    "\n",
    "Create operators to preprocess the data. TFDS data comes as raw\n",
    "uint8 images which need normalization for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(element, key=None):  # noqa: ARG001\n",
    "    \"\"\"Normalize image to [0, 1] range.\"\"\"\n",
    "    del key  # Unused - deterministic operator\n",
    "    image = element.data[\"image\"]\n",
    "    normalized = image.astype(jnp.float32) / 255.0\n",
    "    return element.update_data({\"image\": normalized})\n",
    "\n",
    "\n",
    "normalizer = ElementOperator(\n",
    "    ElementOperatorConfig(stochastic=False),\n",
    "    fn=normalize_image,\n",
    "    rngs=nnx.Rngs(0),\n",
    ")\n",
    "\n",
    "print(\"Created normalizer operator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1698dc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 3: Build Pipeline\n",
    "\n",
    "Chain source and operators using the DAG-based `from_source()` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194340ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "pipeline = from_source(source, batch_size=32).add(OperatorNode(normalizer))\n",
    "\n",
    "print(\"Pipeline: TFDSSource(MNIST) -> Normalize -> Output\")\n",
    "print(\"Batch size: 32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6adefb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 4: Iterate Through Data\n",
    "\n",
    "Process batches and inspect the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3bd961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process batches\n",
    "print(\"\\nProcessing batches:\")\n",
    "for i, batch in enumerate(pipeline):\n",
    "    if i >= 3:  # Show first 3 batches\n",
    "        break\n",
    "\n",
    "    image_batch = batch[\"image\"]\n",
    "    label_batch = batch[\"label\"]\n",
    "\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(f\"  Image: shape={image_batch.shape}, dtype={image_batch.dtype}\")\n",
    "    print(f\"  Image range: [{float(image_batch.min()):.3f}, {float(image_batch.max()):.3f}]\")\n",
    "    print(f\"  Label: shape={label_batch.shape}\")\n",
    "\n",
    "# Expected output:\n",
    "# Batch 0:\n",
    "#   Image: shape=(32, 28, 28, 1), dtype=float32\n",
    "#   Image range: [0.000, 1.000]\n",
    "#   Label: shape=(32,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f932f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| Data Source | TFDS MNIST (500 samples) |\n",
    "| Batch Size | 32 samples per batch |\n",
    "| Transforms | Image normalization [0, 255] -> [0, 1] |\n",
    "| Output | Normalized float32 images |\n",
    "\n",
    "The pipeline integrates TFDS datasets into the Datarax ecosystem,\n",
    "enabling the use of all standard operators and augmentations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597f15b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- **More datasets**: Try `cifar10`, `imagenet`, or other TFDS datasets\n",
    "- **Augmentations**: Add image operators from `datarax.operators.modality.image`\n",
    "- **Distributed**: [Sharding](../../advanced/distributed/01_sharding_quickref.ipynb)\n",
    "- **API Reference**: [TFDSSource](https://datarax.readthedocs.io/sources/tfds/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the TFDS quick reference example.\"\"\"\n",
    "    # Create source\n",
    "    config = TfdsDataSourceConfig(\n",
    "        name=\"mnist\",\n",
    "        split=\"train[:200]\",\n",
    "        shuffle=True,\n",
    "        stochastic=True,\n",
    "        stream_name=\"shuffle\",\n",
    "    )\n",
    "    source = TFDSSource(config, rngs=nnx.Rngs(42, shuffle=42))\n",
    "\n",
    "    # Create operator\n",
    "    normalizer = ElementOperator(\n",
    "        ElementOperatorConfig(stochastic=False),\n",
    "        fn=normalize_image,\n",
    "        rngs=nnx.Rngs(0),\n",
    "    )\n",
    "\n",
    "    # Build and run pipeline\n",
    "    pipeline = from_source(source, batch_size=32).add(OperatorNode(normalizer))\n",
    "\n",
    "    total_samples = 0\n",
    "    for batch in pipeline:\n",
    "        total_samples += batch[\"image\"].shape[0]\n",
    "        # Verify normalization\n",
    "        assert batch[\"image\"].min() >= 0.0, \"Image not normalized\"\n",
    "        assert batch[\"image\"].max() <= 1.0, \"Image not normalized\"\n",
    "\n",
    "    print(f\"Processed {total_samples} TFDS samples successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
